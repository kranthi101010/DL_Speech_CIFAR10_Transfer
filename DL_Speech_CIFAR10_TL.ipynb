{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNAwvdNw27I-"
      },
      "source": [
        "# Deep Learning Techniques for Speech Denoising and CIFAR-10 Classification with Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6fzqqOY3IMc"
      },
      "source": [
        "## Speech Denoising Using Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGK_IJTTdyqu"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-2MYgfDeOlQ"
      },
      "outputs": [],
      "source": [
        "s, sr = librosa.load('train_clean_male.wav', sr=None)\n",
        "S = librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "\n",
        "sn, sr = librosa.load('train_dirty_male.wav', sr=None)\n",
        "X = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "# Take the magnitude of spectrograms\n",
        "S_mag = np.abs(S)\n",
        "X_mag = np.abs(X)\n",
        "\n",
        "# Prepare training data\n",
        "X_train = X_mag.T  # Shape: (2459, 513)\n",
        "Y_train = S_mag.T  # Shape: (2459, 513)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_YPnoW0yd9B"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_mag.T, S_mag.T, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCLz8t28eiww",
        "outputId": "89b19b17-0235-42d5-dec2-06dd272cc723"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(513,)),\n",
        "    tf.keras.layers.Dense(1024, activation='relu', kernel_initializer=tf.keras.initializers.HeUniform()),\n",
        "    tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.HeUniform()),\n",
        "    tf.keras.layers.Dense(513, activation='relu',kernel_initializer=tf.keras.initializers.HeUniform())  # Ensure nonnegative output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCkfmPEyy8cn",
        "outputId": "e2f1cb75-ab8f-472f-fe16-330cbede2237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.1248 - val_loss: 0.0559\n",
            "Epoch 2/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0642 - val_loss: 0.0365\n",
            "Epoch 3/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - val_loss: 0.0267\n",
            "Epoch 4/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0262 - val_loss: 0.0214\n",
            "Epoch 5/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - val_loss: 0.0189\n",
            "Epoch 6/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0200 - val_loss: 0.0171\n",
            "Epoch 7/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0161\n",
            "Epoch 8/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0153\n",
            "Epoch 9/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0147\n",
            "Epoch 10/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0142\n",
            "Epoch 11/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0136\n",
            "Epoch 12/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0133\n",
            "Epoch 13/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0128\n",
            "Epoch 14/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0121\n",
            "Epoch 15/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0120\n",
            "Epoch 16/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0116\n",
            "Epoch 17/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0115\n",
            "Epoch 18/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0111\n",
            "Epoch 19/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0112\n",
            "Epoch 20/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0109\n",
            "Epoch 21/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0109\n",
            "Epoch 22/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0108\n",
            "Epoch 23/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0106\n",
            "Epoch 24/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0105\n",
            "Epoch 25/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0104\n",
            "Epoch 26/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0104\n",
            "Epoch 27/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0102\n",
            "Epoch 28/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0100\n",
            "Epoch 29/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0100\n",
            "Epoch 30/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0100\n",
            "Epoch 31/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0098\n",
            "Epoch 32/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0097\n",
            "Epoch 33/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0099\n",
            "Epoch 34/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0097\n",
            "Epoch 35/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0096\n",
            "Epoch 36/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0096\n",
            "Epoch 37/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0096\n",
            "Epoch 38/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0095\n",
            "Epoch 39/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0094\n",
            "Epoch 40/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0094\n",
            "Epoch 41/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0094\n",
            "Epoch 42/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0093\n",
            "Epoch 43/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - val_loss: 0.0093\n",
            "Epoch 44/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0094\n",
            "Epoch 45/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0092\n",
            "Epoch 46/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
            "Epoch 47/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0092\n",
            "Epoch 48/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0091\n",
            "Epoch 49/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - val_loss: 0.0091\n",
            "Epoch 50/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0092\n",
            "Epoch 51/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0090\n",
            "Epoch 52/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0090\n",
            "Epoch 53/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0089\n",
            "Epoch 54/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0088\n",
            "Epoch 55/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0088\n",
            "Epoch 56/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0087\n",
            "Epoch 57/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0087\n",
            "Epoch 58/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0088\n",
            "Epoch 59/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0087\n",
            "Epoch 60/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0086\n",
            "Epoch 61/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0087\n",
            "Epoch 62/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0086\n",
            "Epoch 63/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0085\n",
            "Epoch 64/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0085\n",
            "Epoch 65/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0084\n",
            "Epoch 66/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0084\n",
            "Epoch 67/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0084\n",
            "Epoch 68/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0083\n",
            "Epoch 69/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0083\n",
            "Epoch 70/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0084\n",
            "Epoch 71/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0083\n",
            "Epoch 72/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0084\n",
            "Epoch 73/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0086\n",
            "Epoch 74/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0084\n",
            "Epoch 75/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0082\n",
            "Epoch 76/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0082\n",
            "Epoch 77/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0083\n",
            "Epoch 78/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0084\n",
            "Epoch 79/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0081\n",
            "Epoch 80/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0082\n",
            "Epoch 81/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0083\n",
            "Epoch 82/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0081\n",
            "Epoch 83/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0081\n",
            "Epoch 84/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0082\n",
            "Epoch 85/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0081\n",
            "Epoch 86/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0082\n",
            "Epoch 87/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0078\n",
            "Epoch 88/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0076\n",
            "Epoch 89/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0076\n",
            "Epoch 90/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0075\n",
            "Epoch 91/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0076\n",
            "Epoch 92/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0076\n",
            "Epoch 93/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0076\n",
            "Epoch 94/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0074\n",
            "Epoch 95/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0075\n",
            "Epoch 96/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0075\n",
            "Epoch 97/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0074\n",
            "Epoch 98/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0074\n",
            "Epoch 99/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0074\n",
            "Epoch 100/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0074\n",
            "Epoch 101/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0075\n",
            "Epoch 102/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0074\n",
            "Epoch 103/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0074\n",
            "Epoch 104/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0075\n",
            "Epoch 105/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0075\n",
            "Epoch 106/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0074\n",
            "Epoch 107/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0074\n",
            "Epoch 108/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0075\n",
            "Epoch 109/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 110/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0073\n",
            "Epoch 111/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0073\n",
            "Epoch 112/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0073\n",
            "Epoch 113/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0072\n",
            "Epoch 114/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0072\n",
            "Epoch 115/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0074\n",
            "Epoch 116/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0072\n",
            "Epoch 117/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0072\n",
            "Epoch 118/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0077\n",
            "Epoch 119/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0072\n",
            "Epoch 120/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0074\n",
            "Epoch 121/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0073\n",
            "Epoch 122/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0072\n",
            "Epoch 123/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0071\n",
            "Epoch 124/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0071\n",
            "Epoch 125/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0071\n",
            "Epoch 126/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0071\n",
            "Epoch 127/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0071\n",
            "Epoch 128/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0070\n",
            "Epoch 129/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0071\n",
            "Epoch 130/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0071\n",
            "Epoch 131/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0072\n",
            "Epoch 132/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0071\n",
            "Epoch 133/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0071\n",
            "Epoch 134/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0071\n",
            "Epoch 135/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0072\n",
            "Epoch 136/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0071\n",
            "Epoch 137/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 138/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0071\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor the validation loss\n",
        "    patience=10,          # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True  # Restores model weights from the epoch with the best validation loss\n",
        ")\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,  # Set a high number of epochs; early stopping will terminate if needed\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "046YrpEBfCTX",
        "outputId": "29e8d91c-ef1f-4c96-c946-d6a1865e1d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
          ]
        }
      ],
      "source": [
        "test_sn, _ = librosa.load('/content/test_x_01.wav', sr=None)\n",
        "X_test = librosa.stft(test_sn, n_fft=1024, hop_length=512)\n",
        "X_test_mag = np.abs(X_test).T\n",
        "\n",
        "# Predict the clean magnitude spectrogram\n",
        "S_test_mag_pred = model.predict(X_test_mag)\n",
        "\n",
        "# Reconstruct the complex-valued spectrogram\n",
        "S_test = (X_test / np.abs(X_test)) * S_test_mag_pred.T\n",
        "\n",
        "# Apply inverse STFT to get the time-domain signal\n",
        "s_test_reconstructed = librosa.istft(S_test, hop_length=512)\n",
        "\n",
        "# Save the reconstructed audio\n",
        "import soundfile as sf\n",
        "sf.write('test_s_01_recons.wav', s_test_reconstructed, sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM-ikGIUiMfP",
        "outputId": "74189d75-2eaa-48b7-f504-a23c5b16b51c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SNR: 8.448843355207424 dB\n"
          ]
        }
      ],
      "source": [
        "# Load the ground-truth clean signal for SNR calculation\n",
        "test_clean, _ = librosa.load('/content/test_s_01.wav', sr=None)\n",
        "\n",
        "min_len = min(len(test_clean), len(s_test_reconstructed))\n",
        "test_clean_trimmed = test_clean[:min_len]\n",
        "s_test_reconstructed_trimmed = s_test_reconstructed[:min_len]\n",
        "\n",
        "# Compute SNR\n",
        "squared_diff = np.sum((test_clean_trimmed - s_test_reconstructed_trimmed) ** 2)\n",
        "squared_signal = np.sum(test_clean_trimmed ** 2)\n",
        "SNR = 10 * np.log10(squared_signal / (squared_diff + 1e-20))\n",
        "print(f'SNR: {SNR} dB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUcqOaCBfIBv",
        "outputId": "c19382ed-c58e-4147-b8e1-ea3d62e2a3f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        }
      ],
      "source": [
        "test_sn_02, _ = librosa.load('/content/test_x_02.wav', sr=None)\n",
        "X_test_02 = librosa.stft(test_sn_02, n_fft=1024, hop_length=512)\n",
        "X_test_02_mag = np.abs(X_test_02).T\n",
        "\n",
        "# Predict the clean magnitude spectrogram for test_02_x\n",
        "S_test_02_mag_pred = model.predict(X_test_02_mag)\n",
        "\n",
        "# Reconstruct the complex-valued spectrogram\n",
        "S_test_02 = (X_test_02 / np.abs(X_test_02)) * S_test_02_mag_pred.T\n",
        "\n",
        "# Apply inverse STFT to get the time-domain signal\n",
        "s_test_02_reconstructed = librosa.istft(S_test_02, hop_length=512)\n",
        "\n",
        "# Save the reconstructed audio for test_02_x\n",
        "sf.write('test_s_02_recons.wav', s_test_02_reconstructed, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tINwCrbPBdyg"
      },
      "source": [
        "reconstructed sound of test_s_02\n",
        "[test_s_02_reconstructed](https://drive.google.com/file/d/1zbpsJJaHTf7XRB6Jw_GnutT4XUti92do/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYbt6MeL7ZwS"
      },
      "source": [
        "## Speech Denoising Using 1D CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-AUYI7y7bai"
      },
      "outputs": [],
      "source": [
        "#will start to load all the audio signals again to avoid mislap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itgXFuqKItMU"
      },
      "outputs": [],
      "source": [
        "s, sr = librosa.load('train_clean_male.wav', sr=None)\n",
        "S = librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "\n",
        "sn, sr = librosa.load('train_dirty_male.wav', sr=None)\n",
        "X = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "# Take the magnitude of spectrograms\n",
        "S_mag = np.abs(S)\n",
        "X_mag = np.abs(X)\n",
        "\n",
        "# Prepare training data\n",
        "X_train = X_mag.T\n",
        "Y_train = S_mag.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXaB5miJJyC0"
      },
      "outputs": [],
      "source": [
        "X_train = X_train[:, :, np.newaxis]\n",
        "y_train = Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EUBCWd87_LS"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2XhXqn89dOl",
        "outputId": "7e4ebd7f-38f1-49b2-a679-b644c2db0aed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model_CNN = tf.keras.models.Sequential([\n",
        "\n",
        "    tf.keras.layers.Conv1D(filters=512, kernel_size=5, strides=2, padding='same', activation='relu', input_shape=(513,1), kernel_initializer=tf.keras.initializers.HeUniform()),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
        "\n",
        "    tf.keras.layers.Conv1D(filters=750, kernel_size=5, strides=2, padding='same', activation='relu', kernel_initializer=tf.keras.initializers.HeUniform()),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
        "\n",
        "    tf.keras.layers.Conv1D(filters=1024, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer=tf.keras.initializers.HeUniform()),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(513, activation='relu')\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJjZsO5zJKA6",
        "outputId": "2ab5e224-293b-4893-f409-4cc0d9bb932a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 2/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 0.0062\n",
            "Epoch 3/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 4/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 5/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 6/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 7/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 8/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 9/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 10/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 11/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 12/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 13/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 14/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 15/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 16/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 17/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9422e-04 - val_loss: 0.0062\n",
            "Epoch 18/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 19/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 20/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8649e-04 - val_loss: 0.0062\n",
            "Epoch 21/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 22/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 23/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 24/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 25/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9016e-04 - val_loss: 0.0062\n",
            "Epoch 26/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 27/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 28/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 29/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 30/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 31/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 32/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8743e-04 - val_loss: 0.0062\n",
            "Epoch 33/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 34/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 35/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 36/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 37/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 38/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 39/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 40/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 41/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 42/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 43/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8574e-04 - val_loss: 0.0062\n",
            "Epoch 44/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4046e-04 - val_loss: 0.0062\n",
            "Epoch 45/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 46/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 47/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 48/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 49/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 50/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 51/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 52/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 53/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 54/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 55/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 56/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 57/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 58/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 59/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 60/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 61/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 62/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 63/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 64/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 65/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 66/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 67/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 68/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 69/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 70/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 71/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 72/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 73/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 74/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 75/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 76/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7285e-04 - val_loss: 0.0062\n",
            "Epoch 77/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 78/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9120e-04 - val_loss: 0.0062\n",
            "Epoch 79/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 80/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 81/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 82/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 83/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 84/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 85/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 86/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 87/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 88/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 89/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 90/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 91/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 92/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 93/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 94/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 95/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 96/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 97/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 98/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 99/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 100/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 101/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 102/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 103/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 104/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 105/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 106/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 107/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 108/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 109/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 110/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 111/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 112/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3189e-04 - val_loss: 0.0062\n",
            "Epoch 113/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 114/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 115/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 116/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 117/200\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 0.0062\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor the validation loss\n",
        "    patience=50,          # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True  # Restores model weights from the epoch with the best validation loss\n",
        ")\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,  # Set a high number of epochs; early stopping will terminate if needed\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwk8zlg4DJjZ",
        "outputId": "bbf3301c-d96c-4ecf-995a-a72cdd09aeb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
          ]
        }
      ],
      "source": [
        "test_sn, _ = librosa.load('/content/test_x_01.wav', sr=None)\n",
        "X_test = librosa.stft(test_sn, n_fft=1024, hop_length=512)\n",
        "X_test_mag = np.abs(X_test).T\n",
        "\n",
        "# Predict the clean magnitude spectrogram\n",
        "S_test_mag_pred = model.predict(X_test_mag)\n",
        "\n",
        "# Reconstruct the complex-valued spectrogram\n",
        "S_test = (X_test / np.abs(X_test)) * S_test_mag_pred.T\n",
        "\n",
        "# Apply inverse STFT to get the time-domain signal\n",
        "s_test_reconstructed = librosa.istft(S_test, hop_length=512)\n",
        "\n",
        "# Save the reconstructed audio\n",
        "import soundfile as sf\n",
        "sf.write('test_s_01_recons_cnn.wav', s_test_reconstructed, sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ5aEousEw09",
        "outputId": "05c07e33-7487-41de-f531-3b8c4e3d7a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SNR: 11.247308227280179 dB\n"
          ]
        }
      ],
      "source": [
        "# Load the ground-truth clean signal for SNR calculation\n",
        "test_clean, _ = librosa.load('/content/test_s_01.wav', sr=None)\n",
        "\n",
        "#min_len = min(len(test_clean), len(s_test_reconstructed))\n",
        "test_clean_trimmed = test_clean[:min_len]\n",
        "s_test_reconstructed_trimmed = s_test_reconstructed[:min_len]\n",
        "\n",
        "# Compute SNR\n",
        "squared_diff = np.sum((test_clean_trimmed - s_test_reconstructed_trimmed) ** 2)\n",
        "squared_signal = np.sum(test_clean_trimmed ** 2)\n",
        "SNR = 10 * np.log10(squared_signal / (squared_diff + 1e-20))\n",
        "print(f'SNR: {SNR} dB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO8MJt-dFcRl",
        "outputId": "0c1e4d00-1c80-4c38-ac87-e8b9c9386a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
          ]
        }
      ],
      "source": [
        "test_sn_02, _ = librosa.load('/content/test_x_02.wav', sr=None)\n",
        "X_test_02 = librosa.stft(test_sn_02, n_fft=1024, hop_length=512)\n",
        "X_test_02_mag = np.abs(X_test_02).T\n",
        "\n",
        "# Predict the clean magnitude spectrogram for test_02_x\n",
        "S_test_02_mag_pred = model.predict(X_test_02_mag)\n",
        "\n",
        "# Reconstruct the complex-valued spectrogram\n",
        "S_test_02 = (X_test_02 / np.abs(X_test_02)) * S_test_02_mag_pred.T\n",
        "\n",
        "# Apply inverse STFT to get the time-domain signal\n",
        "s_test_02_reconstructed = librosa.istft(S_test_02, hop_length=512)\n",
        "\n",
        "# Save the reconstructed audio for test_02_x\n",
        "sf.write('test_s_02_recons_cnn.wav', s_test_02_reconstructed, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKt7Emj3CccC"
      },
      "source": [
        "Sound file of test_s_02\n",
        "[test_s_02_recons_cnn](https://drive.google.com/file/d/1vBM5VRrzcu20bkqsVtf3oFXy_u3bxCPn/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_3_MG-KRxuJ"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jly0bxlEU2gV",
        "outputId": "27f03241-33c4-4688-dda2-b88d7d3c6794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W32Z306PU4FE"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=5000, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLbF9YGAU4N4"
      },
      "outputs": [],
      "source": [
        "X_train_base = X_train.astype('float32') / 255.0\n",
        "X_val_base = X_val.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFkkur17XmWO"
      },
      "outputs": [],
      "source": [
        "X_train = 2 * X_train_base - 1\n",
        "X_val = 2 * X_val_base - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMlnbZ9zU4SD"
      },
      "outputs": [],
      "source": [
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU_s3tPZAPax",
        "outputId": "cb535c7c-0bdb-4abb-d215-a76d70ccb9f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([45000, 32, 32, 3])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPxwDso5U4V8",
        "outputId": "6034632e-f3c0-40b7-c4af-44c491047b7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model_cifar = models.Sequential([\n",
        "    layers.Conv2D(10, (5,5), strides=1,activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Conv2D(10,(5,5),strides=1,activation='relu'),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(20, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtMYVpG7RxV7"
      },
      "outputs": [],
      "source": [
        "model_cifar.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UULlixeZsW5",
        "outputId": "0561b30d-994d-4cae-c97c-a79c5d55e74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.3117 - loss: 1.8735 - val_accuracy: 0.4718 - val_loss: 1.4567\n",
            "Epoch 2/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4882 - loss: 1.4054 - val_accuracy: 0.5046 - val_loss: 1.3529\n",
            "Epoch 3/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5390 - loss: 1.2861 - val_accuracy: 0.5600 - val_loss: 1.2341\n",
            "Epoch 4/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5703 - loss: 1.2021 - val_accuracy: 0.5590 - val_loss: 1.2089\n",
            "Epoch 5/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5896 - loss: 1.1527 - val_accuracy: 0.5634 - val_loss: 1.2147\n",
            "Epoch 6/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 1.1207 - val_accuracy: 0.5966 - val_loss: 1.1222\n",
            "Epoch 7/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6062 - loss: 1.1164 - val_accuracy: 0.5888 - val_loss: 1.1324\n",
            "Epoch 8/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6258 - loss: 1.0687 - val_accuracy: 0.5994 - val_loss: 1.1316\n",
            "Epoch 9/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 1.0579 - val_accuracy: 0.5986 - val_loss: 1.1268\n",
            "Epoch 10/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6368 - loss: 1.0314 - val_accuracy: 0.6168 - val_loss: 1.0734\n",
            "Epoch 11/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6421 - loss: 1.0202 - val_accuracy: 0.6200 - val_loss: 1.0664\n",
            "Epoch 12/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6476 - loss: 1.0070 - val_accuracy: 0.6212 - val_loss: 1.0485\n",
            "Epoch 13/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6489 - loss: 1.0011 - val_accuracy: 0.6246 - val_loss: 1.0546\n",
            "Epoch 14/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6533 - loss: 0.9891 - val_accuracy: 0.6146 - val_loss: 1.0718\n",
            "Epoch 15/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6565 - loss: 0.9772 - val_accuracy: 0.6268 - val_loss: 1.0540\n",
            "Epoch 16/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6621 - loss: 0.9680 - val_accuracy: 0.6326 - val_loss: 1.0446\n",
            "Epoch 17/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 0.9638 - val_accuracy: 0.6334 - val_loss: 1.0516\n",
            "Epoch 18/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6651 - loss: 0.9524 - val_accuracy: 0.6372 - val_loss: 1.0306\n",
            "Epoch 19/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6673 - loss: 0.9481 - val_accuracy: 0.6368 - val_loss: 1.0224\n",
            "Epoch 20/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6693 - loss: 0.9440 - val_accuracy: 0.6408 - val_loss: 1.0321\n",
            "Epoch 21/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6690 - loss: 0.9350 - val_accuracy: 0.6428 - val_loss: 1.0179\n",
            "Epoch 22/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6722 - loss: 0.9269 - val_accuracy: 0.6456 - val_loss: 1.0226\n",
            "Epoch 23/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6748 - loss: 0.9337 - val_accuracy: 0.6334 - val_loss: 1.0475\n",
            "Epoch 24/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.9286 - val_accuracy: 0.6414 - val_loss: 1.0469\n",
            "Epoch 25/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6748 - loss: 0.9226 - val_accuracy: 0.6334 - val_loss: 1.0607\n",
            "Epoch 26/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.9086 - val_accuracy: 0.6376 - val_loss: 1.0439\n",
            "Epoch 27/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6800 - loss: 0.9114 - val_accuracy: 0.6416 - val_loss: 1.0205\n",
            "Epoch 28/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6830 - loss: 0.8995 - val_accuracy: 0.6460 - val_loss: 1.0325\n",
            "Epoch 29/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6837 - loss: 0.8958 - val_accuracy: 0.6448 - val_loss: 1.0248\n",
            "Epoch 30/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.8879 - val_accuracy: 0.6384 - val_loss: 1.0392\n",
            "Epoch 31/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6862 - loss: 0.8942 - val_accuracy: 0.6426 - val_loss: 1.0172\n",
            "Epoch 32/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6850 - loss: 0.8926 - val_accuracy: 0.6556 - val_loss: 1.0164\n",
            "Epoch 33/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 0.8771 - val_accuracy: 0.6486 - val_loss: 1.0119\n",
            "Epoch 34/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6908 - loss: 0.8844 - val_accuracy: 0.6460 - val_loss: 1.0324\n",
            "Epoch 35/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.8738 - val_accuracy: 0.6434 - val_loss: 1.0338\n",
            "Epoch 36/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6989 - loss: 0.8670 - val_accuracy: 0.6416 - val_loss: 1.0417\n",
            "Epoch 37/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6952 - loss: 0.8685 - val_accuracy: 0.6458 - val_loss: 1.0212\n",
            "Epoch 38/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6945 - loss: 0.8712 - val_accuracy: 0.6490 - val_loss: 1.0276\n",
            "Epoch 39/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6994 - loss: 0.8632 - val_accuracy: 0.6530 - val_loss: 1.0039\n",
            "Epoch 40/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6979 - loss: 0.8589 - val_accuracy: 0.6470 - val_loss: 1.0325\n",
            "Epoch 41/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7024 - loss: 0.8506 - val_accuracy: 0.6382 - val_loss: 1.0466\n",
            "Epoch 42/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8613 - val_accuracy: 0.6374 - val_loss: 1.0570\n",
            "Epoch 43/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7013 - loss: 0.8546 - val_accuracy: 0.6452 - val_loss: 1.0271\n",
            "Epoch 44/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7038 - loss: 0.8415 - val_accuracy: 0.6508 - val_loss: 1.0198\n",
            "Epoch 45/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.8465 - val_accuracy: 0.6492 - val_loss: 1.0231\n",
            "Epoch 46/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.8513 - val_accuracy: 0.6418 - val_loss: 1.0221\n",
            "Epoch 47/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.8414 - val_accuracy: 0.6518 - val_loss: 1.0274\n",
            "Epoch 48/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7109 - loss: 0.8335 - val_accuracy: 0.6510 - val_loss: 1.0283\n",
            "Epoch 49/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7040 - loss: 0.8376 - val_accuracy: 0.6368 - val_loss: 1.0628\n",
            "Epoch 50/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7134 - loss: 0.8227 - val_accuracy: 0.6354 - val_loss: 1.0875\n",
            "Epoch 51/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7091 - loss: 0.8325 - val_accuracy: 0.6464 - val_loss: 1.0470\n",
            "Epoch 52/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7090 - loss: 0.8355 - val_accuracy: 0.6440 - val_loss: 1.0533\n",
            "Epoch 53/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7066 - loss: 0.8354 - val_accuracy: 0.6382 - val_loss: 1.0623\n",
            "Epoch 54/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7086 - loss: 0.8328 - val_accuracy: 0.6420 - val_loss: 1.0579\n",
            "Epoch 55/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8267 - val_accuracy: 0.6512 - val_loss: 1.0279\n",
            "Epoch 56/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.8252 - val_accuracy: 0.6452 - val_loss: 1.0430\n",
            "Epoch 57/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7085 - loss: 0.8302 - val_accuracy: 0.6438 - val_loss: 1.0511\n",
            "Epoch 58/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.8198 - val_accuracy: 0.6470 - val_loss: 1.0375\n",
            "Epoch 59/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.8318 - val_accuracy: 0.6440 - val_loss: 1.0436\n",
            "Epoch 60/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7109 - loss: 0.8259 - val_accuracy: 0.6504 - val_loss: 1.0398\n",
            "Epoch 61/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7101 - loss: 0.8198 - val_accuracy: 0.6448 - val_loss: 1.0400\n",
            "Epoch 62/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7147 - loss: 0.8144 - val_accuracy: 0.6476 - val_loss: 1.0315\n",
            "Epoch 63/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.8178 - val_accuracy: 0.6496 - val_loss: 1.0515\n",
            "Epoch 64/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.8136 - val_accuracy: 0.6482 - val_loss: 1.0501\n",
            "Epoch 65/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7144 - loss: 0.8175 - val_accuracy: 0.6526 - val_loss: 1.0406\n",
            "Epoch 66/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.8081 - val_accuracy: 0.6562 - val_loss: 1.0309\n",
            "Epoch 67/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.8158 - val_accuracy: 0.6550 - val_loss: 1.0276\n",
            "Epoch 68/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7134 - loss: 0.8160 - val_accuracy: 0.6486 - val_loss: 1.0340\n",
            "Epoch 69/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7179 - loss: 0.8005 - val_accuracy: 0.6490 - val_loss: 1.0443\n",
            "Epoch 70/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.8074 - val_accuracy: 0.6538 - val_loss: 1.0375\n",
            "Epoch 71/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.8058 - val_accuracy: 0.6374 - val_loss: 1.0865\n",
            "Epoch 72/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.8100 - val_accuracy: 0.6378 - val_loss: 1.0741\n",
            "Epoch 73/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.7984 - val_accuracy: 0.6434 - val_loss: 1.0882\n",
            "Epoch 74/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.7940 - val_accuracy: 0.6512 - val_loss: 1.0560\n",
            "Epoch 75/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7185 - loss: 0.7980 - val_accuracy: 0.6388 - val_loss: 1.0858\n",
            "Epoch 76/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7128 - loss: 0.8102 - val_accuracy: 0.6468 - val_loss: 1.0812\n",
            "Epoch 77/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.8118 - val_accuracy: 0.6436 - val_loss: 1.1036\n",
            "Epoch 78/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.8116 - val_accuracy: 0.6408 - val_loss: 1.0712\n",
            "Epoch 79/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.7917 - val_accuracy: 0.6406 - val_loss: 1.0850\n",
            "Epoch 80/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.7914 - val_accuracy: 0.6518 - val_loss: 1.0516\n",
            "Epoch 81/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 0.7933 - val_accuracy: 0.6454 - val_loss: 1.0595\n",
            "Epoch 82/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.7902 - val_accuracy: 0.6428 - val_loss: 1.0648\n",
            "Epoch 83/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.7964 - val_accuracy: 0.6498 - val_loss: 1.0668\n",
            "Epoch 84/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.7958 - val_accuracy: 0.6454 - val_loss: 1.0723\n",
            "Epoch 85/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.7902 - val_accuracy: 0.6470 - val_loss: 1.0704\n",
            "Epoch 86/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.7912 - val_accuracy: 0.6476 - val_loss: 1.0817\n",
            "Epoch 87/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.7887 - val_accuracy: 0.6420 - val_loss: 1.0677\n",
            "Epoch 88/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7180 - loss: 0.8005 - val_accuracy: 0.6410 - val_loss: 1.0958\n",
            "Epoch 89/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.7937 - val_accuracy: 0.6504 - val_loss: 1.0714\n",
            "Epoch 90/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.7883 - val_accuracy: 0.6460 - val_loss: 1.1053\n",
            "Epoch 91/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.7803 - val_accuracy: 0.6454 - val_loss: 1.0802\n",
            "Epoch 92/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.7835 - val_accuracy: 0.6410 - val_loss: 1.0994\n",
            "Epoch 93/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.7876 - val_accuracy: 0.6488 - val_loss: 1.0729\n",
            "Epoch 94/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.7943 - val_accuracy: 0.6494 - val_loss: 1.0879\n",
            "Epoch 95/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.7799 - val_accuracy: 0.6502 - val_loss: 1.0726\n",
            "Epoch 96/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.7841 - val_accuracy: 0.6494 - val_loss: 1.0714\n",
            "Epoch 97/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.7874 - val_accuracy: 0.6434 - val_loss: 1.0874\n",
            "Epoch 98/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.7896 - val_accuracy: 0.6494 - val_loss: 1.0861\n",
            "Epoch 99/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.7855 - val_accuracy: 0.6490 - val_loss: 1.0741\n",
            "Epoch 100/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.7881 - val_accuracy: 0.6440 - val_loss: 1.0881\n",
            "Epoch 101/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.7817 - val_accuracy: 0.6508 - val_loss: 1.0791\n",
            "Epoch 102/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.7797 - val_accuracy: 0.6392 - val_loss: 1.1075\n",
            "Epoch 103/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.7856 - val_accuracy: 0.6356 - val_loss: 1.1322\n",
            "Epoch 104/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.7743 - val_accuracy: 0.6466 - val_loss: 1.1082\n",
            "Epoch 105/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.7825 - val_accuracy: 0.6318 - val_loss: 1.1362\n",
            "Epoch 106/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.7788 - val_accuracy: 0.6492 - val_loss: 1.0798\n",
            "Epoch 107/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.7730 - val_accuracy: 0.6454 - val_loss: 1.0986\n",
            "Epoch 108/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.7745 - val_accuracy: 0.6418 - val_loss: 1.0909\n",
            "Epoch 109/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.7713 - val_accuracy: 0.6468 - val_loss: 1.0878\n",
            "Epoch 110/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.7768 - val_accuracy: 0.6404 - val_loss: 1.1137\n",
            "Epoch 111/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.7753 - val_accuracy: 0.6512 - val_loss: 1.0930\n",
            "Epoch 112/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.7631 - val_accuracy: 0.6450 - val_loss: 1.0985\n",
            "Epoch 113/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.7732 - val_accuracy: 0.6516 - val_loss: 1.0841\n",
            "Epoch 114/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.7761 - val_accuracy: 0.6462 - val_loss: 1.0891\n",
            "Epoch 115/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.7715 - val_accuracy: 0.6488 - val_loss: 1.0796\n",
            "Epoch 116/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7247 - loss: 0.7842 - val_accuracy: 0.6526 - val_loss: 1.0800\n",
            "Epoch 117/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.7705 - val_accuracy: 0.6486 - val_loss: 1.0986\n",
            "Epoch 118/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.7667 - val_accuracy: 0.6456 - val_loss: 1.0880\n",
            "Epoch 119/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.7655 - val_accuracy: 0.6508 - val_loss: 1.0766\n",
            "Epoch 120/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.7711 - val_accuracy: 0.6386 - val_loss: 1.1109\n",
            "Epoch 121/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.7719 - val_accuracy: 0.6480 - val_loss: 1.0868\n",
            "Epoch 122/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.7673 - val_accuracy: 0.6402 - val_loss: 1.1154\n",
            "Epoch 123/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.7682 - val_accuracy: 0.6412 - val_loss: 1.1036\n",
            "Epoch 124/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7247 - loss: 0.7771 - val_accuracy: 0.6452 - val_loss: 1.1027\n",
            "Epoch 125/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.7717 - val_accuracy: 0.6380 - val_loss: 1.1409\n",
            "Epoch 126/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.7697 - val_accuracy: 0.6442 - val_loss: 1.0915\n",
            "Epoch 127/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.7647 - val_accuracy: 0.6366 - val_loss: 1.1225\n",
            "Epoch 128/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.7669 - val_accuracy: 0.6436 - val_loss: 1.1015\n",
            "Epoch 129/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.7616 - val_accuracy: 0.6564 - val_loss: 1.0852\n",
            "Epoch 130/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.7712 - val_accuracy: 0.6460 - val_loss: 1.0838\n",
            "Epoch 131/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.7636 - val_accuracy: 0.6398 - val_loss: 1.1179\n",
            "Epoch 132/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.7640 - val_accuracy: 0.6532 - val_loss: 1.0794\n",
            "Epoch 133/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.7608 - val_accuracy: 0.6316 - val_loss: 1.1350\n",
            "Epoch 134/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.7535 - val_accuracy: 0.6432 - val_loss: 1.1140\n",
            "Epoch 135/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.7570 - val_accuracy: 0.6366 - val_loss: 1.1367\n",
            "Epoch 136/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.7569 - val_accuracy: 0.6406 - val_loss: 1.1093\n",
            "Epoch 137/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.7567 - val_accuracy: 0.6510 - val_loss: 1.0970\n",
            "Epoch 138/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.7577 - val_accuracy: 0.6472 - val_loss: 1.0883\n",
            "Epoch 139/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.7670 - val_accuracy: 0.6490 - val_loss: 1.0957\n",
            "Epoch 140/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.7620 - val_accuracy: 0.6400 - val_loss: 1.1213\n",
            "Epoch 141/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.7626 - val_accuracy: 0.6482 - val_loss: 1.0972\n",
            "Epoch 142/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.7641 - val_accuracy: 0.6458 - val_loss: 1.1084\n",
            "Epoch 143/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.7638 - val_accuracy: 0.6370 - val_loss: 1.1235\n",
            "Epoch 144/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.7575 - val_accuracy: 0.6490 - val_loss: 1.0883\n",
            "Epoch 145/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.7592 - val_accuracy: 0.6468 - val_loss: 1.0875\n",
            "Epoch 146/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.7643 - val_accuracy: 0.6432 - val_loss: 1.1053\n",
            "Epoch 147/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.7710 - val_accuracy: 0.6390 - val_loss: 1.1205\n",
            "Epoch 148/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.7639 - val_accuracy: 0.6394 - val_loss: 1.1096\n",
            "Epoch 149/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.7587 - val_accuracy: 0.6436 - val_loss: 1.1034\n",
            "Epoch 150/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7304 - loss: 0.7626 - val_accuracy: 0.6428 - val_loss: 1.1219\n",
            "Epoch 151/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.7671 - val_accuracy: 0.6448 - val_loss: 1.1082\n",
            "Epoch 152/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.7580 - val_accuracy: 0.6428 - val_loss: 1.1307\n",
            "Epoch 153/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.7609 - val_accuracy: 0.6484 - val_loss: 1.0986\n",
            "Epoch 154/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.7552 - val_accuracy: 0.6358 - val_loss: 1.1632\n",
            "Epoch 155/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.7555 - val_accuracy: 0.6410 - val_loss: 1.1262\n",
            "Epoch 156/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.7542 - val_accuracy: 0.6504 - val_loss: 1.1072\n",
            "Epoch 157/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.7436 - val_accuracy: 0.6480 - val_loss: 1.1189\n",
            "Epoch 158/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.7580 - val_accuracy: 0.6410 - val_loss: 1.1138\n",
            "Epoch 159/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.7550 - val_accuracy: 0.6422 - val_loss: 1.1329\n",
            "Epoch 160/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.7534 - val_accuracy: 0.6404 - val_loss: 1.1096\n",
            "Epoch 161/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 0.7539 - val_accuracy: 0.6414 - val_loss: 1.1467\n",
            "Epoch 162/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.7536 - val_accuracy: 0.6436 - val_loss: 1.1185\n",
            "Epoch 163/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.7440 - val_accuracy: 0.6454 - val_loss: 1.1182\n",
            "Epoch 164/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.7578 - val_accuracy: 0.6394 - val_loss: 1.1694\n",
            "Epoch 165/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7322 - loss: 0.7586 - val_accuracy: 0.6458 - val_loss: 1.1187\n",
            "Epoch 166/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.7476 - val_accuracy: 0.6380 - val_loss: 1.1387\n",
            "Epoch 167/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.7590 - val_accuracy: 0.6380 - val_loss: 1.1208\n",
            "Epoch 168/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.7580 - val_accuracy: 0.6366 - val_loss: 1.1524\n",
            "Epoch 169/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.7525 - val_accuracy: 0.6452 - val_loss: 1.1220\n",
            "Epoch 170/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: 0.7499 - val_accuracy: 0.6466 - val_loss: 1.1384\n",
            "Epoch 171/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.7538 - val_accuracy: 0.6432 - val_loss: 1.1188\n",
            "Epoch 172/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.7496 - val_accuracy: 0.6476 - val_loss: 1.1189\n",
            "Epoch 173/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.7524 - val_accuracy: 0.6448 - val_loss: 1.1341\n",
            "Epoch 174/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.7580 - val_accuracy: 0.6352 - val_loss: 1.1623\n",
            "Epoch 175/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.7573 - val_accuracy: 0.6378 - val_loss: 1.1409\n",
            "Epoch 176/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.7597 - val_accuracy: 0.6512 - val_loss: 1.1173\n",
            "Epoch 177/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 0.7450 - val_accuracy: 0.6412 - val_loss: 1.1486\n",
            "Epoch 178/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.7510 - val_accuracy: 0.6336 - val_loss: 1.1648\n",
            "Epoch 179/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.7556 - val_accuracy: 0.6410 - val_loss: 1.1267\n",
            "Epoch 180/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7399 - loss: 0.7431 - val_accuracy: 0.6406 - val_loss: 1.1339\n",
            "Epoch 181/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7371 - loss: 0.7447 - val_accuracy: 0.6510 - val_loss: 1.1180\n",
            "Epoch 182/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.7501 - val_accuracy: 0.6394 - val_loss: 1.1433\n",
            "Epoch 183/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.7489 - val_accuracy: 0.6412 - val_loss: 1.1352\n",
            "Epoch 184/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.7444 - val_accuracy: 0.6466 - val_loss: 1.1121\n",
            "Epoch 185/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.7383 - val_accuracy: 0.6480 - val_loss: 1.1119\n",
            "Epoch 186/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.7495 - val_accuracy: 0.6464 - val_loss: 1.1118\n",
            "Epoch 187/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.7443 - val_accuracy: 0.6398 - val_loss: 1.1466\n",
            "Epoch 188/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.7550 - val_accuracy: 0.6324 - val_loss: 1.1655\n",
            "Epoch 189/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.7496 - val_accuracy: 0.6368 - val_loss: 1.1425\n",
            "Epoch 190/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.7494 - val_accuracy: 0.6420 - val_loss: 1.1443\n",
            "Epoch 191/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.7539 - val_accuracy: 0.6442 - val_loss: 1.1313\n",
            "Epoch 192/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.7550 - val_accuracy: 0.6432 - val_loss: 1.1456\n",
            "Epoch 193/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.7491 - val_accuracy: 0.6336 - val_loss: 1.1522\n",
            "Epoch 194/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.7440 - val_accuracy: 0.6406 - val_loss: 1.1335\n",
            "Epoch 195/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.7429 - val_accuracy: 0.6376 - val_loss: 1.1402\n",
            "Epoch 196/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.7401 - val_accuracy: 0.6430 - val_loss: 1.1190\n",
            "Epoch 197/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.7357 - val_accuracy: 0.6388 - val_loss: 1.1270\n",
            "Epoch 198/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.7504 - val_accuracy: 0.6388 - val_loss: 1.1359\n",
            "Epoch 199/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.7479 - val_accuracy: 0.6506 - val_loss: 1.1286\n",
            "Epoch 200/200\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.7530 - val_accuracy: 0.6436 - val_loss: 1.1589\n"
          ]
        }
      ],
      "source": [
        "history = model_cifar.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,  # Set a high number of epochs; early stopping will terminate if needed\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "v_62n4l5cm3N",
        "outputId": "61989a44-d143-4151-f522-0c9b4c7b99af"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['val_accuracy'], label='Baseline Model')\n",
        "plt.title('Validation Accuracy Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hPog7_eextX"
      },
      "source": [
        "Building Augmented classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUayf9nodJmX"
      },
      "outputs": [],
      "source": [
        "X_train_bright=np.minimum(1.1*X_train_base,1)\n",
        "X_train_dark=np.maximum(0.9*X_train_base,0)\n",
        "X_train_flip=np.flip(X_train_base,axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "wBZIsePwC0m9",
        "outputId": "cdf2f898-9201-424d-d660-646136b1a2c0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(8, 8))\n",
        "\n",
        "    # Original image\n",
        "    axes[0].imshow(X_train_base[i])\n",
        "    axes[0].set_title('Original')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Brightened image\n",
        "    axes[1].imshow(X_train_bright[i])\n",
        "    axes[1].set_title('Brightened')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Darkened image\n",
        "    axes[2].imshow(X_train_dark[i])\n",
        "    axes[2].set_title('Darkened')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    # Flipped image\n",
        "    axes[3].imshow(X_train_flip[i])\n",
        "    axes[3].set_title('Flipped')\n",
        "    axes[3].axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LzWtdjpfgVV"
      },
      "outputs": [],
      "source": [
        "X_augmented = np.concatenate([X_train_base, X_train_bright, X_train_dark, X_train_flip], axis=0)\n",
        "y_augmented = np.tile(y_train, (4, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUbGbB5YimeT"
      },
      "outputs": [],
      "source": [
        "#normalizing it to [-1,1] again.\n",
        "X_augmented = 2 * X_augmented - 1\n",
        "model_cifar.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qup8IIjQipvD",
        "outputId": "179e34cd-cfa6-4f49-b26c-9538899e26e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.7063 - loss: 0.8481 - val_accuracy: 0.6520 - val_loss: 1.0551\n",
            "Epoch 2/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7086 - loss: 0.8360 - val_accuracy: 0.6498 - val_loss: 1.0467\n",
            "Epoch 3/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.8353 - val_accuracy: 0.6528 - val_loss: 1.0535\n",
            "Epoch 4/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7093 - loss: 0.8356 - val_accuracy: 0.6518 - val_loss: 1.0673\n",
            "Epoch 5/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7099 - loss: 0.8341 - val_accuracy: 0.6584 - val_loss: 1.0106\n",
            "Epoch 6/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.8328 - val_accuracy: 0.6536 - val_loss: 1.0360\n",
            "Epoch 7/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7126 - loss: 0.8271 - val_accuracy: 0.6586 - val_loss: 1.0063\n",
            "Epoch 8/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7129 - loss: 0.8216 - val_accuracy: 0.6670 - val_loss: 1.0018\n",
            "Epoch 9/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8274 - val_accuracy: 0.6588 - val_loss: 1.0258\n",
            "Epoch 10/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8194 - val_accuracy: 0.6654 - val_loss: 0.9965\n",
            "Epoch 11/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.8264 - val_accuracy: 0.6660 - val_loss: 0.9996\n",
            "Epoch 12/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.8246 - val_accuracy: 0.6570 - val_loss: 1.0197\n",
            "Epoch 13/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7115 - loss: 0.8253 - val_accuracy: 0.6532 - val_loss: 1.0320\n",
            "Epoch 14/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.8220 - val_accuracy: 0.6608 - val_loss: 1.0165\n",
            "Epoch 15/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.8236 - val_accuracy: 0.6580 - val_loss: 1.0324\n",
            "Epoch 16/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7144 - loss: 0.8185 - val_accuracy: 0.6652 - val_loss: 1.0004\n",
            "Epoch 17/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7109 - loss: 0.8266 - val_accuracy: 0.6652 - val_loss: 1.0046\n",
            "Epoch 18/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.8207 - val_accuracy: 0.6698 - val_loss: 0.9872\n",
            "Epoch 19/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7111 - loss: 0.8263 - val_accuracy: 0.6566 - val_loss: 1.0354\n",
            "Epoch 20/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7147 - loss: 0.8217 - val_accuracy: 0.6670 - val_loss: 0.9956\n",
            "Epoch 21/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.8217 - val_accuracy: 0.6650 - val_loss: 1.0011\n",
            "Epoch 22/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7159 - loss: 0.8165 - val_accuracy: 0.6644 - val_loss: 1.0061\n",
            "Epoch 23/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.8138 - val_accuracy: 0.6622 - val_loss: 0.9975\n",
            "Epoch 24/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7156 - loss: 0.8165 - val_accuracy: 0.6674 - val_loss: 1.0017\n",
            "Epoch 25/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.8204 - val_accuracy: 0.6676 - val_loss: 1.0051\n",
            "Epoch 26/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7152 - loss: 0.8185 - val_accuracy: 0.6666 - val_loss: 1.0009\n",
            "Epoch 27/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8169 - val_accuracy: 0.6524 - val_loss: 1.0360\n",
            "Epoch 28/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.8176 - val_accuracy: 0.6668 - val_loss: 0.9975\n",
            "Epoch 29/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7175 - loss: 0.8102 - val_accuracy: 0.6598 - val_loss: 1.0190\n",
            "Epoch 30/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7144 - loss: 0.8155 - val_accuracy: 0.6646 - val_loss: 0.9945\n",
            "Epoch 31/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.8163 - val_accuracy: 0.6644 - val_loss: 0.9983\n",
            "Epoch 32/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7156 - loss: 0.8111 - val_accuracy: 0.6622 - val_loss: 0.9992\n",
            "Epoch 33/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.8126 - val_accuracy: 0.6646 - val_loss: 0.9743\n",
            "Epoch 34/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.8117 - val_accuracy: 0.6622 - val_loss: 1.0114\n",
            "Epoch 35/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7166 - loss: 0.8097 - val_accuracy: 0.6672 - val_loss: 0.9905\n",
            "Epoch 36/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.8133 - val_accuracy: 0.6612 - val_loss: 1.0046\n",
            "Epoch 37/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.8122 - val_accuracy: 0.6646 - val_loss: 0.9936\n",
            "Epoch 38/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.8102 - val_accuracy: 0.6602 - val_loss: 1.0109\n",
            "Epoch 39/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7169 - loss: 0.8107 - val_accuracy: 0.6692 - val_loss: 0.9975\n",
            "Epoch 40/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7175 - loss: 0.8082 - val_accuracy: 0.6694 - val_loss: 0.9898\n",
            "Epoch 41/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.8111 - val_accuracy: 0.6726 - val_loss: 0.9826\n",
            "Epoch 42/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.8058 - val_accuracy: 0.6702 - val_loss: 0.9847\n",
            "Epoch 43/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.8081 - val_accuracy: 0.6642 - val_loss: 1.0039\n",
            "Epoch 44/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.8050 - val_accuracy: 0.6694 - val_loss: 0.9910\n",
            "Epoch 45/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.8032 - val_accuracy: 0.6678 - val_loss: 0.9861\n",
            "Epoch 46/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.8089 - val_accuracy: 0.6736 - val_loss: 0.9959\n",
            "Epoch 47/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.8000 - val_accuracy: 0.6602 - val_loss: 1.0211\n",
            "Epoch 48/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7179 - loss: 0.8107 - val_accuracy: 0.6674 - val_loss: 0.9914\n",
            "Epoch 49/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7200 - loss: 0.8034 - val_accuracy: 0.6696 - val_loss: 0.9855\n",
            "Epoch 50/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7179 - loss: 0.8053 - val_accuracy: 0.6588 - val_loss: 1.0161\n",
            "Epoch 51/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7185 - loss: 0.8047 - val_accuracy: 0.6712 - val_loss: 1.0036\n",
            "Epoch 52/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.8067 - val_accuracy: 0.6740 - val_loss: 0.9780\n",
            "Epoch 53/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.8029 - val_accuracy: 0.6574 - val_loss: 1.0178\n",
            "Epoch 54/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7207 - loss: 0.8003 - val_accuracy: 0.6690 - val_loss: 0.9751\n",
            "Epoch 55/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.8053 - val_accuracy: 0.6564 - val_loss: 1.0382\n",
            "Epoch 56/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.8023 - val_accuracy: 0.6690 - val_loss: 1.0100\n",
            "Epoch 57/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7196 - loss: 0.8030 - val_accuracy: 0.6704 - val_loss: 0.9881\n",
            "Epoch 58/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.8007 - val_accuracy: 0.6688 - val_loss: 1.0014\n",
            "Epoch 59/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7194 - loss: 0.7990 - val_accuracy: 0.6670 - val_loss: 0.9953\n",
            "Epoch 60/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.8014 - val_accuracy: 0.6694 - val_loss: 1.0105\n",
            "Epoch 61/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.7994 - val_accuracy: 0.6630 - val_loss: 0.9870\n",
            "Epoch 62/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.8000 - val_accuracy: 0.6658 - val_loss: 1.0115\n",
            "Epoch 63/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.8054 - val_accuracy: 0.6646 - val_loss: 0.9903\n",
            "Epoch 64/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.7967 - val_accuracy: 0.6642 - val_loss: 0.9990\n",
            "Epoch 65/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.8056 - val_accuracy: 0.6722 - val_loss: 0.9981\n",
            "Epoch 66/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.7980 - val_accuracy: 0.6670 - val_loss: 1.0014\n",
            "Epoch 67/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.7991 - val_accuracy: 0.6674 - val_loss: 0.9973\n",
            "Epoch 68/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.8019 - val_accuracy: 0.6662 - val_loss: 0.9970\n",
            "Epoch 69/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.7987 - val_accuracy: 0.6662 - val_loss: 0.9998\n",
            "Epoch 70/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.8028 - val_accuracy: 0.6638 - val_loss: 1.0083\n",
            "Epoch 71/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.7967 - val_accuracy: 0.6692 - val_loss: 0.9913\n",
            "Epoch 72/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.8005 - val_accuracy: 0.6730 - val_loss: 0.9938\n",
            "Epoch 73/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.7962 - val_accuracy: 0.6594 - val_loss: 1.0183\n",
            "Epoch 74/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.7950 - val_accuracy: 0.6742 - val_loss: 0.9969\n",
            "Epoch 75/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.7978 - val_accuracy: 0.6652 - val_loss: 0.9979\n",
            "Epoch 76/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.7961 - val_accuracy: 0.6622 - val_loss: 1.0088\n",
            "Epoch 77/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.7968 - val_accuracy: 0.6642 - val_loss: 1.0157\n",
            "Epoch 78/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.7961 - val_accuracy: 0.6722 - val_loss: 0.9778\n",
            "Epoch 79/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.7975 - val_accuracy: 0.6668 - val_loss: 0.9913\n",
            "Epoch 80/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.7984 - val_accuracy: 0.6666 - val_loss: 0.9992\n",
            "Epoch 81/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.7890 - val_accuracy: 0.6650 - val_loss: 1.0085\n",
            "Epoch 82/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.7987 - val_accuracy: 0.6756 - val_loss: 0.9963\n",
            "Epoch 83/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.7922 - val_accuracy: 0.6708 - val_loss: 0.9948\n",
            "Epoch 84/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.7912 - val_accuracy: 0.6700 - val_loss: 0.9990\n",
            "Epoch 85/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.7924 - val_accuracy: 0.6694 - val_loss: 0.9840\n",
            "Epoch 86/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.7854 - val_accuracy: 0.6758 - val_loss: 0.9931\n",
            "Epoch 87/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.7924 - val_accuracy: 0.6740 - val_loss: 0.9668\n",
            "Epoch 88/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.7924 - val_accuracy: 0.6762 - val_loss: 0.9848\n",
            "Epoch 89/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7954 - val_accuracy: 0.6746 - val_loss: 0.9984\n",
            "Epoch 90/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.7916 - val_accuracy: 0.6726 - val_loss: 0.9990\n",
            "Epoch 91/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.7921 - val_accuracy: 0.6648 - val_loss: 1.0031\n",
            "Epoch 92/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.7940 - val_accuracy: 0.6678 - val_loss: 0.9997\n",
            "Epoch 93/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.7948 - val_accuracy: 0.6692 - val_loss: 0.9858\n",
            "Epoch 94/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.7913 - val_accuracy: 0.6546 - val_loss: 1.0364\n",
            "Epoch 95/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.7903 - val_accuracy: 0.6606 - val_loss: 1.0401\n",
            "Epoch 96/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.7925 - val_accuracy: 0.6688 - val_loss: 1.0007\n",
            "Epoch 97/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.7909 - val_accuracy: 0.6690 - val_loss: 1.0209\n",
            "Epoch 98/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.7934 - val_accuracy: 0.6640 - val_loss: 1.0222\n",
            "Epoch 99/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.7947 - val_accuracy: 0.6696 - val_loss: 1.0067\n",
            "Epoch 100/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.7937 - val_accuracy: 0.6696 - val_loss: 0.9825\n",
            "Epoch 101/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.7977 - val_accuracy: 0.6700 - val_loss: 1.0018\n",
            "Epoch 102/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.7892 - val_accuracy: 0.6714 - val_loss: 1.0054\n",
            "Epoch 103/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.7916 - val_accuracy: 0.6662 - val_loss: 1.0028\n",
            "Epoch 104/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.7898 - val_accuracy: 0.6702 - val_loss: 1.0136\n",
            "Epoch 105/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.7944 - val_accuracy: 0.6650 - val_loss: 1.0195\n",
            "Epoch 106/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.7919 - val_accuracy: 0.6754 - val_loss: 0.9849\n",
            "Epoch 107/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.7893 - val_accuracy: 0.6558 - val_loss: 1.0300\n",
            "Epoch 108/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.7940 - val_accuracy: 0.6664 - val_loss: 1.0050\n",
            "Epoch 109/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.7895 - val_accuracy: 0.6582 - val_loss: 1.0054\n",
            "Epoch 110/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.7850 - val_accuracy: 0.6640 - val_loss: 1.0130\n",
            "Epoch 111/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.7886 - val_accuracy: 0.6646 - val_loss: 0.9921\n",
            "Epoch 112/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7207 - loss: 0.7921 - val_accuracy: 0.6776 - val_loss: 0.9837\n",
            "Epoch 113/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.7897 - val_accuracy: 0.6726 - val_loss: 1.0033\n",
            "Epoch 114/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.7854 - val_accuracy: 0.6722 - val_loss: 0.9867\n",
            "Epoch 115/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.7868 - val_accuracy: 0.6752 - val_loss: 0.9839\n",
            "Epoch 116/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.7890 - val_accuracy: 0.6722 - val_loss: 0.9872\n",
            "Epoch 117/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.7903 - val_accuracy: 0.6726 - val_loss: 0.9953\n",
            "Epoch 118/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.7853 - val_accuracy: 0.6730 - val_loss: 0.9868\n",
            "Epoch 119/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.7856 - val_accuracy: 0.6756 - val_loss: 0.9876\n",
            "Epoch 120/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.7883 - val_accuracy: 0.6696 - val_loss: 0.9992\n",
            "Epoch 121/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.7877 - val_accuracy: 0.6704 - val_loss: 1.0003\n",
            "Epoch 122/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.7881 - val_accuracy: 0.6652 - val_loss: 1.0027\n",
            "Epoch 123/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.7933 - val_accuracy: 0.6750 - val_loss: 0.9915\n",
            "Epoch 124/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.7901 - val_accuracy: 0.6642 - val_loss: 1.0203\n",
            "Epoch 125/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.7911 - val_accuracy: 0.6700 - val_loss: 1.0004\n",
            "Epoch 126/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7254 - loss: 0.7841 - val_accuracy: 0.6720 - val_loss: 0.9888\n",
            "Epoch 127/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.7827 - val_accuracy: 0.6694 - val_loss: 0.9962\n",
            "Epoch 128/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.7825 - val_accuracy: 0.6690 - val_loss: 1.0115\n",
            "Epoch 129/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.7836 - val_accuracy: 0.6708 - val_loss: 0.9952\n",
            "Epoch 130/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.7898 - val_accuracy: 0.6716 - val_loss: 0.9973\n",
            "Epoch 131/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.7873 - val_accuracy: 0.6700 - val_loss: 0.9869\n",
            "Epoch 132/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.7816 - val_accuracy: 0.6680 - val_loss: 0.9828\n",
            "Epoch 133/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.7848 - val_accuracy: 0.6704 - val_loss: 1.0022\n",
            "Epoch 134/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.7875 - val_accuracy: 0.6702 - val_loss: 0.9946\n",
            "Epoch 135/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.7817 - val_accuracy: 0.6752 - val_loss: 1.0028\n",
            "Epoch 136/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.7874 - val_accuracy: 0.6696 - val_loss: 1.0215\n",
            "Epoch 137/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.7866 - val_accuracy: 0.6738 - val_loss: 0.9916\n",
            "Epoch 138/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.7880 - val_accuracy: 0.6680 - val_loss: 1.0117\n",
            "Epoch 139/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.7869 - val_accuracy: 0.6696 - val_loss: 1.0067\n",
            "Epoch 140/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.7837 - val_accuracy: 0.6764 - val_loss: 0.9926\n",
            "Epoch 141/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.7842 - val_accuracy: 0.6668 - val_loss: 0.9978\n",
            "Epoch 142/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.7841 - val_accuracy: 0.6750 - val_loss: 0.9900\n",
            "Epoch 143/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.7857 - val_accuracy: 0.6792 - val_loss: 0.9924\n",
            "Epoch 144/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.7807 - val_accuracy: 0.6600 - val_loss: 1.0403\n",
            "Epoch 145/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.7837 - val_accuracy: 0.6762 - val_loss: 0.9853\n",
            "Epoch 146/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.7844 - val_accuracy: 0.6722 - val_loss: 0.9945\n",
            "Epoch 147/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.7829 - val_accuracy: 0.6732 - val_loss: 0.9874\n",
            "Epoch 148/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.7860 - val_accuracy: 0.6678 - val_loss: 1.0107\n",
            "Epoch 149/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.7778 - val_accuracy: 0.6664 - val_loss: 1.0094\n",
            "Epoch 150/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.7766 - val_accuracy: 0.6730 - val_loss: 1.0137\n",
            "Epoch 151/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.7780 - val_accuracy: 0.6680 - val_loss: 1.0064\n",
            "Epoch 152/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.7874 - val_accuracy: 0.6694 - val_loss: 1.0065\n",
            "Epoch 153/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.7793 - val_accuracy: 0.6746 - val_loss: 1.0088\n",
            "Epoch 154/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.7815 - val_accuracy: 0.6728 - val_loss: 0.9920\n",
            "Epoch 155/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.7812 - val_accuracy: 0.6698 - val_loss: 0.9936\n",
            "Epoch 156/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.7805 - val_accuracy: 0.6610 - val_loss: 1.0385\n",
            "Epoch 157/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.7835 - val_accuracy: 0.6730 - val_loss: 1.0044\n",
            "Epoch 158/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.7847 - val_accuracy: 0.6716 - val_loss: 1.0045\n",
            "Epoch 159/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.7787 - val_accuracy: 0.6742 - val_loss: 0.9914\n",
            "Epoch 160/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.7771 - val_accuracy: 0.6704 - val_loss: 1.0107\n",
            "Epoch 161/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.7776 - val_accuracy: 0.6600 - val_loss: 1.0243\n",
            "Epoch 162/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.7779 - val_accuracy: 0.6754 - val_loss: 0.9895\n",
            "Epoch 163/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.7753 - val_accuracy: 0.6718 - val_loss: 1.0036\n",
            "Epoch 164/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.7783 - val_accuracy: 0.6720 - val_loss: 0.9927\n",
            "Epoch 165/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.7824 - val_accuracy: 0.6670 - val_loss: 1.0130\n",
            "Epoch 166/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.7815 - val_accuracy: 0.6744 - val_loss: 0.9925\n",
            "Epoch 167/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.7776 - val_accuracy: 0.6654 - val_loss: 1.0087\n",
            "Epoch 168/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.7821 - val_accuracy: 0.6714 - val_loss: 1.0053\n",
            "Epoch 169/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.7751 - val_accuracy: 0.6686 - val_loss: 0.9978\n",
            "Epoch 170/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.7795 - val_accuracy: 0.6688 - val_loss: 1.0098\n",
            "Epoch 171/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.7822 - val_accuracy: 0.6682 - val_loss: 0.9986\n",
            "Epoch 172/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.7804 - val_accuracy: 0.6714 - val_loss: 0.9940\n",
            "Epoch 173/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.7810 - val_accuracy: 0.6690 - val_loss: 1.0042\n",
            "Epoch 174/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.7784 - val_accuracy: 0.6670 - val_loss: 1.0063\n",
            "Epoch 175/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 0.7771 - val_accuracy: 0.6708 - val_loss: 0.9999\n",
            "Epoch 176/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.7821 - val_accuracy: 0.6730 - val_loss: 0.9901\n",
            "Epoch 177/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.7819 - val_accuracy: 0.6738 - val_loss: 0.9961\n",
            "Epoch 178/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.7799 - val_accuracy: 0.6670 - val_loss: 1.0121\n",
            "Epoch 179/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 0.7766 - val_accuracy: 0.6650 - val_loss: 1.0255\n",
            "Epoch 180/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.7774 - val_accuracy: 0.6622 - val_loss: 1.0187\n",
            "Epoch 181/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.7790 - val_accuracy: 0.6732 - val_loss: 0.9941\n",
            "Epoch 182/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.7771 - val_accuracy: 0.6728 - val_loss: 1.0066\n",
            "Epoch 183/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.7791 - val_accuracy: 0.6670 - val_loss: 1.0119\n",
            "Epoch 184/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.7796 - val_accuracy: 0.6686 - val_loss: 1.0082\n",
            "Epoch 185/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.7815 - val_accuracy: 0.6666 - val_loss: 1.0080\n",
            "Epoch 186/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.7787 - val_accuracy: 0.6706 - val_loss: 0.9967\n",
            "Epoch 187/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.7771 - val_accuracy: 0.6736 - val_loss: 0.9829\n",
            "Epoch 188/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.7773 - val_accuracy: 0.6714 - val_loss: 1.0014\n",
            "Epoch 189/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.7762 - val_accuracy: 0.6658 - val_loss: 1.0178\n",
            "Epoch 190/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.7756 - val_accuracy: 0.6680 - val_loss: 0.9944\n",
            "Epoch 191/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.7794 - val_accuracy: 0.6708 - val_loss: 0.9986\n",
            "Epoch 192/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.7758 - val_accuracy: 0.6710 - val_loss: 0.9853\n",
            "Epoch 193/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.7693 - val_accuracy: 0.6626 - val_loss: 1.0326\n",
            "Epoch 194/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.7762 - val_accuracy: 0.6768 - val_loss: 0.9936\n",
            "Epoch 195/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.7767 - val_accuracy: 0.6690 - val_loss: 1.0005\n",
            "Epoch 196/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.7711 - val_accuracy: 0.6718 - val_loss: 0.9894\n",
            "Epoch 197/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.7690 - val_accuracy: 0.6734 - val_loss: 1.0091\n",
            "Epoch 198/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.7689 - val_accuracy: 0.6692 - val_loss: 1.0141\n",
            "Epoch 199/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.7798 - val_accuracy: 0.6656 - val_loss: 1.0290\n",
            "Epoch 200/200\n",
            "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.7786 - val_accuracy: 0.6698 - val_loss: 1.0118\n"
          ]
        }
      ],
      "source": [
        "history_aug=model_cifar.fit(\n",
        "    X_augmented, y_augmented,\n",
        "    epochs=200,\n",
        "    batch_size=32,validation_data=(X_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "rBHRuILmysvJ",
        "outputId": "5ded1f90-53d8-4f33-88aa-058561e45208"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['val_accuracy'], label='Baseline Model')\n",
        "plt.plot(history_aug.history['val_accuracy'], label='Augmented Model')\n",
        "plt.title('Validation Accuracy Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNzbht3U02qA"
      },
      "source": [
        "# Self-Supervised Learning via Pretext Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqTLSNQJ1jei"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_f3eYP6zA2G",
        "outputId": "7a259334-e298-46eb-9b6c-4e91d149073e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "(X_train_org, y_train_org), (X_test_org, y_test_org) = datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYhDJuzv2hhp"
      },
      "outputs": [],
      "source": [
        "X_train_label=X_train_org[49500::]\n",
        "X_train=X_train_org[0:49500]\n",
        "y_train_label=y_train_org[49500::]\n",
        "y_train=y_train_org[0:49500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Y8XffX7vZn"
      },
      "outputs": [],
      "source": [
        "#X_train_org = X_train_org.astype('float32') / 255.0\n",
        "X_train_label = X_train_label.astype('float32') / 255.0\n",
        "X_test_org = X_test_org.astype('float32') / 255.0\n",
        "X_train = X_train.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t85Jrql4AiG"
      },
      "outputs": [],
      "source": [
        "#Creating Class 0\n",
        "X_train_class0=X_train\n",
        "y_train_class0 = np.full((X_train.shape[0],),0, dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBThfk0o48tY"
      },
      "outputs": [],
      "source": [
        "#create class 1\n",
        "X_train_class1=np.flip(X_train, axis=1)\n",
        "y_train_class1 = np.ones((X_train.shape[0],), dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb8PlV-S5Gd6"
      },
      "outputs": [],
      "source": [
        "#create class 2\n",
        "X_train_class2=np.rot90(X_train, k=1, axes=(1, 2))\n",
        "y_train_class2 = np.full((X_train.shape[0],), 2, dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKgE3wwS5WjC"
      },
      "outputs": [],
      "source": [
        "#combine classes and labels\n",
        "X_train_pretext=np.concatenate([X_train_class0,X_train_class1,X_train_class2],axis=0)\n",
        "y_train_pretext=np.concatenate([y_train_class0,y_train_class1,y_train_class2],axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEfYnZ8A1q4K"
      },
      "source": [
        "Building Pre_text model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DPAPHrE2T-R"
      },
      "outputs": [],
      "source": [
        "model_pretext = models.Sequential([\n",
        "    layers.Conv2D(10, (5,5), strides=1,activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Conv2D(10,(5,5),strides=1,activation='relu'),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(20, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRqyS6c86pPt"
      },
      "outputs": [],
      "source": [
        "model_pretext.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-Qw8muo6Vhv",
        "outputId": "58cd685e-5fb6-403f-9d48-b4982194d3cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.6392 - loss: 0.7921\n",
            "Epoch 2/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6697 - loss: 0.7410\n",
            "Epoch 3/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6862 - loss: 0.7132\n",
            "Epoch 4/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6960 - loss: 0.6961\n",
            "Epoch 5/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7004 - loss: 0.6854\n",
            "Epoch 6/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7038 - loss: 0.6759\n",
            "Epoch 7/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.6680\n",
            "Epoch 8/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7111 - loss: 0.6588\n",
            "Epoch 9/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.6594\n",
            "Epoch 10/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.6520\n",
            "Epoch 11/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.6469\n",
            "Epoch 12/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6449\n",
            "Epoch 13/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.6413\n",
            "Epoch 14/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.6397\n",
            "Epoch 15/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.6376\n",
            "Epoch 16/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.6348\n",
            "Epoch 17/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.6296\n",
            "Epoch 18/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.6250\n",
            "Epoch 19/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 0.6250\n",
            "Epoch 20/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.6228\n",
            "Epoch 21/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.6209\n",
            "Epoch 22/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7338 - loss: 0.6184\n",
            "Epoch 23/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.6156\n",
            "Epoch 24/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.6187\n",
            "Epoch 25/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.6145\n",
            "Epoch 26/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.6121\n",
            "Epoch 27/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7402 - loss: 0.6082\n",
            "Epoch 28/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.6136\n",
            "Epoch 29/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.6107\n",
            "Epoch 30/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.6109\n",
            "Epoch 31/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.6069\n",
            "Epoch 32/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7381 - loss: 0.6096\n",
            "Epoch 33/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7420 - loss: 0.6055\n",
            "Epoch 34/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7402 - loss: 0.6074\n",
            "Epoch 35/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.6046\n",
            "Epoch 36/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7434 - loss: 0.6040\n",
            "Epoch 37/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7429 - loss: 0.6023\n",
            "Epoch 38/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.6037\n",
            "Epoch 39/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.6051\n",
            "Epoch 40/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7439 - loss: 0.6015\n",
            "Epoch 41/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7442 - loss: 0.5987\n",
            "Epoch 42/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7451 - loss: 0.5999\n",
            "Epoch 43/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.5970\n",
            "Epoch 44/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7460 - loss: 0.5972\n",
            "Epoch 45/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7430 - loss: 0.6005\n",
            "Epoch 46/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 0.5996\n",
            "Epoch 47/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 0.6010\n",
            "Epoch 48/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7456 - loss: 0.5950\n",
            "Epoch 49/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.5940\n",
            "Epoch 50/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7464 - loss: 0.5954\n",
            "Epoch 51/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7459 - loss: 0.5964\n",
            "Epoch 52/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7489 - loss: 0.5939\n",
            "Epoch 53/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7469 - loss: 0.5932\n",
            "Epoch 54/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7455 - loss: 0.5948\n",
            "Epoch 55/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.5962\n",
            "Epoch 56/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7483 - loss: 0.5925\n",
            "Epoch 57/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7477 - loss: 0.5925\n",
            "Epoch 58/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7454 - loss: 0.5957\n",
            "Epoch 59/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7450 - loss: 0.5956\n",
            "Epoch 60/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7474 - loss: 0.5923\n",
            "Epoch 61/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7480 - loss: 0.5934\n",
            "Epoch 62/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7468 - loss: 0.5935\n",
            "Epoch 63/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7492 - loss: 0.5912\n",
            "Epoch 64/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7467 - loss: 0.5942\n",
            "Epoch 65/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7499 - loss: 0.5895\n",
            "Epoch 66/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7507 - loss: 0.5885\n",
            "Epoch 67/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7506 - loss: 0.5897\n",
            "Epoch 68/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.5884\n",
            "Epoch 69/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7482 - loss: 0.5918\n",
            "Epoch 70/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7508 - loss: 0.5886\n",
            "Epoch 71/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.5876\n",
            "Epoch 72/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7494 - loss: 0.5887\n",
            "Epoch 73/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7486 - loss: 0.5889\n",
            "Epoch 74/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7502 - loss: 0.5883\n",
            "Epoch 75/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7510 - loss: 0.5905\n",
            "Epoch 76/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.5857\n",
            "Epoch 77/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7532 - loss: 0.5828\n",
            "Epoch 78/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7513 - loss: 0.5878\n",
            "Epoch 79/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7498 - loss: 0.5869\n",
            "Epoch 80/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7510 - loss: 0.5843\n",
            "Epoch 81/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7511 - loss: 0.5849\n",
            "Epoch 82/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.5873\n",
            "Epoch 83/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7507 - loss: 0.5869\n",
            "Epoch 84/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7498 - loss: 0.5899\n",
            "Epoch 85/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7545 - loss: 0.5833\n",
            "Epoch 86/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7490 - loss: 0.5882\n",
            "Epoch 87/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.5848\n",
            "Epoch 88/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7522 - loss: 0.5824\n",
            "Epoch 89/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7495 - loss: 0.5847\n",
            "Epoch 90/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7488 - loss: 0.5867\n",
            "Epoch 91/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7540 - loss: 0.5835\n",
            "Epoch 92/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7509 - loss: 0.5846\n",
            "Epoch 93/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7539 - loss: 0.5836\n",
            "Epoch 94/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7518 - loss: 0.5843\n",
            "Epoch 95/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7535 - loss: 0.5809\n",
            "Epoch 96/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7510 - loss: 0.5875\n",
            "Epoch 97/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7536 - loss: 0.5813\n",
            "Epoch 98/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7522 - loss: 0.5852\n",
            "Epoch 99/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.5844\n",
            "Epoch 100/100\n",
            "\u001b[1m4641/4641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7514 - loss: 0.5842\n"
          ]
        }
      ],
      "source": [
        "history_pretext = model_pretext.fit(\n",
        "    X_train_pretext, y_train_pretext,\n",
        "    epochs=100,  # Set a high number of epochs; early stopping will terminate if needed\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqp1PKOd_ULT",
        "outputId": "9e4afa03-7e02-4fd1-e047-fe5ab8c5b808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved cifar10_unlabble_trained_model.h5'\n"
          ]
        }
      ],
      "source": [
        "model_pretext.save('cifar10_unlabble_trained_model.h5')\n",
        "\n",
        "print(\"model saved cifar10_unlabble_trained_model.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg-m99tp7xtc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "class baseline(Callback):\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "    test_loss_arr=[]\n",
        "    test_acc=[]\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 100 == 0:  # Check every 100 epochs\n",
        "            X_test, y_test = self.test_data\n",
        "            test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "            self.test_loss_arr.append(test_loss)\n",
        "            self.test_acc.append(test_accuracy)\n",
        "            print(f\"\\nTest accuracy at epoch {epoch + 1}: {test_accuracy * 100:.2f}%\")\n",
        "test_data = (X_test_org, y_test_org)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8loQlfIYSCYf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63TBVdeoR7VN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "class pretrained(Callback):\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "    test_loss_arr_1=[]\n",
        "    test_acc_2=[]\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 100 == 0:  # Check every 100 epochs\n",
        "            X_test, y_test = self.test_data\n",
        "            test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "            self.test_loss_arr_1.append(test_loss)\n",
        "            self.test_acc_2.append(test_accuracy)\n",
        "            print(f\"\\nTest accuracy at epoch {epoch + 1}: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psP0bLgk1wgf"
      },
      "source": [
        "Building Base line model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVJWEyni6I3m",
        "outputId": "740c29b1-e7cc-4269-9c85-df664c5abf3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model_baseline = models.Sequential([\n",
        "    layers.Conv2D(10, (5,5), strides=1,activation='relu', input_shape=(32, 32, 3), kernel_initializer=tf.keras.initializers.HeNormal()),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Conv2D(10,(5,5),strides=1,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal()),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(20, activation='relu',kernel_initializer=tf.keras.initializers.HeNormal()),\n",
        "    layers.Dense(10, activation='softmax',kernel_initializer=tf.keras.initializers.HeNormal())\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7E70RiqD6tb",
        "outputId": "e6172bcd-d028-4f97-beb3-a1aa12bc0d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 7526/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3345e-05 \n",
            "Epoch 7527/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1203e-05 \n",
            "Epoch 7528/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0632e-05 \n",
            "Epoch 7529/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2347e-05 \n",
            "Epoch 7530/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1885e-05 \n",
            "Epoch 7531/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1109e-05 \n",
            "Epoch 7532/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0214e-05 \n",
            "Epoch 7533/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3605e-06 \n",
            "Epoch 7534/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1163e-05 \n",
            "Epoch 7535/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2089e-05 \n",
            "Epoch 7536/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1076e-05 \n",
            "Epoch 7537/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0915e-05 \n",
            "Epoch 7538/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2355e-05 \n",
            "Epoch 7539/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8333e-06 \n",
            "Epoch 7540/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1078e-05 \n",
            "Epoch 7541/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1235e-05 \n",
            "Epoch 7542/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0411e-05 \n",
            "Epoch 7543/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0271e-05 \n",
            "Epoch 7544/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1478e-05 \n",
            "Epoch 7545/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0559e-05 \n",
            "Epoch 7546/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1111e-05 \n",
            "Epoch 7547/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5091e-06 \n",
            "Epoch 7548/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0124e-05 \n",
            "Epoch 7549/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5030e-06 \n",
            "Epoch 7550/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9802e-06 \n",
            "Epoch 7551/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0235e-06 \n",
            "Epoch 7552/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4794e-06 \n",
            "Epoch 7553/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0402e-05 \n",
            "Epoch 7554/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0790e-05 \n",
            "Epoch 7555/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7246e-06 \n",
            "Epoch 7556/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9139e-06 \n",
            "Epoch 7557/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7660e-06 \n",
            "Epoch 7558/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4858e-06 \n",
            "Epoch 7559/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4135e-06 \n",
            "Epoch 7560/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1298e-05 \n",
            "Epoch 7561/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0562e-06 \n",
            "Epoch 7562/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1063e-05 \n",
            "Epoch 7563/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0092e-06 \n",
            "Epoch 7564/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5222e-06 \n",
            "Epoch 7565/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7831e-06 \n",
            "Epoch 7566/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0235e-05 \n",
            "Epoch 7567/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4995e-06 \n",
            "Epoch 7568/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8380e-06 \n",
            "Epoch 7569/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3479e-06 \n",
            "Epoch 7570/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5044e-06 \n",
            "Epoch 7571/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2212e-06 \n",
            "Epoch 7572/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0569e-06 \n",
            "Epoch 7573/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6677e-06 \n",
            "Epoch 7574/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4606e-06 \n",
            "Epoch 7575/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6769e-06 \n",
            "Epoch 7576/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0175e-06 \n",
            "Epoch 7577/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6206e-06 \n",
            "Epoch 7578/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6213e-06 \n",
            "Epoch 7579/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8638e-06 \n",
            "Epoch 7580/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3758e-06 \n",
            "Epoch 7581/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2556e-06 \n",
            "Epoch 7582/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3319e-06 \n",
            "Epoch 7583/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9657e-06 \n",
            "Epoch 7584/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5532e-06 \n",
            "Epoch 7585/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6599e-06 \n",
            "Epoch 7586/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9055e-06 \n",
            "Epoch 7587/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0685e-06 \n",
            "Epoch 7588/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3409e-06 \n",
            "Epoch 7589/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2398e-06 \n",
            "Epoch 7590/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3064e-06 \n",
            "Epoch 7591/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0358e-06 \n",
            "Epoch 7592/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1535e-06 \n",
            "Epoch 7593/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3550e-06 \n",
            "Epoch 7594/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9775e-06 \n",
            "Epoch 7595/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4616e-06 \n",
            "Epoch 7596/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4055e-06 \n",
            "Epoch 7597/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7664e-06 \n",
            "Epoch 7598/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8213e-06 \n",
            "Epoch 7599/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3075e-06 \n",
            "Epoch 7600/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0483e-05\n",
            "Test accuracy at epoch 7600: 31.99%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.3202e-06\n",
            "Epoch 7601/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2183e-06 \n",
            "Epoch 7602/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3264e-06 \n",
            "Epoch 7603/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0669e-06 \n",
            "Epoch 7604/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2613e-06 \n",
            "Epoch 7605/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7709e-06 \n",
            "Epoch 7606/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2630e-06 \n",
            "Epoch 7607/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7534e-06 \n",
            "Epoch 7608/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7138e-06 \n",
            "Epoch 7609/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6073e-06 \n",
            "Epoch 7610/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8265e-06 \n",
            "Epoch 7611/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6610e-06 \n",
            "Epoch 7612/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8281e-06 \n",
            "Epoch 7613/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2636e-06 \n",
            "Epoch 7614/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4324e-06 \n",
            "Epoch 7615/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7436e-06 \n",
            "Epoch 7616/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3128e-06 \n",
            "Epoch 7617/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6164e-06 \n",
            "Epoch 7618/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2729e-06 \n",
            "Epoch 7619/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0856e-06 \n",
            "Epoch 7620/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9134e-06 \n",
            "Epoch 7621/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2778e-06 \n",
            "Epoch 7622/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0781e-06 \n",
            "Epoch 7623/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8719e-06 \n",
            "Epoch 7624/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4642e-06 \n",
            "Epoch 7625/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6055e-06 \n",
            "Epoch 7626/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0530e-06 \n",
            "Epoch 7627/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4059e-06 \n",
            "Epoch 7628/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5516e-06 \n",
            "Epoch 7629/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7958e-06 \n",
            "Epoch 7630/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0516e-06 \n",
            "Epoch 7631/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8725e-06 \n",
            "Epoch 7632/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6917e-06 \n",
            "Epoch 7633/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9100e-06 \n",
            "Epoch 7634/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2360e-06 \n",
            "Epoch 7635/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0712e-06 \n",
            "Epoch 7636/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0475e-06 \n",
            "Epoch 7637/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2083e-06 \n",
            "Epoch 7638/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8927e-06 \n",
            "Epoch 7639/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4216e-06 \n",
            "Epoch 7640/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7890e-06 \n",
            "Epoch 7641/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1427e-06 \n",
            "Epoch 7642/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9035e-06 \n",
            "Epoch 7643/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3074e-06  \n",
            "Epoch 7644/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2513e-06 \n",
            "Epoch 7645/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6614e-06 \n",
            "Epoch 7646/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4127e-06 \n",
            "Epoch 7647/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1348e-06 \n",
            "Epoch 7648/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3950e-06 \n",
            "Epoch 7649/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9695e-06 \n",
            "Epoch 7650/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6964e-06 \n",
            "Epoch 7651/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8493e-06 \n",
            "Epoch 7652/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9698e-06 \n",
            "Epoch 7653/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1742e-06 \n",
            "Epoch 7654/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8011e-06 \n",
            "Epoch 7655/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2781e-06 \n",
            "Epoch 7656/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5959e-06 \n",
            "Epoch 7657/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5465e-06 \n",
            "Epoch 7658/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2212e-06 \n",
            "Epoch 7659/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2585e-06 \n",
            "Epoch 7660/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1569e-06 \n",
            "Epoch 7661/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6155e-06 \n",
            "Epoch 7662/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4858e-06 \n",
            "Epoch 7663/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1729e-06 \n",
            "Epoch 7664/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9393e-06 \n",
            "Epoch 7665/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2497e-06 \n",
            "Epoch 7666/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9165e-06 \n",
            "Epoch 7667/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1687e-06 \n",
            "Epoch 7668/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7623e-06 \n",
            "Epoch 7669/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7215e-06 \n",
            "Epoch 7670/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0252e-06 \n",
            "Epoch 7671/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5790e-06 \n",
            "Epoch 7672/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8254e-06 \n",
            "Epoch 7673/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6289e-06 \n",
            "Epoch 7674/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5299e-06 \n",
            "Epoch 7675/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9239e-06 \n",
            "Epoch 7676/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8736e-06 \n",
            "Epoch 7677/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1112e-06 \n",
            "Epoch 7678/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6612e-06 \n",
            "Epoch 7679/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3077e-06 \n",
            "Epoch 7680/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2230e-06 \n",
            "Epoch 7681/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5010e-06 \n",
            "Epoch 7682/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1648e-06 \n",
            "Epoch 7683/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1550e-06 \n",
            "Epoch 7684/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7374e-06 \n",
            "Epoch 7685/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8163e-06 \n",
            "Epoch 7686/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3270e-06 \n",
            "Epoch 7687/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9786e-06 \n",
            "Epoch 7688/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3353e-06 \n",
            "Epoch 7689/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4702e-06 \n",
            "Epoch 7690/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4164e-06 \n",
            "Epoch 7691/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1719e-06 \n",
            "Epoch 7692/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1257e-06 \n",
            "Epoch 7693/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6634e-06 \n",
            "Epoch 7694/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6672e-06 \n",
            "Epoch 7695/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4023e-06 \n",
            "Epoch 7696/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9026e-06 \n",
            "Epoch 7697/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3240e-06 \n",
            "Epoch 7698/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8831e-06 \n",
            "Epoch 7699/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0266e-06 \n",
            "Epoch 7700/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.2728e-06\n",
            "Test accuracy at epoch 7700: 32.07%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.0261e-06\n",
            "Epoch 7701/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2307e-06 \n",
            "Epoch 7702/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0006e-06 \n",
            "Epoch 7703/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2556e-06 \n",
            "Epoch 7704/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6859e-06 \n",
            "Epoch 7705/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0306e-06 \n",
            "Epoch 7706/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0465e-06 \n",
            "Epoch 7707/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7448e-06 \n",
            "Epoch 7708/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0030e-06 \n",
            "Epoch 7709/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9460e-06 \n",
            "Epoch 7710/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8775e-06 \n",
            "Epoch 7711/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6970e-06 \n",
            "Epoch 7712/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8223e-06 \n",
            "Epoch 7713/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1364e-06 \n",
            "Epoch 7714/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0833e-06 \n",
            "Epoch 7715/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3205e-06 \n",
            "Epoch 7716/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1095e-06 \n",
            "Epoch 7717/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6446e-06 \n",
            "Epoch 7718/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5168e-06 \n",
            "Epoch 7719/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7235e-06 \n",
            "Epoch 7720/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8226e-06 \n",
            "Epoch 7721/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0883e-06 \n",
            "Epoch 7722/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8719e-06 \n",
            "Epoch 7723/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7296e-06 \n",
            "Epoch 7724/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6785e-06 \n",
            "Epoch 7725/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8181e-06 \n",
            "Epoch 7726/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5378e-06 \n",
            "Epoch 7727/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3794e-06 \n",
            "Epoch 7728/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8472e-06 \n",
            "Epoch 7729/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0596e-06 \n",
            "Epoch 7730/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8033e-06 \n",
            "Epoch 7731/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8690e-06 \n",
            "Epoch 7732/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9896e-06 \n",
            "Epoch 7733/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4797e-06 \n",
            "Epoch 7734/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4345e-06 \n",
            "Epoch 7735/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5588e-06 \n",
            "Epoch 7736/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3218e-06 \n",
            "Epoch 7737/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4471e-06 \n",
            "Epoch 7738/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5447e-06 \n",
            "Epoch 7739/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3040e-06 \n",
            "Epoch 7740/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1627e-06 \n",
            "Epoch 7741/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6967e-06 \n",
            "Epoch 7742/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4966e-06 \n",
            "Epoch 7743/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9855e-06 \n",
            "Epoch 7744/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6295e-06 \n",
            "Epoch 7745/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0783e-06 \n",
            "Epoch 7746/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4193e-06 \n",
            "Epoch 7747/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4536e-06 \n",
            "Epoch 7748/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2743e-06 \n",
            "Epoch 7749/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6376e-06 \n",
            "Epoch 7750/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0966e-06 \n",
            "Epoch 7751/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6497e-06 \n",
            "Epoch 7752/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1805e-06 \n",
            "Epoch 7753/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1005e-06 \n",
            "Epoch 7754/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2103e-06 \n",
            "Epoch 7755/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1999e-06 \n",
            "Epoch 7756/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2427e-06 \n",
            "Epoch 7757/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1356e-06 \n",
            "Epoch 7758/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2464e-06 \n",
            "Epoch 7759/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1375e-06 \n",
            "Epoch 7760/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2817e-06 \n",
            "Epoch 7761/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1515e-06 \n",
            "Epoch 7762/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0532e-06 \n",
            "Epoch 7763/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1295e-06 \n",
            "Epoch 7764/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2996e-06 \n",
            "Epoch 7765/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8148e-06 \n",
            "Epoch 7766/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2445e-06 \n",
            "Epoch 7767/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8725e-06 \n",
            "Epoch 7768/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8566e-06 \n",
            "Epoch 7769/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2243e-06 \n",
            "Epoch 7770/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2108e-06 \n",
            "Epoch 7771/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9263e-06 \n",
            "Epoch 7772/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6970e-06 \n",
            "Epoch 7773/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7889e-06 \n",
            "Epoch 7774/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9392e-06 \n",
            "Epoch 7775/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9562e-06 \n",
            "Epoch 7776/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7530e-06 \n",
            "Epoch 7777/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9669e-06 \n",
            "Epoch 7778/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6338e-06 \n",
            "Epoch 7779/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4850e-06 \n",
            "Epoch 7780/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7924e-06 \n",
            "Epoch 7781/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8384e-06 \n",
            "Epoch 7782/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7590e-06 \n",
            "Epoch 7783/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7443e-06 \n",
            "Epoch 7784/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5692e-06 \n",
            "Epoch 7785/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8194e-06 \n",
            "Epoch 7786/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8341e-06 \n",
            "Epoch 7787/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6612e-06 \n",
            "Epoch 7788/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4689e-06 \n",
            "Epoch 7789/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5961e-06 \n",
            "Epoch 7790/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7754e-06 \n",
            "Epoch 7791/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7285e-06 \n",
            "Epoch 7792/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9316e-06 \n",
            "Epoch 7793/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6371e-06 \n",
            "Epoch 7794/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4188e-06 \n",
            "Epoch 7795/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6311e-06 \n",
            "Epoch 7796/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7242e-06 \n",
            "Epoch 7797/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3739e-06 \n",
            "Epoch 7798/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4393e-06 \n",
            "Epoch 7799/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4941e-06 \n",
            "Epoch 7800/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0096e-06\n",
            "Test accuracy at epoch 7800: 32.19%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.5984e-06\n",
            "Epoch 7801/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7276e-06 \n",
            "Epoch 7802/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6716e-06 \n",
            "Epoch 7803/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3651e-06 \n",
            "Epoch 7804/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6802e-06 \n",
            "Epoch 7805/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3639e-06 \n",
            "Epoch 7806/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4594e-06 \n",
            "Epoch 7807/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7913e-06 \n",
            "Epoch 7808/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3507e-06 \n",
            "Epoch 7809/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4974e-06 \n",
            "Epoch 7810/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3741e-06 \n",
            "Epoch 7811/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4485e-06 \n",
            "Epoch 7812/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2995e-06 \n",
            "Epoch 7813/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3499e-06 \n",
            "Epoch 7814/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2710e-06 \n",
            "Epoch 7815/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4467e-06 \n",
            "Epoch 7816/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1482e-06 \n",
            "Epoch 7817/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3533e-06 \n",
            "Epoch 7818/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4125e-06 \n",
            "Epoch 7819/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2387e-06 \n",
            "Epoch 7820/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5162e-06 \n",
            "Epoch 7821/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2933e-06 \n",
            "Epoch 7822/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2977e-06 \n",
            "Epoch 7823/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2992e-06 \n",
            "Epoch 7824/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3089e-06 \n",
            "Epoch 7825/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1541e-06 \n",
            "Epoch 7826/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4110e-06 \n",
            "Epoch 7827/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0687e-06 \n",
            "Epoch 7828/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2772e-06 \n",
            "Epoch 7829/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2074e-06 \n",
            "Epoch 7830/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3189e-06 \n",
            "Epoch 7831/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1638e-06 \n",
            "Epoch 7832/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3970e-06 \n",
            "Epoch 7833/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2265e-06 \n",
            "Epoch 7834/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2349e-06 \n",
            "Epoch 7835/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1282e-06 \n",
            "Epoch 7836/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3044e-06 \n",
            "Epoch 7837/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1723e-06 \n",
            "Epoch 7838/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1800e-06 \n",
            "Epoch 7839/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3374e-06 \n",
            "Epoch 7840/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1521e-06 \n",
            "Epoch 7841/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2152e-06 \n",
            "Epoch 7842/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4913e-07 \n",
            "Epoch 7843/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1653e-06 \n",
            "Epoch 7844/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1604e-06 \n",
            "Epoch 7845/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0086e-06 \n",
            "Epoch 7846/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1057e-06 \n",
            "Epoch 7847/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0718e-06 \n",
            "Epoch 7848/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2516e-06 \n",
            "Epoch 7849/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0387e-06 \n",
            "Epoch 7850/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0310e-06 \n",
            "Epoch 7851/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0336e-06 \n",
            "Epoch 7852/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0477e-06 \n",
            "Epoch 7853/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0936e-06 \n",
            "Epoch 7854/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0151e-06 \n",
            "Epoch 7855/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9015e-07 \n",
            "Epoch 7856/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1655e-06 \n",
            "Epoch 7857/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0786e-06 \n",
            "Epoch 7858/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4621e-07 \n",
            "Epoch 7859/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6372e-07 \n",
            "Epoch 7860/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8170e-07 \n",
            "Epoch 7861/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1124e-06 \n",
            "Epoch 7862/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8115e-07 \n",
            "Epoch 7863/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6306e-07 \n",
            "Epoch 7864/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2600e-07 \n",
            "Epoch 7865/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5554e-07 \n",
            "Epoch 7866/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8507e-07 \n",
            "Epoch 7867/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6063e-07 \n",
            "Epoch 7868/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7418e-07 \n",
            "Epoch 7869/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6381e-07 \n",
            "Epoch 7870/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8942e-07 \n",
            "Epoch 7871/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0229e-06 \n",
            "Epoch 7872/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0859e-07 \n",
            "Epoch 7873/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5978e-07 \n",
            "Epoch 7874/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0670e-07 \n",
            "Epoch 7875/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4032e-07 \n",
            "Epoch 7876/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6031e-07 \n",
            "Epoch 7877/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1218e-07 \n",
            "Epoch 7878/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8518e-07 \n",
            "Epoch 7879/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6007e-07 \n",
            "Epoch 7880/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6239e-07 \n",
            "Epoch 7881/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1056e-07 \n",
            "Epoch 7882/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0528e-07 \n",
            "Epoch 7883/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5459e-07 \n",
            "Epoch 7884/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8822e-07 \n",
            "Epoch 7885/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5965e-07 \n",
            "Epoch 7886/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4329e-07 \n",
            "Epoch 7887/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0910e-07 \n",
            "Epoch 7888/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0545e-07 \n",
            "Epoch 7889/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8544e-07 \n",
            "Epoch 7890/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0993e-07 \n",
            "Epoch 7891/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7297e-07 \n",
            "Epoch 7892/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6112e-07 \n",
            "Epoch 7893/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7717e-07 \n",
            "Epoch 7894/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0706e-07 \n",
            "Epoch 7895/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1746e-07 \n",
            "Epoch 7896/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0285e-07 \n",
            "Epoch 7897/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7505e-07 \n",
            "Epoch 7898/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2387e-07 \n",
            "Epoch 7899/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6978e-07 \n",
            "Epoch 7900/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.9861e-07\n",
            "Test accuracy at epoch 7900: 32.40%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.2230e-07\n",
            "Epoch 7901/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6327e-07 \n",
            "Epoch 7902/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4045e-07 \n",
            "Epoch 7903/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7504e-07 \n",
            "Epoch 7904/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6919e-07 \n",
            "Epoch 7905/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5259e-07 \n",
            "Epoch 7906/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4522e-07 \n",
            "Epoch 7907/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3849e-07 \n",
            "Epoch 7908/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5014e-07 \n",
            "Epoch 7909/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1538e-07 \n",
            "Epoch 7910/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2003e-07 \n",
            "Epoch 7911/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7367e-07 \n",
            "Epoch 7912/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8975e-07 \n",
            "Epoch 7913/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6344e-07 \n",
            "Epoch 7914/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0562e-07 \n",
            "Epoch 7915/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2058e-07 \n",
            "Epoch 7916/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1281e-07 \n",
            "Epoch 7917/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3771e-07 \n",
            "Epoch 7918/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1824e-07 \n",
            "Epoch 7919/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7413e-07 \n",
            "Epoch 7920/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2580e-07 \n",
            "Epoch 7921/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1639e-07 \n",
            "Epoch 7922/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7909e-07 \n",
            "Epoch 7923/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0170e-07 \n",
            "Epoch 7924/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4822e-07 \n",
            "Epoch 7925/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8306e-07 \n",
            "Epoch 7926/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6596e-07 \n",
            "Epoch 7927/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9503e-07 \n",
            "Epoch 7928/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9639e-07 \n",
            "Epoch 7929/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0450e-07 \n",
            "Epoch 7930/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5659e-07 \n",
            "Epoch 7931/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9702e-07 \n",
            "Epoch 7932/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4046e-07 \n",
            "Epoch 7933/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0855e-07 \n",
            "Epoch 7934/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2485e-07 \n",
            "Epoch 7935/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5755e-07 \n",
            "Epoch 7936/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9082e-07 \n",
            "Epoch 7937/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8136e-07 \n",
            "Epoch 7938/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5618e-07 \n",
            "Epoch 7939/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7271e-07 \n",
            "Epoch 7940/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3717e-07 \n",
            "Epoch 7941/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3788e-07 \n",
            "Epoch 7942/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3324e-07 \n",
            "Epoch 7943/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1969e-07 \n",
            "Epoch 7944/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7564e-07 \n",
            "Epoch 7945/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5452e-07 \n",
            "Epoch 7946/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6332e-07 \n",
            "Epoch 7947/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6909e-07 \n",
            "Epoch 7948/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5678e-07 \n",
            "Epoch 7949/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0271e-07 \n",
            "Epoch 7950/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8221e-07 \n",
            "Epoch 7951/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8161e-07 \n",
            "Epoch 7952/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8168e-07 \n",
            "Epoch 7953/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6689e-07 \n",
            "Epoch 7954/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7250e-07 \n",
            "Epoch 7955/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7267e-07 \n",
            "Epoch 7956/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1892e-07 \n",
            "Epoch 7957/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7287e-07 \n",
            "Epoch 7958/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6200e-07 \n",
            "Epoch 7959/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1831e-07 \n",
            "Epoch 7960/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4396e-07 \n",
            "Epoch 7961/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8522e-07 \n",
            "Epoch 7962/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3738e-07 \n",
            "Epoch 7963/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2995e-07 \n",
            "Epoch 7964/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0266e-07 \n",
            "Epoch 7965/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3180e-07 \n",
            "Epoch 7966/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5157e-07 \n",
            "Epoch 7967/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7746e-07 \n",
            "Epoch 7968/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1674e-07 \n",
            "Epoch 7969/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1180e-07 \n",
            "Epoch 7970/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0215e-07 \n",
            "Epoch 7971/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1154e-07 \n",
            "Epoch 7972/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7994e-07 \n",
            "Epoch 7973/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2080e-07 \n",
            "Epoch 7974/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4273e-07 \n",
            "Epoch 7975/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2913e-07 \n",
            "Epoch 7976/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7892e-07 \n",
            "Epoch 7977/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3402e-07 \n",
            "Epoch 7978/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7130e-07 \n",
            "Epoch 7979/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8284e-07 \n",
            "Epoch 7980/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3504e-07 \n",
            "Epoch 7981/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1078e-07 \n",
            "Epoch 7982/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5097e-07 \n",
            "Epoch 7983/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4917e-07 \n",
            "Epoch 7984/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6411e-07 \n",
            "Epoch 7985/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6646e-07 \n",
            "Epoch 7986/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0857e-07 \n",
            "Epoch 7987/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4974e-07 \n",
            "Epoch 7988/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9659e-07 \n",
            "Epoch 7989/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4094e-07 \n",
            "Epoch 7990/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3460e-07 \n",
            "Epoch 7991/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7095e-07 \n",
            "Epoch 7992/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5598e-07 \n",
            "Epoch 7993/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1730e-07 \n",
            "Epoch 7994/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1606e-07 \n",
            "Epoch 7995/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6239e-07 \n",
            "Epoch 7996/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0641e-07 \n",
            "Epoch 7997/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2994e-07 \n",
            "Epoch 7998/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0847e-07 \n",
            "Epoch 7999/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8199e-07 \n",
            "Epoch 8000/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.5704e-07\n",
            "Test accuracy at epoch 8000: 32.68%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.1738e-07\n",
            "Epoch 8001/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4742e-07 \n",
            "Epoch 8002/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0383e-07 \n",
            "Epoch 8003/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5798e-07 \n",
            "Epoch 8004/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2304e-07 \n",
            "Epoch 8005/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6409e-07 \n",
            "Epoch 8006/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9255e-07 \n",
            "Epoch 8007/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0882e-07 \n",
            "Epoch 8008/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4725e-07 \n",
            "Epoch 8009/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8539e-07 \n",
            "Epoch 8010/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3066e-07 \n",
            "Epoch 8011/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9006e-07 \n",
            "Epoch 8012/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1633e-07 \n",
            "Epoch 8013/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3240e-07 \n",
            "Epoch 8014/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9363e-07 \n",
            "Epoch 8015/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3979e-07 \n",
            "Epoch 8016/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9824e-07 \n",
            "Epoch 8017/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7309e-07 \n",
            "Epoch 8018/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0033e-07 \n",
            "Epoch 8019/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4071e-07 \n",
            "Epoch 8020/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6375e-07 \n",
            "Epoch 8021/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8360e-07 \n",
            "Epoch 8022/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7476e-07 \n",
            "Epoch 8023/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3404e-07 \n",
            "Epoch 8024/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2015e-07 \n",
            "Epoch 8025/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6905e-07 \n",
            "Epoch 8026/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5960e-07 \n",
            "Epoch 8027/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5699e-07 \n",
            "Epoch 8028/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6712e-07 \n",
            "Epoch 8029/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3330e-07 \n",
            "Epoch 8030/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3853e-07 \n",
            "Epoch 8031/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2130e-07 \n",
            "Epoch 8032/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4984e-07 \n",
            "Epoch 8033/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5793e-07 \n",
            "Epoch 8034/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4572e-07 \n",
            "Epoch 8035/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5899e-07 \n",
            "Epoch 8036/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1724e-07 \n",
            "Epoch 8037/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4065e-07 \n",
            "Epoch 8038/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0183e-07 \n",
            "Epoch 8039/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0913e-07 \n",
            "Epoch 8040/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8382e-07 \n",
            "Epoch 8041/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0357e-07 \n",
            "Epoch 8042/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3704e-07 \n",
            "Epoch 8043/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1692e-07 \n",
            "Epoch 8044/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4161e-07 \n",
            "Epoch 8045/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8994e-07 \n",
            "Epoch 8046/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4417e-07 \n",
            "Epoch 8047/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0297e-07 \n",
            "Epoch 8048/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3016e-07 \n",
            "Epoch 8049/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4129e-07 \n",
            "Epoch 8050/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8890e-07 \n",
            "Epoch 8051/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2363e-07 \n",
            "Epoch 8052/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4852e-07 \n",
            "Epoch 8053/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0507e-07 \n",
            "Epoch 8054/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1752e-07 \n",
            "Epoch 8055/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1553e-07 \n",
            "Epoch 8056/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8610e-07 \n",
            "Epoch 8057/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9391e-07 \n",
            "Epoch 8058/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1768e-07 \n",
            "Epoch 8059/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9047e-07 \n",
            "Epoch 8060/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0030e-07 \n",
            "Epoch 8061/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9754e-07 \n",
            "Epoch 8062/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9129e-07 \n",
            "Epoch 8063/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1413e-07 \n",
            "Epoch 8064/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0048e-07 \n",
            "Epoch 8065/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6073e-07 \n",
            "Epoch 8066/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7435e-07 \n",
            "Epoch 8067/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8648e-07 \n",
            "Epoch 8068/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8754e-07 \n",
            "Epoch 8069/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8238e-07 \n",
            "Epoch 8070/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8194e-07 \n",
            "Epoch 8071/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9328e-07 \n",
            "Epoch 8072/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7064e-07 \n",
            "Epoch 8073/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6958e-07 \n",
            "Epoch 8074/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8489e-07 \n",
            "Epoch 8075/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6290e-07 \n",
            "Epoch 8076/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8841e-07 \n",
            "Epoch 8077/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9323e-07 \n",
            "Epoch 8078/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7866e-07 \n",
            "Epoch 8079/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6495e-07 \n",
            "Epoch 8080/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7001e-07 \n",
            "Epoch 8081/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5870e-07 \n",
            "Epoch 8082/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5764e-07 \n",
            "Epoch 8083/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5695e-07 \n",
            "Epoch 8084/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7595e-07 \n",
            "Epoch 8085/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7105e-07 \n",
            "Epoch 8086/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6402e-07 \n",
            "Epoch 8087/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6389e-07 \n",
            "Epoch 8088/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7305e-07 \n",
            "Epoch 8089/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4239e-07 \n",
            "Epoch 8090/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4295e-07 \n",
            "Epoch 8091/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2155e-07 \n",
            "Epoch 8092/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6097e-07 \n",
            "Epoch 8093/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7165e-07 \n",
            "Epoch 8094/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2609e-07 \n",
            "Epoch 8095/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6450e-07 \n",
            "Epoch 8096/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3760e-07 \n",
            "Epoch 8097/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2983e-07 \n",
            "Epoch 8098/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1890e-07 \n",
            "Epoch 8099/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4290e-07 \n",
            "Epoch 8100/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.9372e-07\n",
            "Test accuracy at epoch 8100: 32.74%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.3492e-07\n",
            "Epoch 8101/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4053e-07 \n",
            "Epoch 8102/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3927e-07 \n",
            "Epoch 8103/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2159e-07 \n",
            "Epoch 8104/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3500e-07 \n",
            "Epoch 8105/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4332e-07 \n",
            "Epoch 8106/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3059e-07 \n",
            "Epoch 8107/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5197e-07 \n",
            "Epoch 8108/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1469e-07 \n",
            "Epoch 8109/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3330e-07 \n",
            "Epoch 8110/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1928e-07 \n",
            "Epoch 8111/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5369e-07 \n",
            "Epoch 8112/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1611e-07 \n",
            "Epoch 8113/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3964e-07 \n",
            "Epoch 8114/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2014e-07 \n",
            "Epoch 8115/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2148e-07 \n",
            "Epoch 8116/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0863e-07 \n",
            "Epoch 8117/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9627e-08 \n",
            "Epoch 8118/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2030e-07 \n",
            "Epoch 8119/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0445e-07 \n",
            "Epoch 8120/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0681e-07 \n",
            "Epoch 8121/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0387e-07 \n",
            "Epoch 8122/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1689e-07 \n",
            "Epoch 8123/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2519e-07 \n",
            "Epoch 8124/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1447e-07 \n",
            "Epoch 8125/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6208e-08 \n",
            "Epoch 8126/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2193e-07 \n",
            "Epoch 8127/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1577e-07 \n",
            "Epoch 8128/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6464e-08 \n",
            "Epoch 8129/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9582e-08 \n",
            "Epoch 8130/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0163e-07 \n",
            "Epoch 8131/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0616e-07 \n",
            "Epoch 8132/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2617e-08 \n",
            "Epoch 8133/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0446e-07 \n",
            "Epoch 8134/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0249e-07 \n",
            "Epoch 8135/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0073e-07 \n",
            "Epoch 8136/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1614e-07 \n",
            "Epoch 8137/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0565e-07 \n",
            "Epoch 8138/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1054e-08 \n",
            "Epoch 8139/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0336e-07 \n",
            "Epoch 8140/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8369e-08 \n",
            "Epoch 8141/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3048e-08 \n",
            "Epoch 8142/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5135e-08 \n",
            "Epoch 8143/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4377e-08 \n",
            "Epoch 8144/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8766e-08 \n",
            "Epoch 8145/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6820e-08 \n",
            "Epoch 8146/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4801e-08 \n",
            "Epoch 8147/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6249e-08 \n",
            "Epoch 8148/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7113e-08 \n",
            "Epoch 8149/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5128e-08 \n",
            "Epoch 8150/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1399e-08 \n",
            "Epoch 8151/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9010e-08 \n",
            "Epoch 8152/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1346e-08 \n",
            "Epoch 8153/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6528e-08 \n",
            "Epoch 8154/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6764e-08 \n",
            "Epoch 8155/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2113e-08 \n",
            "Epoch 8156/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7584e-08 \n",
            "Epoch 8157/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0752e-08 \n",
            "Epoch 8158/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2782e-08 \n",
            "Epoch 8159/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5788e-08 \n",
            "Epoch 8160/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3755e-08 \n",
            "Epoch 8161/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3038e-08 \n",
            "Epoch 8162/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4383e-08 \n",
            "Epoch 8163/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5949e-08 \n",
            "Epoch 8164/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0450e-08 \n",
            "Epoch 8165/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2299e-08 \n",
            "Epoch 8166/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5859e-08 \n",
            "Epoch 8167/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3262e-08 \n",
            "Epoch 8168/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7547e-08 \n",
            "Epoch 8169/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1345e-08 \n",
            "Epoch 8170/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5538e-08 \n",
            "Epoch 8171/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6760e-08 \n",
            "Epoch 8172/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6894e-08 \n",
            "Epoch 8173/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1936e-08 \n",
            "Epoch 8174/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3551e-08 \n",
            "Epoch 8175/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1668e-08 \n",
            "Epoch 8176/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3037e-08 \n",
            "Epoch 8177/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7658e-08 \n",
            "Epoch 8178/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0326e-08 \n",
            "Epoch 8179/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9840e-08 \n",
            "Epoch 8180/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3907e-08 \n",
            "Epoch 8181/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1783e-08 \n",
            "Epoch 8182/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6174e-08 \n",
            "Epoch 8183/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4194e-08 \n",
            "Epoch 8184/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2570e-08 \n",
            "Epoch 8185/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0737e-08 \n",
            "Epoch 8186/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1729e-08 \n",
            "Epoch 8187/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0373e-08 \n",
            "Epoch 8188/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4839e-08 \n",
            "Epoch 8189/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2384e-08 \n",
            "Epoch 8190/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7183e-08 \n",
            "Epoch 8191/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9268e-08 \n",
            "Epoch 8192/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7513e-08 \n",
            "Epoch 8193/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9839e-08 \n",
            "Epoch 8194/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2329e-08 \n",
            "Epoch 8195/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4621e-08 \n",
            "Epoch 8196/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1332e-08 \n",
            "Epoch 8197/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9176e-08 \n",
            "Epoch 8198/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5823e-08 \n",
            "Epoch 8199/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3304e-08 \n",
            "Epoch 8200/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.4703e-08\n",
            "Test accuracy at epoch 8200: 32.71%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.2067e-08\n",
            "Epoch 8201/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3930e-08 \n",
            "Epoch 8202/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8406e-08 \n",
            "Epoch 8203/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6557e-08 \n",
            "Epoch 8204/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6747e-08 \n",
            "Epoch 8205/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7529e-08 \n",
            "Epoch 8206/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9246e-08 \n",
            "Epoch 8207/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0133e-08 \n",
            "Epoch 8208/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3365e-08 \n",
            "Epoch 8209/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7862e-08 \n",
            "Epoch 8210/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8909e-08 \n",
            "Epoch 8211/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7636e-08 \n",
            "Epoch 8212/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3162e-08 \n",
            "Epoch 8213/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7700e-08 \n",
            "Epoch 8214/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9017e-08 \n",
            "Epoch 8215/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3620e-08 \n",
            "Epoch 8216/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5567e-08 \n",
            "Epoch 8217/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8638e-08 \n",
            "Epoch 8218/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6142e-08 \n",
            "Epoch 8219/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3829e-08 \n",
            "Epoch 8220/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3913e-08 \n",
            "Epoch 8221/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9423e-08 \n",
            "Epoch 8222/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3338e-08 \n",
            "Epoch 8223/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0041e-08 \n",
            "Epoch 8224/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9712e-08 \n",
            "Epoch 8225/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4952e-08 \n",
            "Epoch 8226/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7180e-08 \n",
            "Epoch 8227/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5418e-08 \n",
            "Epoch 8228/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0791e-08 \n",
            "Epoch 8229/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4456e-08 \n",
            "Epoch 8230/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2662e-08 \n",
            "Epoch 8231/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2322e-08 \n",
            "Epoch 8232/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4765e-08 \n",
            "Epoch 8233/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2954e-08 \n",
            "Epoch 8234/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3616e-08 \n",
            "Epoch 8235/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7937e-08 \n",
            "Epoch 8236/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2447e-08 \n",
            "Epoch 8237/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8289e-08 \n",
            "Epoch 8238/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4594e-08 \n",
            "Epoch 8239/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8700e-08 \n",
            "Epoch 8240/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8000e-08 \n",
            "Epoch 8241/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3247e-08 \n",
            "Epoch 8242/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2310e-08 \n",
            "Epoch 8243/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6209e-08 \n",
            "Epoch 8244/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3070e-08 \n",
            "Epoch 8245/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8080e-08 \n",
            "Epoch 8246/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1395e-08 \n",
            "Epoch 8247/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4923e-08 \n",
            "Epoch 8248/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8270e-08 \n",
            "Epoch 8249/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6367e-08 \n",
            "Epoch 8250/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7621e-08 \n",
            "Epoch 8251/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1191e-08 \n",
            "Epoch 8252/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1356e-08 \n",
            "Epoch 8253/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8643e-08 \n",
            "Epoch 8254/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5087e-08 \n",
            "Epoch 8255/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8861e-08 \n",
            "Epoch 8256/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8865e-08 \n",
            "Epoch 8257/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7332e-08 \n",
            "Epoch 8258/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7513e-08 \n",
            "Epoch 8259/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0204e-08 \n",
            "Epoch 8260/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0520e-08 \n",
            "Epoch 8261/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8617e-08 \n",
            "Epoch 8262/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0179e-08 \n",
            "Epoch 8263/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5405e-08 \n",
            "Epoch 8264/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6554e-08 \n",
            "Epoch 8265/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9635e-08 \n",
            "Epoch 8266/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9409e-08 \n",
            "Epoch 8267/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7188e-08 \n",
            "Epoch 8268/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4077e-08 \n",
            "Epoch 8269/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1852e-08 \n",
            "Epoch 8270/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3653e-08 \n",
            "Epoch 8271/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3787e-08 \n",
            "Epoch 8272/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0736e-08 \n",
            "Epoch 8273/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3400e-08 \n",
            "Epoch 8274/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4598e-08 \n",
            "Epoch 8275/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8150e-08 \n",
            "Epoch 8276/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3430e-08 \n",
            "Epoch 8277/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9764e-08 \n",
            "Epoch 8278/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6693e-08 \n",
            "Epoch 8279/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4452e-08 \n",
            "Epoch 8280/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3737e-08 \n",
            "Epoch 8281/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3672e-08 \n",
            "Epoch 8282/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1999e-08 \n",
            "Epoch 8283/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8171e-08 \n",
            "Epoch 8284/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5214e-08 \n",
            "Epoch 8285/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2685e-08 \n",
            "Epoch 8286/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1194e-08 \n",
            "Epoch 8287/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0696e-08 \n",
            "Epoch 8288/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1792e-08 \n",
            "Epoch 8289/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6379e-08 \n",
            "Epoch 8290/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1975e-08 \n",
            "Epoch 8291/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0404e-08 \n",
            "Epoch 8292/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0081e-08 \n",
            "Epoch 8293/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4906e-08 \n",
            "Epoch 8294/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0323e-08 \n",
            "Epoch 8295/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0433e-08 \n",
            "Epoch 8296/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1233e-08 \n",
            "Epoch 8297/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4341e-08 \n",
            "Epoch 8298/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9669e-08 \n",
            "Epoch 8299/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9873e-08 \n",
            "Epoch 8300/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.7253e-09\n",
            "Test accuracy at epoch 8300: 32.95%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.9101e-08\n",
            "Epoch 8301/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8676e-08 \n",
            "Epoch 8302/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1389e-08 \n",
            "Epoch 8303/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9347e-08 \n",
            "Epoch 8304/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9586e-08 \n",
            "Epoch 8305/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7169e-08 \n",
            "Epoch 8306/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5556e-08 \n",
            "Epoch 8307/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8481e-08 \n",
            "Epoch 8308/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8566e-08 \n",
            "Epoch 8309/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7939e-08 \n",
            "Epoch 8310/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7804e-08 \n",
            "Epoch 8311/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3994e-08 \n",
            "Epoch 8312/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9073e-08 \n",
            "Epoch 8313/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4939e-08 \n",
            "Epoch 8314/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6979e-08 \n",
            "Epoch 8315/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3431e-08 \n",
            "Epoch 8316/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5975e-08 \n",
            "Epoch 8317/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6730e-08 \n",
            "Epoch 8318/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8169e-08 \n",
            "Epoch 8319/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7982e-08 \n",
            "Epoch 8320/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7860e-08 \n",
            "Epoch 8321/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7194e-08 \n",
            "Epoch 8322/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5915e-08 \n",
            "Epoch 8323/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3234e-08 \n",
            "Epoch 8324/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8029e-08 \n",
            "Epoch 8325/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3232e-08 \n",
            "Epoch 8326/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2715e-08 \n",
            "Epoch 8327/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2823e-08 \n",
            "Epoch 8328/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6421e-08 \n",
            "Epoch 8329/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7097e-08 \n",
            "Epoch 8330/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5117e-08 \n",
            "Epoch 8331/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3505e-08 \n",
            "Epoch 8332/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3947e-08 \n",
            "Epoch 8333/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4595e-08 \n",
            "Epoch 8334/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4162e-08 \n",
            "Epoch 8335/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4942e-08 \n",
            "Epoch 8336/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1977e-08 \n",
            "Epoch 8337/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6210e-08 \n",
            "Epoch 8338/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4330e-08 \n",
            "Epoch 8339/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2512e-08 \n",
            "Epoch 8340/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3081e-08 \n",
            "Epoch 8341/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2181e-08 \n",
            "Epoch 8342/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3320e-08 \n",
            "Epoch 8343/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8919e-09 \n",
            "Epoch 8344/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1542e-08 \n",
            "Epoch 8345/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0851e-08 \n",
            "Epoch 8346/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3694e-08 \n",
            "Epoch 8347/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0292e-08 \n",
            "Epoch 8348/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2266e-08 \n",
            "Epoch 8349/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4928e-08 \n",
            "Epoch 8350/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8462e-09 \n",
            "Epoch 8351/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2378e-08 \n",
            "Epoch 8352/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2866e-09 \n",
            "Epoch 8353/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2913e-09 \n",
            "Epoch 8354/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9843e-09 \n",
            "Epoch 8355/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1431e-08 \n",
            "Epoch 8356/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4460e-08 \n",
            "Epoch 8357/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0120e-08 \n",
            "Epoch 8358/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0550e-08 \n",
            "Epoch 8359/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1115e-09 \n",
            "Epoch 8360/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9101e-09 \n",
            "Epoch 8361/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1373e-08 \n",
            "Epoch 8362/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0541e-08 \n",
            "Epoch 8363/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1437e-08 \n",
            "Epoch 8364/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2120e-08 \n",
            "Epoch 8365/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1537e-08 \n",
            "Epoch 8366/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3449e-08 \n",
            "Epoch 8367/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8209e-09 \n",
            "Epoch 8368/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3747e-09 \n",
            "Epoch 8369/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0810e-08 \n",
            "Epoch 8370/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2886e-08 \n",
            "Epoch 8371/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1179e-08 \n",
            "Epoch 8372/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6289e-09 \n",
            "Epoch 8373/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6206e-09 \n",
            "Epoch 8374/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2228e-08 \n",
            "Epoch 8375/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0288e-08 \n",
            "Epoch 8376/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0028e-08 \n",
            "Epoch 8377/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9123e-09 \n",
            "Epoch 8378/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5501e-09 \n",
            "Epoch 8379/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1124e-09 \n",
            "Epoch 8380/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1932e-09 \n",
            "Epoch 8381/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3600e-09 \n",
            "Epoch 8382/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8071e-09 \n",
            "Epoch 8383/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5286e-09 \n",
            "Epoch 8384/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7360e-09 \n",
            "Epoch 8385/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1594e-08 \n",
            "Epoch 8386/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6139e-09 \n",
            "Epoch 8387/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4400e-09 \n",
            "Epoch 8388/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6348e-09 \n",
            "Epoch 8389/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0584e-09 \n",
            "Epoch 8390/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5859e-09 \n",
            "Epoch 8391/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3518e-09 \n",
            "Epoch 8392/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4216e-09 \n",
            "Epoch 8393/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3834e-09 \n",
            "Epoch 8394/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4521e-09 \n",
            "Epoch 8395/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9887e-09 \n",
            "Epoch 8396/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0805e-09 \n",
            "Epoch 8397/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8314e-09 \n",
            "Epoch 8398/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5167e-09 \n",
            "Epoch 8399/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5938e-09 \n",
            "Epoch 8400/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.4506e-09\n",
            "Test accuracy at epoch 8400: 32.96%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.1570e-09\n",
            "Epoch 8401/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0575e-08 \n",
            "Epoch 8402/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8495e-09 \n",
            "Epoch 8403/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4358e-09 \n",
            "Epoch 8404/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3449e-09 \n",
            "Epoch 8405/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3321e-09 \n",
            "Epoch 8406/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0939e-09 \n",
            "Epoch 8407/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2461e-09 \n",
            "Epoch 8408/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6023e-09 \n",
            "Epoch 8409/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7476e-09 \n",
            "Epoch 8410/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1841e-09 \n",
            "Epoch 8411/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8864e-09 \n",
            "Epoch 8412/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2234e-09 \n",
            "Epoch 8413/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4119e-09 \n",
            "Epoch 8414/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0780e-09 \n",
            "Epoch 8415/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1818e-09 \n",
            "Epoch 8416/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3568e-09 \n",
            "Epoch 8417/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2520e-09 \n",
            "Epoch 8418/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4306e-09 \n",
            "Epoch 8419/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1560e-09 \n",
            "Epoch 8420/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2302e-09 \n",
            "Epoch 8421/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0337e-09 \n",
            "Epoch 8422/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5772e-09 \n",
            "Epoch 8423/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8501e-09 \n",
            "Epoch 8424/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5295e-09 \n",
            "Epoch 8425/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4681e-09 \n",
            "Epoch 8426/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1803e-09 \n",
            "Epoch 8427/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1860e-09 \n",
            "Epoch 8428/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9748e-09 \n",
            "Epoch 8429/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3420e-09 \n",
            "Epoch 8430/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9782e-09 \n",
            "Epoch 8431/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5751e-09 \n",
            "Epoch 8432/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1273e-09 \n",
            "Epoch 8433/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8000e-09 \n",
            "Epoch 8434/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7022e-09 \n",
            "Epoch 8435/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7355e-09 \n",
            "Epoch 8436/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3833e-09 \n",
            "Epoch 8437/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2706e-09 \n",
            "Epoch 8438/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4204e-09 \n",
            "Epoch 8439/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3732e-09 \n",
            "Epoch 8440/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7367e-09 \n",
            "Epoch 8441/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8306e-09 \n",
            "Epoch 8442/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5231e-09 \n",
            "Epoch 8443/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1826e-09 \n",
            "Epoch 8444/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3619e-09 \n",
            "Epoch 8445/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0658e-09 \n",
            "Epoch 8446/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2869e-09 \n",
            "Epoch 8447/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1364e-09 \n",
            "Epoch 8448/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2684e-09 \n",
            "Epoch 8449/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0241e-09 \n",
            "Epoch 8450/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0178e-09 \n",
            "Epoch 8451/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9882e-09 \n",
            "Epoch 8452/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2074e-09 \n",
            "Epoch 8453/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8052e-09 \n",
            "Epoch 8454/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3935e-09 \n",
            "Epoch 8455/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3982e-09 \n",
            "Epoch 8456/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9211e-09 \n",
            "Epoch 8457/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9829e-09 \n",
            "Epoch 8458/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0583e-09 \n",
            "Epoch 8459/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6754e-09 \n",
            "Epoch 8460/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1772e-09 \n",
            "Epoch 8461/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2568e-09 \n",
            "Epoch 8462/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7281e-09 \n",
            "Epoch 8463/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5618e-09 \n",
            "Epoch 8464/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5430e-09 \n",
            "Epoch 8465/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6180e-09 \n",
            "Epoch 8466/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6220e-09 \n",
            "Epoch 8467/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9854e-09 \n",
            "Epoch 8468/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6318e-09 \n",
            "Epoch 8469/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0752e-09 \n",
            "Epoch 8470/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8876e-09 \n",
            "Epoch 8471/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2097e-09 \n",
            "Epoch 8472/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9728e-09 \n",
            "Epoch 8473/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7325e-09 \n",
            "Epoch 8474/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6529e-09 \n",
            "Epoch 8475/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1638e-09 \n",
            "Epoch 8476/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3330e-09 \n",
            "Epoch 8477/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9179e-09 \n",
            "Epoch 8478/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0384e-09 \n",
            "Epoch 8479/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7658e-09 \n",
            "Epoch 8480/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7150e-09 \n",
            "Epoch 8481/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3631e-09 \n",
            "Epoch 8482/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6051e-09 \n",
            "Epoch 8483/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9523e-09 \n",
            "Epoch 8484/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8274e-09 \n",
            "Epoch 8485/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9757e-09 \n",
            "Epoch 8486/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1153e-09 \n",
            "Epoch 8487/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2504e-09 \n",
            "Epoch 8488/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1744e-09 \n",
            "Epoch 8489/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8785e-09 \n",
            "Epoch 8490/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8232e-09 \n",
            "Epoch 8491/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6125e-09 \n",
            "Epoch 8492/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5784e-09 \n",
            "Epoch 8493/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0640e-09 \n",
            "Epoch 8494/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6913e-09 \n",
            "Epoch 8495/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4548e-09 \n",
            "Epoch 8496/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6256e-09 \n",
            "Epoch 8497/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9146e-09 \n",
            "Epoch 8498/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6958e-09 \n",
            "Epoch 8499/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1452e-09 \n",
            "Epoch 8500/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.4506e-09\n",
            "Test accuracy at epoch 8500: 33.38%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.0912e-09\n",
            "Epoch 8501/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5983e-09 \n",
            "Epoch 8502/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2029e-09 \n",
            "Epoch 8503/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0786e-09 \n",
            "Epoch 8504/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2160e-09 \n",
            "Epoch 8505/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1062e-09 \n",
            "Epoch 8506/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3279e-09 \n",
            "Epoch 8507/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8344e-09 \n",
            "Epoch 8508/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3095e-09 \n",
            "Epoch 8509/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3342e-09 \n",
            "Epoch 8510/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2837e-09 \n",
            "Epoch 8511/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5934e-09 \n",
            "Epoch 8512/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3663e-09 \n",
            "Epoch 8513/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8925e-09 \n",
            "Epoch 8514/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6002e-09 \n",
            "Epoch 8515/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1643e-09 \n",
            "Epoch 8516/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0917e-09 \n",
            "Epoch 8517/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1083e-09 \n",
            "Epoch 8518/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8867e-09 \n",
            "Epoch 8519/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2548e-09 \n",
            "Epoch 8520/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2377e-09 \n",
            "Epoch 8521/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4693e-09 \n",
            "Epoch 8522/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2472e-09 \n",
            "Epoch 8523/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5546e-09 \n",
            "Epoch 8524/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1059e-09 \n",
            "Epoch 8525/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7894e-09 \n",
            "Epoch 8526/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9305e-09 \n",
            "Epoch 8527/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2220e-09 \n",
            "Epoch 8528/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9108e-09 \n",
            "Epoch 8529/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9979e-09 \n",
            "Epoch 8530/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1801e-09 \n",
            "Epoch 8531/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1002e-09 \n",
            "Epoch 8532/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8715e-09 \n",
            "Epoch 8533/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2331e-09 \n",
            "Epoch 8534/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9513e-09 \n",
            "Epoch 8535/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2969e-09 \n",
            "Epoch 8536/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5104e-09 \n",
            "Epoch 8537/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5141e-09 \n",
            "Epoch 8538/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1356e-09 \n",
            "Epoch 8539/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0386e-09 \n",
            "Epoch 8540/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9692e-09 \n",
            "Epoch 8541/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7693e-09 \n",
            "Epoch 8542/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3442e-09 \n",
            "Epoch 8543/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7503e-09 \n",
            "Epoch 8544/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3495e-09 \n",
            "Epoch 8545/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5555e-09 \n",
            "Epoch 8546/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9140e-09 \n",
            "Epoch 8547/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0560e-09 \n",
            "Epoch 8548/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3100e-09 \n",
            "Epoch 8549/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4945e-09 \n",
            "Epoch 8550/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3573e-09 \n",
            "Epoch 8551/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0332e-09 \n",
            "Epoch 8552/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6242e-09 \n",
            "Epoch 8553/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0388e-09 \n",
            "Epoch 8554/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2273e-09 \n",
            "Epoch 8555/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2613e-09 \n",
            "Epoch 8556/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1965e-09 \n",
            "Epoch 8557/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1644e-09 \n",
            "Epoch 8558/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3821e-09 \n",
            "Epoch 8559/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0399e-09 \n",
            "Epoch 8560/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1186e-09 \n",
            "Epoch 8561/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8515e-09 \n",
            "Epoch 8562/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2808e-09 \n",
            "Epoch 8563/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1217e-09 \n",
            "Epoch 8564/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2803e-08 \n",
            "Epoch 8565/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0191e-09 \n",
            "Epoch 8566/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5784e-09 \n",
            "Epoch 8567/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1469e-09 \n",
            "Epoch 8568/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0152e-08 \n",
            "Epoch 8569/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3523e-08 \n",
            "Epoch 8570/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1628e-08 \n",
            "Epoch 8571/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6202e-09 \n",
            "Epoch 8572/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0044e-08 \n",
            "Epoch 8573/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2572e-08 \n",
            "Epoch 8574/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0129e-08 \n",
            "Epoch 8575/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2079e-08 \n",
            "Epoch 8576/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1013e-09 \n",
            "Epoch 8577/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8810e-09 \n",
            "Epoch 8578/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8526e-09 \n",
            "Epoch 8579/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1367e-08 \n",
            "Epoch 8580/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1034e-08 \n",
            "Epoch 8581/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0672e-08 \n",
            "Epoch 8582/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9618 - loss: 0.9296     \n",
            "Epoch 8583/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7602 - loss: 2.9548 \n",
            "Epoch 8584/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.6369 \n",
            "Epoch 8585/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9228 - loss: 0.2275 \n",
            "Epoch 8586/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0711 \n",
            "Epoch 8587/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0089 \n",
            "Epoch 8588/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
            "Epoch 8589/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
            "Epoch 8590/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
            "Epoch 8591/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
            "Epoch 8592/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
            "Epoch 8593/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
            "Epoch 8594/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
            "Epoch 8595/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
            "Epoch 8596/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
            "Epoch 8597/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
            "Epoch 8598/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1599e-04 \n",
            "Epoch 8599/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1544e-04 \n",
            "Epoch 8600/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Test accuracy at epoch 8600: 30.63%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 8601/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1497e-04 \n",
            "Epoch 8602/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2211e-04\n",
            "Epoch 8603/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3022e-04 \n",
            "Epoch 8604/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6238e-04 \n",
            "Epoch 8605/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5694e-04 \n",
            "Epoch 8606/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9521e-04 \n",
            "Epoch 8607/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2377e-04\n",
            "Epoch 8608/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2381e-04 \n",
            "Epoch 8609/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3631e-04 \n",
            "Epoch 8610/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5064e-04 \n",
            "Epoch 8611/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3692e-04 \n",
            "Epoch 8612/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1761e-04 \n",
            "Epoch 8613/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5214e-04 \n",
            "Epoch 8614/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3492e-04 \n",
            "Epoch 8615/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3937e-04 \n",
            "Epoch 8616/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4263e-04 \n",
            "Epoch 8617/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5325e-04 \n",
            "Epoch 8618/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5524e-04 \n",
            "Epoch 8619/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1162e-04 \n",
            "Epoch 8620/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8299e-04 \n",
            "Epoch 8621/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5908e-04 \n",
            "Epoch 8622/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2769e-04 \n",
            "Epoch 8623/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1807e-04 \n",
            "Epoch 8624/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3290e-04 \n",
            "Epoch 8625/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5029e-04 \n",
            "Epoch 8626/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8227e-04 \n",
            "Epoch 8627/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8333e-04 \n",
            "Epoch 8628/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7796e-04 \n",
            "Epoch 8629/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2116e-04 \n",
            "Epoch 8630/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8698e-04 \n",
            "Epoch 8631/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1273e-04 \n",
            "Epoch 8632/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6397e-04 \n",
            "Epoch 8633/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3952e-04 \n",
            "Epoch 8634/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0263e-04 \n",
            "Epoch 8635/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2116e-04 \n",
            "Epoch 8636/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6207e-04 \n",
            "Epoch 8637/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3443e-04 \n",
            "Epoch 8638/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1714e-04 \n",
            "Epoch 8639/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2199e-04 \n",
            "Epoch 8640/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1367e-04 \n",
            "Epoch 8641/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5866e-04 \n",
            "Epoch 8642/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3607e-04 \n",
            "Epoch 8643/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1444e-04 \n",
            "Epoch 8644/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3234e-04 \n",
            "Epoch 8645/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4199e-04 \n",
            "Epoch 8646/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4429e-04 \n",
            "Epoch 8647/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2012e-04 \n",
            "Epoch 8648/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4622e-04 \n",
            "Epoch 8649/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3790e-04 \n",
            "Epoch 8650/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2214e-04 \n",
            "Epoch 8651/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2612e-04 \n",
            "Epoch 8652/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2373e-04 \n",
            "Epoch 8653/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5557e-04 \n",
            "Epoch 8654/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7551e-04 \n",
            "Epoch 8655/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1272e-04 \n",
            "Epoch 8656/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5914e-04 \n",
            "Epoch 8657/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0351e-04 \n",
            "Epoch 8658/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8425e-04 \n",
            "Epoch 8659/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1674e-04 \n",
            "Epoch 8660/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8779e-04 \n",
            "Epoch 8661/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3732e-04 \n",
            "Epoch 8662/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9860e-04 \n",
            "Epoch 8663/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9917e-04 \n",
            "Epoch 8664/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0150e-04 \n",
            "Epoch 8665/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0941e-04 \n",
            "Epoch 8666/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7408e-04 \n",
            "Epoch 8667/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5970e-04 \n",
            "Epoch 8668/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8005e-04 \n",
            "Epoch 8669/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6906e-04 \n",
            "Epoch 8670/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6379e-04 \n",
            "Epoch 8671/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7349e-04 \n",
            "Epoch 8672/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9795e-04 \n",
            "Epoch 8673/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7104e-04 \n",
            "Epoch 8674/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4708e-04 \n",
            "Epoch 8675/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7414e-04 \n",
            "Epoch 8676/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4987e-04 \n",
            "Epoch 8677/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5089e-04 \n",
            "Epoch 8678/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5887e-04 \n",
            "Epoch 8679/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5596e-04 \n",
            "Epoch 8680/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7132e-04 \n",
            "Epoch 8681/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4791e-04 \n",
            "Epoch 8682/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5415e-04 \n",
            "Epoch 8683/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3538e-04 \n",
            "Epoch 8684/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8044e-04 \n",
            "Epoch 8685/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3707e-04 \n",
            "Epoch 8686/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1369e-04 \n",
            "Epoch 8687/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3560e-04 \n",
            "Epoch 8688/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2004e-04 \n",
            "Epoch 8689/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2504e-04 \n",
            "Epoch 8690/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3424e-04 \n",
            "Epoch 8691/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1425e-04 \n",
            "Epoch 8692/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1534e-04 \n",
            "Epoch 8693/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6283e-04 \n",
            "Epoch 8694/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1098e-04 \n",
            "Epoch 8695/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3859e-04 \n",
            "Epoch 8696/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3106e-04 \n",
            "Epoch 8697/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4406e-04 \n",
            "Epoch 8698/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3031e-04 \n",
            "Epoch 8699/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1805e-04 \n",
            "Epoch 8700/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.1058e-04\n",
            "Test accuracy at epoch 8700: 31.01%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2577e-04\n",
            "Epoch 8701/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1848e-04 \n",
            "Epoch 8702/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1789e-04 \n",
            "Epoch 8703/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0728e-04 \n",
            "Epoch 8704/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1557e-04 \n",
            "Epoch 8705/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1112e-04 \n",
            "Epoch 8706/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9554e-05 \n",
            "Epoch 8707/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3966e-04 \n",
            "Epoch 8708/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1067e-04 \n",
            "Epoch 8709/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1172e-04 \n",
            "Epoch 8710/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8752e-05 \n",
            "Epoch 8711/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0432e-04 \n",
            "Epoch 8712/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2194e-04 \n",
            "Epoch 8713/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0333e-04 \n",
            "Epoch 8714/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8610e-05 \n",
            "Epoch 8715/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0314e-04 \n",
            "Epoch 8716/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0354e-04 \n",
            "Epoch 8717/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1571e-04 \n",
            "Epoch 8718/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1910e-04 \n",
            "Epoch 8719/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0061e-04 \n",
            "Epoch 8720/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1430e-05 \n",
            "Epoch 8721/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2531e-05 \n",
            "Epoch 8722/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4813e-05 \n",
            "Epoch 8723/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3580e-05 \n",
            "Epoch 8724/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1796e-05 \n",
            "Epoch 8725/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0834e-04 \n",
            "Epoch 8726/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1086e-05 \n",
            "Epoch 8727/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0867e-05 \n",
            "Epoch 8728/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9442e-05 \n",
            "Epoch 8729/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2609e-05 \n",
            "Epoch 8730/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6161e-05 \n",
            "Epoch 8731/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5604e-05 \n",
            "Epoch 8732/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3802e-05 \n",
            "Epoch 8733/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4033e-05 \n",
            "Epoch 8734/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5828e-05 \n",
            "Epoch 8735/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3963e-05 \n",
            "Epoch 8736/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5702e-05 \n",
            "Epoch 8737/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9677e-05 \n",
            "Epoch 8738/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0594e-05 \n",
            "Epoch 8739/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5042e-05 \n",
            "Epoch 8740/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2574e-05 \n",
            "Epoch 8741/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6564e-05 \n",
            "Epoch 8742/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4993e-05 \n",
            "Epoch 8743/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4846e-05 \n",
            "Epoch 8744/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6749e-05 \n",
            "Epoch 8745/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3382e-05 \n",
            "Epoch 8746/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5819e-05 \n",
            "Epoch 8747/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8156e-05 \n",
            "Epoch 8748/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2575e-05 \n",
            "Epoch 8749/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1918e-05 \n",
            "Epoch 8750/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7240e-05 \n",
            "Epoch 8751/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5968e-05 \n",
            "Epoch 8752/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2676e-05 \n",
            "Epoch 8753/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1167e-05 \n",
            "Epoch 8754/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3754e-05 \n",
            "Epoch 8755/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3703e-05 \n",
            "Epoch 8756/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4403e-05 \n",
            "Epoch 8757/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9043e-05 \n",
            "Epoch 8758/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8676e-05 \n",
            "Epoch 8759/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2893e-05 \n",
            "Epoch 8760/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7472e-05 \n",
            "Epoch 8761/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0326e-05 \n",
            "Epoch 8762/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8710e-05 \n",
            "Epoch 8763/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4006e-05 \n",
            "Epoch 8764/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5806e-05 \n",
            "Epoch 8765/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8213e-05 \n",
            "Epoch 8766/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8435e-05 \n",
            "Epoch 8767/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6095e-05 \n",
            "Epoch 8768/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5507e-05 \n",
            "Epoch 8769/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3329e-05 \n",
            "Epoch 8770/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0887e-05 \n",
            "Epoch 8771/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2111e-05 \n",
            "Epoch 8772/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1821e-05 \n",
            "Epoch 8773/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8013e-05 \n",
            "Epoch 8774/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4194e-05 \n",
            "Epoch 8775/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1002e-05 \n",
            "Epoch 8776/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8061e-05 \n",
            "Epoch 8777/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0986e-05 \n",
            "Epoch 8778/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4262e-05 \n",
            "Epoch 8779/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1675e-05 \n",
            "Epoch 8780/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5340e-05 \n",
            "Epoch 8781/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3188e-05 \n",
            "Epoch 8782/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3526e-05 \n",
            "Epoch 8783/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1079e-05 \n",
            "Epoch 8784/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7407e-05 \n",
            "Epoch 8785/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7265e-05 \n",
            "Epoch 8786/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4302e-05 \n",
            "Epoch 8787/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5105e-05 \n",
            "Epoch 8788/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3904e-05 \n",
            "Epoch 8789/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4886e-05 \n",
            "Epoch 8790/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4143e-05 \n",
            "Epoch 8791/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8564e-05 \n",
            "Epoch 8792/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1074e-05 \n",
            "Epoch 8793/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6649e-05 \n",
            "Epoch 8794/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3409e-05 \n",
            "Epoch 8795/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2364e-05 \n",
            "Epoch 8796/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2043e-05 \n",
            "Epoch 8797/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7099e-05 \n",
            "Epoch 8798/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1064e-05 \n",
            "Epoch 8799/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8035e-05 \n",
            "Epoch 8800/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.6013e-05\n",
            "Test accuracy at epoch 8800: 31.25%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.0455e-05\n",
            "Epoch 8801/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3654e-05 \n",
            "Epoch 8802/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4763e-05 \n",
            "Epoch 8803/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0823e-05 \n",
            "Epoch 8804/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1981e-05 \n",
            "Epoch 8805/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7973e-05 \n",
            "Epoch 8806/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3326e-05 \n",
            "Epoch 8807/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7835e-05 \n",
            "Epoch 8808/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3004e-05 \n",
            "Epoch 8809/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7962e-05 \n",
            "Epoch 8810/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2138e-05 \n",
            "Epoch 8811/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4350e-05 \n",
            "Epoch 8812/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1226e-05 \n",
            "Epoch 8813/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1449e-05 \n",
            "Epoch 8814/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2311e-05 \n",
            "Epoch 8815/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9674e-05 \n",
            "Epoch 8816/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3434e-05 \n",
            "Epoch 8817/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5718e-05 \n",
            "Epoch 8818/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3713e-05 \n",
            "Epoch 8819/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7593e-05 \n",
            "Epoch 8820/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0646e-05 \n",
            "Epoch 8821/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4401e-05 \n",
            "Epoch 8822/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4893e-05 \n",
            "Epoch 8823/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7726e-05 \n",
            "Epoch 8824/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6488e-05 \n",
            "Epoch 8825/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4287e-05 \n",
            "Epoch 8826/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7974e-05 \n",
            "Epoch 8827/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3364e-05 \n",
            "Epoch 8828/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0229e-05 \n",
            "Epoch 8829/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4823e-05 \n",
            "Epoch 8830/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4893e-05 \n",
            "Epoch 8831/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3368e-05 \n",
            "Epoch 8832/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2346e-05 \n",
            "Epoch 8833/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4455e-05 \n",
            "Epoch 8834/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1620e-05 \n",
            "Epoch 8835/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2277e-05 \n",
            "Epoch 8836/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2275e-05 \n",
            "Epoch 8837/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6401e-05 \n",
            "Epoch 8838/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3467e-05 \n",
            "Epoch 8839/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2275e-05 \n",
            "Epoch 8840/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9748e-05 \n",
            "Epoch 8841/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4985e-05 \n",
            "Epoch 8842/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6434e-05 \n",
            "Epoch 8843/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4079e-05 \n",
            "Epoch 8844/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9689e-05 \n",
            "Epoch 8845/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3089e-05 \n",
            "Epoch 8846/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0418e-05 \n",
            "Epoch 8847/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7058e-05 \n",
            "Epoch 8848/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8032e-05 \n",
            "Epoch 8849/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6429e-05 \n",
            "Epoch 8850/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1108e-05 \n",
            "Epoch 8851/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1476e-05 \n",
            "Epoch 8852/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7677e-05 \n",
            "Epoch 8853/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6315e-05 \n",
            "Epoch 8854/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9697e-05 \n",
            "Epoch 8855/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9597e-05 \n",
            "Epoch 8856/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6107e-05 \n",
            "Epoch 8857/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0322e-05 \n",
            "Epoch 8858/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7064e-05 \n",
            "Epoch 8859/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9726e-05 \n",
            "Epoch 8860/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4684e-05 \n",
            "Epoch 8861/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6334e-05 \n",
            "Epoch 8862/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7089e-05 \n",
            "Epoch 8863/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8359e-05 \n",
            "Epoch 8864/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7273e-05 \n",
            "Epoch 8865/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7910e-05 \n",
            "Epoch 8866/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3554e-05 \n",
            "Epoch 8867/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5695e-05 \n",
            "Epoch 8868/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6046e-05 \n",
            "Epoch 8869/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2381e-05 \n",
            "Epoch 8870/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2306e-05 \n",
            "Epoch 8871/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7183e-05 \n",
            "Epoch 8872/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7317e-05 \n",
            "Epoch 8873/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6018e-05 \n",
            "Epoch 8874/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2518e-05 \n",
            "Epoch 8875/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1747e-05 \n",
            "Epoch 8876/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1918e-05 \n",
            "Epoch 8877/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5041e-05 \n",
            "Epoch 8878/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4485e-05 \n",
            "Epoch 8879/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2286e-05 \n",
            "Epoch 8880/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4188e-05 \n",
            "Epoch 8881/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1149e-05 \n",
            "Epoch 8882/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1412e-05 \n",
            "Epoch 8883/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6346e-05 \n",
            "Epoch 8884/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5547e-05 \n",
            "Epoch 8885/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0464e-05 \n",
            "Epoch 8886/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9831e-05 \n",
            "Epoch 8887/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0016e-05 \n",
            "Epoch 8888/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4564e-05 \n",
            "Epoch 8889/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9162e-05 \n",
            "Epoch 8890/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0433e-05 \n",
            "Epoch 8891/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9033e-05 \n",
            "Epoch 8892/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8921e-05 \n",
            "Epoch 8893/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5055e-05 \n",
            "Epoch 8894/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9553e-05 \n",
            "Epoch 8895/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8608e-05 \n",
            "Epoch 8896/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7646e-05 \n",
            "Epoch 8897/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2780e-05 \n",
            "Epoch 8898/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0117e-05 \n",
            "Epoch 8899/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8753e-05 \n",
            "Epoch 8900/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.6019e-05\n",
            "Test accuracy at epoch 8900: 31.46%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.9547e-05\n",
            "Epoch 8901/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7135e-05 \n",
            "Epoch 8902/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0187e-05 \n",
            "Epoch 8903/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8352e-05 \n",
            "Epoch 8904/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6643e-05 \n",
            "Epoch 8905/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9898e-05 \n",
            "Epoch 8906/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8119e-05 \n",
            "Epoch 8907/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1317e-05 \n",
            "Epoch 8908/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5990e-05\n",
            "Epoch 8909/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7982e-05 \n",
            "Epoch 8910/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6836e-05 \n",
            "Epoch 8911/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6070e-05 \n",
            "Epoch 8912/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6953e-05 \n",
            "Epoch 8913/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0396e-05 \n",
            "Epoch 8914/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9677e-05 \n",
            "Epoch 8915/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5697e-05 \n",
            "Epoch 8916/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7158e-05 \n",
            "Epoch 8917/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8335e-05 \n",
            "Epoch 8918/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6443e-05 \n",
            "Epoch 8919/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6138e-05 \n",
            "Epoch 8920/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7652e-05 \n",
            "Epoch 8921/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9063e-05 \n",
            "Epoch 8922/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5245e-05 \n",
            "Epoch 8923/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5216e-05 \n",
            "Epoch 8924/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5277e-05 \n",
            "Epoch 8925/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5403e-05 \n",
            "Epoch 8926/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5459e-05 \n",
            "Epoch 8927/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3957e-05 \n",
            "Epoch 8928/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5521e-05 \n",
            "Epoch 8929/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5711e-05 \n",
            "Epoch 8930/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4042e-05 \n",
            "Epoch 8931/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3110e-05 \n",
            "Epoch 8932/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4580e-05 \n",
            "Epoch 8933/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5550e-05 \n",
            "Epoch 8934/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6851e-05 \n",
            "Epoch 8935/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5747e-05 \n",
            "Epoch 8936/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3142e-05 \n",
            "Epoch 8937/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3720e-05 \n",
            "Epoch 8938/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5080e-05 \n",
            "Epoch 8939/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2453e-05 \n",
            "Epoch 8940/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4717e-05 \n",
            "Epoch 8941/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4027e-05 \n",
            "Epoch 8942/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4028e-05 \n",
            "Epoch 8943/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3603e-05 \n",
            "Epoch 8944/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3294e-05 \n",
            "Epoch 8945/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4409e-05 \n",
            "Epoch 8946/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3583e-05 \n",
            "Epoch 8947/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3740e-05 \n",
            "Epoch 8948/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1365e-05 \n",
            "Epoch 8949/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3535e-05 \n",
            "Epoch 8950/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3660e-05 \n",
            "Epoch 8951/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2115e-05 \n",
            "Epoch 8952/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2342e-05 \n",
            "Epoch 8953/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2457e-05 \n",
            "Epoch 8954/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0718e-05 \n",
            "Epoch 8955/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4151e-05 \n",
            "Epoch 8956/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4764e-05 \n",
            "Epoch 8957/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2763e-05 \n",
            "Epoch 8958/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2915e-05 \n",
            "Epoch 8959/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0375e-05 \n",
            "Epoch 8960/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2895e-05 \n",
            "Epoch 8961/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1291e-05 \n",
            "Epoch 8962/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2368e-05 \n",
            "Epoch 8963/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1732e-05 \n",
            "Epoch 8964/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2110e-05 \n",
            "Epoch 8965/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1354e-05 \n",
            "Epoch 8966/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0997e-05 \n",
            "Epoch 8967/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0433e-05 \n",
            "Epoch 8968/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0564e-05 \n",
            "Epoch 8969/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2773e-05 \n",
            "Epoch 8970/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3130e-05 \n",
            "Epoch 8971/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1799e-05 \n",
            "Epoch 8972/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0923e-05 \n",
            "Epoch 8973/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2624e-05 \n",
            "Epoch 8974/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0420e-05 \n",
            "Epoch 8975/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1657e-05 \n",
            "Epoch 8976/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8116e-06 \n",
            "Epoch 8977/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0020e-05 \n",
            "Epoch 8978/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0154e-05 \n",
            "Epoch 8979/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8366e-06 \n",
            "Epoch 8980/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0444e-05 \n",
            "Epoch 8981/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0280e-05 \n",
            "Epoch 8982/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0572e-05 \n",
            "Epoch 8983/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8654e-06 \n",
            "Epoch 8984/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6966e-06 \n",
            "Epoch 8985/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0305e-05 \n",
            "Epoch 8986/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1003e-05 \n",
            "Epoch 8987/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0725e-05 \n",
            "Epoch 8988/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0152e-05 \n",
            "Epoch 8989/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0087e-05 \n",
            "Epoch 8990/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5789e-06 \n",
            "Epoch 8991/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4706e-06 \n",
            "Epoch 8992/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8845e-06 \n",
            "Epoch 8993/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5777e-06 \n",
            "Epoch 8994/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4700e-06 \n",
            "Epoch 8995/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1248e-06 \n",
            "Epoch 8996/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7026e-06 \n",
            "Epoch 8997/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4576e-06 \n",
            "Epoch 8998/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7454e-06 \n",
            "Epoch 8999/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4564e-06 \n",
            "Epoch 9000/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3645e-05\n",
            "Test accuracy at epoch 9000: 31.66%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.2627e-06\n",
            "Epoch 9001/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8572e-06 \n",
            "Epoch 9002/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6586e-06 \n",
            "Epoch 9003/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7583e-06 \n",
            "Epoch 9004/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5915e-06 \n",
            "Epoch 9005/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2196e-06 \n",
            "Epoch 9006/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2723e-06 \n",
            "Epoch 9007/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5235e-06 \n",
            "Epoch 9008/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8180e-06 \n",
            "Epoch 9009/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7867e-06 \n",
            "Epoch 9010/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9458e-06 \n",
            "Epoch 9011/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4617e-06 \n",
            "Epoch 9012/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3013e-06 \n",
            "Epoch 9013/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2231e-06 \n",
            "Epoch 9014/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6245e-06 \n",
            "Epoch 9015/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4410e-06 \n",
            "Epoch 9016/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6564e-06 \n",
            "Epoch 9017/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4301e-06 \n",
            "Epoch 9018/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2274e-06 \n",
            "Epoch 9019/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3745e-06 \n",
            "Epoch 9020/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3429e-06 \n",
            "Epoch 9021/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7656e-06 \n",
            "Epoch 9022/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6999e-06 \n",
            "Epoch 9023/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3126e-06 \n",
            "Epoch 9024/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4617e-06 \n",
            "Epoch 9025/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2771e-06 \n",
            "Epoch 9026/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7173e-06 \n",
            "Epoch 9027/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5839e-06 \n",
            "Epoch 9028/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9384e-06 \n",
            "Epoch 9029/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1081e-06 \n",
            "Epoch 9030/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1009e-06 \n",
            "Epoch 9031/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6936e-06 \n",
            "Epoch 9032/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1715e-06 \n",
            "Epoch 9033/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4164e-06 \n",
            "Epoch 9034/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4513e-06 \n",
            "Epoch 9035/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4208e-06 \n",
            "Epoch 9036/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8999e-06 \n",
            "Epoch 9037/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8172e-06 \n",
            "Epoch 9038/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2236e-06 \n",
            "Epoch 9039/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5610e-06 \n",
            "Epoch 9040/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8430e-06 \n",
            "Epoch 9041/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1472e-06 \n",
            "Epoch 9042/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6068e-06 \n",
            "Epoch 9043/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6348e-06 \n",
            "Epoch 9044/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0210e-06 \n",
            "Epoch 9045/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1116e-06 \n",
            "Epoch 9046/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9905e-06 \n",
            "Epoch 9047/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3257e-06 \n",
            "Epoch 9048/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1459e-06 \n",
            "Epoch 9049/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6137e-06 \n",
            "Epoch 9050/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9526e-06 \n",
            "Epoch 9051/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6746e-06 \n",
            "Epoch 9052/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1737e-06 \n",
            "Epoch 9053/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1068e-06 \n",
            "Epoch 9054/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4408e-06 \n",
            "Epoch 9055/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7629e-06 \n",
            "Epoch 9056/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4205e-06 \n",
            "Epoch 9057/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3575e-06 \n",
            "Epoch 9058/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1001e-06 \n",
            "Epoch 9059/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9958e-06 \n",
            "Epoch 9060/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6459e-06 \n",
            "Epoch 9061/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4375e-06 \n",
            "Epoch 9062/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6869e-06 \n",
            "Epoch 9063/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9105e-06 \n",
            "Epoch 9064/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1860e-06 \n",
            "Epoch 9065/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1257e-06 \n",
            "Epoch 9066/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4993e-06 \n",
            "Epoch 9067/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9222e-06 \n",
            "Epoch 9068/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9962e-06 \n",
            "Epoch 9069/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4815e-06 \n",
            "Epoch 9070/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6554e-06 \n",
            "Epoch 9071/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0214e-06 \n",
            "Epoch 9072/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9840e-06 \n",
            "Epoch 9073/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5346e-06 \n",
            "Epoch 9074/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0344e-06 \n",
            "Epoch 9075/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1226e-06 \n",
            "Epoch 9076/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9212e-06 \n",
            "Epoch 9077/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7309e-06 \n",
            "Epoch 9078/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9357e-06 \n",
            "Epoch 9079/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6892e-06 \n",
            "Epoch 9080/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8732e-06 \n",
            "Epoch 9081/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0333e-06 \n",
            "Epoch 9082/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3243e-06 \n",
            "Epoch 9083/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9157e-06 \n",
            "Epoch 9084/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3225e-06 \n",
            "Epoch 9085/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9270e-06 \n",
            "Epoch 9086/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2926e-06 \n",
            "Epoch 9087/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7657e-06 \n",
            "Epoch 9088/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0900e-06 \n",
            "Epoch 9089/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5160e-06 \n",
            "Epoch 9090/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9227e-06 \n",
            "Epoch 9091/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6582e-06 \n",
            "Epoch 9092/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5357e-06 \n",
            "Epoch 9093/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5244e-06 \n",
            "Epoch 9094/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6247e-06 \n",
            "Epoch 9095/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5140e-06 \n",
            "Epoch 9096/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2886e-06 \n",
            "Epoch 9097/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1155e-06 \n",
            "Epoch 9098/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6756e-06 \n",
            "Epoch 9099/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5313e-06 \n",
            "Epoch 9100/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.8945e-06\n",
            "Test accuracy at epoch 9100: 31.77%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.5929e-06\n",
            "Epoch 9101/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9580e-06 \n",
            "Epoch 9102/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1680e-06 \n",
            "Epoch 9103/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5611e-06 \n",
            "Epoch 9104/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0961e-06 \n",
            "Epoch 9105/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6864e-06 \n",
            "Epoch 9106/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7076e-06 \n",
            "Epoch 9107/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3694e-06 \n",
            "Epoch 9108/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5405e-06 \n",
            "Epoch 9109/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6651e-06 \n",
            "Epoch 9110/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3271e-06 \n",
            "Epoch 9111/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6014e-06 \n",
            "Epoch 9112/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2732e-06 \n",
            "Epoch 9113/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5726e-06 \n",
            "Epoch 9114/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1514e-06 \n",
            "Epoch 9115/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0595e-06 \n",
            "Epoch 9116/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5970e-06 \n",
            "Epoch 9117/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9401e-06 \n",
            "Epoch 9118/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7545e-06 \n",
            "Epoch 9119/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8442e-06 \n",
            "Epoch 9120/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4460e-06 \n",
            "Epoch 9121/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3142e-06 \n",
            "Epoch 9122/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0732e-06 \n",
            "Epoch 9123/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1632e-06 \n",
            "Epoch 9124/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5686e-06 \n",
            "Epoch 9125/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8522e-06 \n",
            "Epoch 9126/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1904e-06 \n",
            "Epoch 9127/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2946e-06 \n",
            "Epoch 9128/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9442e-06 \n",
            "Epoch 9129/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6046e-06 \n",
            "Epoch 9130/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7803e-06 \n",
            "Epoch 9131/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8423e-06 \n",
            "Epoch 9132/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4549e-06 \n",
            "Epoch 9133/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8964e-06 \n",
            "Epoch 9134/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9742e-06 \n",
            "Epoch 9135/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8315e-06 \n",
            "Epoch 9136/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9406e-06 \n",
            "Epoch 9137/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7398e-06 \n",
            "Epoch 9138/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6301e-06 \n",
            "Epoch 9139/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0566e-06 \n",
            "Epoch 9140/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1990e-06 \n",
            "Epoch 9141/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6439e-06 \n",
            "Epoch 9142/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5829e-06 \n",
            "Epoch 9143/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2890e-06 \n",
            "Epoch 9144/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6207e-06 \n",
            "Epoch 9145/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5686e-06 \n",
            "Epoch 9146/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6673e-06 \n",
            "Epoch 9147/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8742e-06 \n",
            "Epoch 9148/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6762e-06 \n",
            "Epoch 9149/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7528e-06 \n",
            "Epoch 9150/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7206e-06 \n",
            "Epoch 9151/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6862e-06 \n",
            "Epoch 9152/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5941e-06 \n",
            "Epoch 9153/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4522e-06 \n",
            "Epoch 9154/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4096e-06 \n",
            "Epoch 9155/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4893e-06 \n",
            "Epoch 9156/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3106e-06 \n",
            "Epoch 9157/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3798e-06 \n",
            "Epoch 9158/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3564e-06 \n",
            "Epoch 9159/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7251e-06 \n",
            "Epoch 9160/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3605e-06 \n",
            "Epoch 9161/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6280e-06 \n",
            "Epoch 9162/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2910e-06 \n",
            "Epoch 9163/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2123e-06 \n",
            "Epoch 9164/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4854e-06 \n",
            "Epoch 9165/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1427e-06 \n",
            "Epoch 9166/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5120e-06 \n",
            "Epoch 9167/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2169e-06 \n",
            "Epoch 9168/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3855e-06 \n",
            "Epoch 9169/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0062e-06 \n",
            "Epoch 9170/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2161e-06 \n",
            "Epoch 9171/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2998e-06 \n",
            "Epoch 9172/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9921e-06 \n",
            "Epoch 9173/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1404e-06 \n",
            "Epoch 9174/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8862e-06 \n",
            "Epoch 9175/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2034e-06 \n",
            "Epoch 9176/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9023e-06 \n",
            "Epoch 9177/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8682e-06 \n",
            "Epoch 9178/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1859e-06 \n",
            "Epoch 9179/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9524e-06 \n",
            "Epoch 9180/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1315e-06 \n",
            "Epoch 9181/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7231e-06 \n",
            "Epoch 9182/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1948e-06 \n",
            "Epoch 9183/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8943e-06 \n",
            "Epoch 9184/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9807e-06 \n",
            "Epoch 9185/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9717e-06 \n",
            "Epoch 9186/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9579e-06 \n",
            "Epoch 9187/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0098e-06 \n",
            "Epoch 9188/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0206e-06 \n",
            "Epoch 9189/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7011e-06 \n",
            "Epoch 9190/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8986e-06 \n",
            "Epoch 9191/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0473e-06 \n",
            "Epoch 9192/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6105e-06 \n",
            "Epoch 9193/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9074e-06 \n",
            "Epoch 9194/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6291e-06 \n",
            "Epoch 9195/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7067e-06 \n",
            "Epoch 9196/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8264e-06 \n",
            "Epoch 9197/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6744e-06 \n",
            "Epoch 9198/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8860e-06 \n",
            "Epoch 9199/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6118e-06 \n",
            "Epoch 9200/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.3262e-06\n",
            "Test accuracy at epoch 9200: 31.78%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5641e-06\n",
            "Epoch 9201/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7794e-06 \n",
            "Epoch 9202/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9730e-06 \n",
            "Epoch 9203/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7403e-06 \n",
            "Epoch 9204/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8596e-06 \n",
            "Epoch 9205/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6652e-06 \n",
            "Epoch 9206/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6251e-06 \n",
            "Epoch 9207/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5169e-06 \n",
            "Epoch 9208/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6968e-06 \n",
            "Epoch 9209/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9948e-06 \n",
            "Epoch 9210/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5196e-06 \n",
            "Epoch 9211/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5362e-06 \n",
            "Epoch 9212/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4977e-06 \n",
            "Epoch 9213/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5113e-06 \n",
            "Epoch 9214/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5644e-06 \n",
            "Epoch 9215/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6421e-06 \n",
            "Epoch 9216/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6140e-06 \n",
            "Epoch 9217/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6794e-06 \n",
            "Epoch 9218/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5449e-06 \n",
            "Epoch 9219/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3906e-06 \n",
            "Epoch 9220/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4708e-06 \n",
            "Epoch 9221/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4251e-06 \n",
            "Epoch 9222/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2267e-06 \n",
            "Epoch 9223/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3656e-06 \n",
            "Epoch 9224/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3639e-06 \n",
            "Epoch 9225/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4943e-06 \n",
            "Epoch 9226/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4157e-06 \n",
            "Epoch 9227/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4525e-06 \n",
            "Epoch 9228/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2865e-06 \n",
            "Epoch 9229/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3209e-06 \n",
            "Epoch 9230/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3687e-06 \n",
            "Epoch 9231/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2314e-06 \n",
            "Epoch 9232/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2716e-06 \n",
            "Epoch 9233/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1625e-06 \n",
            "Epoch 9234/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3840e-06 \n",
            "Epoch 9235/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2899e-06 \n",
            "Epoch 9236/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3624e-06 \n",
            "Epoch 9237/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3064e-06 \n",
            "Epoch 9238/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1728e-06 \n",
            "Epoch 9239/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3824e-06 \n",
            "Epoch 9240/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1671e-06 \n",
            "Epoch 9241/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3534e-06 \n",
            "Epoch 9242/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3553e-06 \n",
            "Epoch 9243/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1681e-06 \n",
            "Epoch 9244/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4468e-06 \n",
            "Epoch 9245/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1765e-06 \n",
            "Epoch 9246/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0668e-06 \n",
            "Epoch 9247/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3665e-06 \n",
            "Epoch 9248/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2343e-06 \n",
            "Epoch 9249/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2293e-06 \n",
            "Epoch 9250/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0341e-06 \n",
            "Epoch 9251/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1171e-06 \n",
            "Epoch 9252/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0553e-06 \n",
            "Epoch 9253/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0026e-06 \n",
            "Epoch 9254/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2199e-06 \n",
            "Epoch 9255/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1737e-06 \n",
            "Epoch 9256/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1118e-06 \n",
            "Epoch 9257/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2265e-06 \n",
            "Epoch 9258/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0052e-06 \n",
            "Epoch 9259/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0396e-06 \n",
            "Epoch 9260/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5212e-07 \n",
            "Epoch 9261/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1124e-06 \n",
            "Epoch 9262/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1359e-06 \n",
            "Epoch 9263/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0067e-06 \n",
            "Epoch 9264/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0256e-06 \n",
            "Epoch 9265/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6835e-07 \n",
            "Epoch 9266/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0227e-06 \n",
            "Epoch 9267/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0445e-06 \n",
            "Epoch 9268/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7337e-07 \n",
            "Epoch 9269/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0952e-06 \n",
            "Epoch 9270/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0354e-06 \n",
            "Epoch 9271/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6377e-07 \n",
            "Epoch 9272/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0205e-06 \n",
            "Epoch 9273/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8277e-07 \n",
            "Epoch 9274/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7861e-07 \n",
            "Epoch 9275/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6215e-07 \n",
            "Epoch 9276/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4710e-07 \n",
            "Epoch 9277/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6573e-07 \n",
            "Epoch 9278/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7856e-07 \n",
            "Epoch 9279/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5108e-07 \n",
            "Epoch 9280/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4610e-07 \n",
            "Epoch 9281/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6900e-07 \n",
            "Epoch 9282/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5871e-07 \n",
            "Epoch 9283/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1512e-06 \n",
            "Epoch 9284/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6378e-07 \n",
            "Epoch 9285/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7118e-07 \n",
            "Epoch 9286/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8499e-07 \n",
            "Epoch 9287/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5673e-07 \n",
            "Epoch 9288/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3406e-07 \n",
            "Epoch 9289/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6094e-07 \n",
            "Epoch 9290/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5026e-07 \n",
            "Epoch 9291/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0526e-07 \n",
            "Epoch 9292/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1012e-07 \n",
            "Epoch 9293/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4601e-07 \n",
            "Epoch 9294/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5960e-07 \n",
            "Epoch 9295/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8497e-07 \n",
            "Epoch 9296/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6093e-07 \n",
            "Epoch 9297/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5403e-07 \n",
            "Epoch 9298/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7929e-07 \n",
            "Epoch 9299/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8627e-07 \n",
            "Epoch 9300/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.0722e-07\n",
            "Test accuracy at epoch 9300: 32.02%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.1428e-07\n",
            "Epoch 9301/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3348e-07 \n",
            "Epoch 9302/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8641e-07 \n",
            "Epoch 9303/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8488e-07 \n",
            "Epoch 9304/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4287e-07 \n",
            "Epoch 9305/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9403e-07 \n",
            "Epoch 9306/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2460e-07 \n",
            "Epoch 9307/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9000e-07 \n",
            "Epoch 9308/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7951e-07 \n",
            "Epoch 9309/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2739e-07 \n",
            "Epoch 9310/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1819e-07 \n",
            "Epoch 9311/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7201e-07 \n",
            "Epoch 9312/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5698e-07 \n",
            "Epoch 9313/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3462e-07 \n",
            "Epoch 9314/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4682e-07 \n",
            "Epoch 9315/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7647e-07 \n",
            "Epoch 9316/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9009e-07 \n",
            "Epoch 9317/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7391e-07 \n",
            "Epoch 9318/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3180e-07 \n",
            "Epoch 9319/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8914e-07 \n",
            "Epoch 9320/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9419e-07 \n",
            "Epoch 9321/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0057e-07 \n",
            "Epoch 9322/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2188e-07 \n",
            "Epoch 9323/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1612e-07 \n",
            "Epoch 9324/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9490e-07 \n",
            "Epoch 9325/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3295e-07 \n",
            "Epoch 9326/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2483e-07 \n",
            "Epoch 9327/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7854e-07 \n",
            "Epoch 9328/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6247e-07 \n",
            "Epoch 9329/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6461e-07 \n",
            "Epoch 9330/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9642e-07 \n",
            "Epoch 9331/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2074e-07 \n",
            "Epoch 9332/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8532e-07 \n",
            "Epoch 9333/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1133e-07 \n",
            "Epoch 9334/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2429e-07 \n",
            "Epoch 9335/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5284e-07 \n",
            "Epoch 9336/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5002e-07 \n",
            "Epoch 9337/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1214e-07 \n",
            "Epoch 9338/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9252e-07 \n",
            "Epoch 9339/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9228e-07 \n",
            "Epoch 9340/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4903e-07 \n",
            "Epoch 9341/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0180e-07 \n",
            "Epoch 9342/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4035e-07 \n",
            "Epoch 9343/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0575e-07 \n",
            "Epoch 9344/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1653e-07 \n",
            "Epoch 9345/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0334e-07 \n",
            "Epoch 9346/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3759e-07 \n",
            "Epoch 9347/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1058e-07 \n",
            "Epoch 9348/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7490e-07 \n",
            "Epoch 9349/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2084e-07 \n",
            "Epoch 9350/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0744e-07 \n",
            "Epoch 9351/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7915e-07 \n",
            "Epoch 9352/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6985e-07 \n",
            "Epoch 9353/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8564e-07 \n",
            "Epoch 9354/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3189e-07 \n",
            "Epoch 9355/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9883e-07 \n",
            "Epoch 9356/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5700e-07 \n",
            "Epoch 9357/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6912e-07 \n",
            "Epoch 9358/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3557e-07 \n",
            "Epoch 9359/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1147e-07 \n",
            "Epoch 9360/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6650e-07 \n",
            "Epoch 9361/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4885e-07 \n",
            "Epoch 9362/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7959e-07 \n",
            "Epoch 9363/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3710e-07 \n",
            "Epoch 9364/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2825e-07 \n",
            "Epoch 9365/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0660e-07 \n",
            "Epoch 9366/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2587e-07 \n",
            "Epoch 9367/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5408e-07 \n",
            "Epoch 9368/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2545e-07 \n",
            "Epoch 9369/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4633e-07 \n",
            "Epoch 9370/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7081e-07 \n",
            "Epoch 9371/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0233e-07 \n",
            "Epoch 9372/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3114e-07 \n",
            "Epoch 9373/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6960e-07 \n",
            "Epoch 9374/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4034e-07 \n",
            "Epoch 9375/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4974e-07 \n",
            "Epoch 9376/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1153e-07 \n",
            "Epoch 9377/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9990e-07 \n",
            "Epoch 9378/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3269e-07 \n",
            "Epoch 9379/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1592e-07 \n",
            "Epoch 9380/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4461e-07 \n",
            "Epoch 9381/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2781e-07 \n",
            "Epoch 9382/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3617e-07 \n",
            "Epoch 9383/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2930e-07 \n",
            "Epoch 9384/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5323e-07 \n",
            "Epoch 9385/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9070e-07 \n",
            "Epoch 9386/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6580e-07 \n",
            "Epoch 9387/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2264e-07 \n",
            "Epoch 9388/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8191e-07 \n",
            "Epoch 9389/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9137e-07 \n",
            "Epoch 9390/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7984e-07 \n",
            "Epoch 9391/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7919e-07 \n",
            "Epoch 9392/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7564e-07 \n",
            "Epoch 9393/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7042e-07 \n",
            "Epoch 9394/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6583e-07 \n",
            "Epoch 9395/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8769e-07 \n",
            "Epoch 9396/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9993e-07 \n",
            "Epoch 9397/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3403e-07 \n",
            "Epoch 9398/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0697e-07 \n",
            "Epoch 9399/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6465e-07 \n",
            "Epoch 9400/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.9488e-07\n",
            "Test accuracy at epoch 9400: 32.26%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.4321e-07\n",
            "Epoch 9401/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4749e-07 \n",
            "Epoch 9402/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2055e-07 \n",
            "Epoch 9403/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4663e-07 \n",
            "Epoch 9404/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8699e-07 \n",
            "Epoch 9405/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5633e-07 \n",
            "Epoch 9406/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4044e-07 \n",
            "Epoch 9407/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1876e-07 \n",
            "Epoch 9408/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9541e-07 \n",
            "Epoch 9409/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2110e-07 \n",
            "Epoch 9410/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8989e-07 \n",
            "Epoch 9411/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4857e-07 \n",
            "Epoch 9412/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9454e-07 \n",
            "Epoch 9413/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1330e-07 \n",
            "Epoch 9414/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2942e-07 \n",
            "Epoch 9415/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6342e-07 \n",
            "Epoch 9416/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1933e-07 \n",
            "Epoch 9417/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3354e-07 \n",
            "Epoch 9418/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2698e-07 \n",
            "Epoch 9419/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6152e-07 \n",
            "Epoch 9420/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7966e-07 \n",
            "Epoch 9421/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1080e-07 \n",
            "Epoch 9422/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1054e-07 \n",
            "Epoch 9423/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2968e-07 \n",
            "Epoch 9424/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0875e-07 \n",
            "Epoch 9425/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8324e-07 \n",
            "Epoch 9426/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6345e-07 \n",
            "Epoch 9427/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8822e-07 \n",
            "Epoch 9428/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1417e-07 \n",
            "Epoch 9429/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6958e-07 \n",
            "Epoch 9430/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8024e-07 \n",
            "Epoch 9431/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9906e-07 \n",
            "Epoch 9432/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1810e-07 \n",
            "Epoch 9433/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4201e-07 \n",
            "Epoch 9434/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7557e-07 \n",
            "Epoch 9435/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0132e-07 \n",
            "Epoch 9436/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0180e-07 \n",
            "Epoch 9437/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3449e-07 \n",
            "Epoch 9438/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3117e-07 \n",
            "Epoch 9439/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4709e-07 \n",
            "Epoch 9440/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3616e-07 \n",
            "Epoch 9441/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5832e-07 \n",
            "Epoch 9442/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5125e-07 \n",
            "Epoch 9443/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0151e-07 \n",
            "Epoch 9444/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3440e-07 \n",
            "Epoch 9445/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5715e-07 \n",
            "Epoch 9446/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7734e-07 \n",
            "Epoch 9447/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3587e-07 \n",
            "Epoch 9448/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5345e-07 \n",
            "Epoch 9449/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5075e-07 \n",
            "Epoch 9450/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4974e-07 \n",
            "Epoch 9451/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2256e-07 \n",
            "Epoch 9452/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5970e-07 \n",
            "Epoch 9453/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1192e-07 \n",
            "Epoch 9454/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8393e-07 \n",
            "Epoch 9455/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2997e-07 \n",
            "Epoch 9456/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1157e-07 \n",
            "Epoch 9457/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2886e-07 \n",
            "Epoch 9458/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1771e-07 \n",
            "Epoch 9459/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3796e-07 \n",
            "Epoch 9460/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1658e-07 \n",
            "Epoch 9461/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6003e-07 \n",
            "Epoch 9462/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4853e-07 \n",
            "Epoch 9463/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1421e-07 \n",
            "Epoch 9464/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9158e-07 \n",
            "Epoch 9465/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1615e-07 \n",
            "Epoch 9466/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0919e-07 \n",
            "Epoch 9467/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1413e-07 \n",
            "Epoch 9468/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2079e-07 \n",
            "Epoch 9469/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3698e-07 \n",
            "Epoch 9470/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1534e-07 \n",
            "Epoch 9471/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0340e-07 \n",
            "Epoch 9472/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7884e-07 \n",
            "Epoch 9473/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1755e-07 \n",
            "Epoch 9474/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9814e-07 \n",
            "Epoch 9475/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8273e-07 \n",
            "Epoch 9476/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0723e-07 \n",
            "Epoch 9477/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6746e-07 \n",
            "Epoch 9478/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0193e-07 \n",
            "Epoch 9479/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9179e-07 \n",
            "Epoch 9480/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8526e-07 \n",
            "Epoch 9481/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7939e-07 \n",
            "Epoch 9482/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8461e-07 \n",
            "Epoch 9483/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8457e-07 \n",
            "Epoch 9484/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0294e-07 \n",
            "Epoch 9485/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6764e-07 \n",
            "Epoch 9486/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6723e-07 \n",
            "Epoch 9487/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7196e-07 \n",
            "Epoch 9488/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9844e-07 \n",
            "Epoch 9489/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8715e-07 \n",
            "Epoch 9490/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7064e-07 \n",
            "Epoch 9491/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5363e-07 \n",
            "Epoch 9492/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7267e-07 \n",
            "Epoch 9493/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6771e-07 \n",
            "Epoch 9494/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7753e-07 \n",
            "Epoch 9495/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9067e-07 \n",
            "Epoch 9496/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4709e-07 \n",
            "Epoch 9497/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6649e-07 \n",
            "Epoch 9498/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4201e-07 \n",
            "Epoch 9499/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5717e-07 \n",
            "Epoch 9500/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.6391e-07\n",
            "Test accuracy at epoch 9500: 32.29%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.7659e-07\n",
            "Epoch 9501/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5627e-07 \n",
            "Epoch 9502/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7809e-07 \n",
            "Epoch 9503/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6177e-07 \n",
            "Epoch 9504/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4104e-07 \n",
            "Epoch 9505/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4587e-07 \n",
            "Epoch 9506/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4383e-07 \n",
            "Epoch 9507/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3594e-07 \n",
            "Epoch 9508/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7294e-07 \n",
            "Epoch 9509/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4531e-07 \n",
            "Epoch 9510/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1794e-07 \n",
            "Epoch 9511/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2906e-07 \n",
            "Epoch 9512/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4672e-07 \n",
            "Epoch 9513/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3671e-07 \n",
            "Epoch 9514/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3582e-07 \n",
            "Epoch 9515/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5282e-07 \n",
            "Epoch 9516/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3553e-07 \n",
            "Epoch 9517/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4354e-07 \n",
            "Epoch 9518/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3862e-07 \n",
            "Epoch 9519/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5466e-07 \n",
            "Epoch 9520/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2357e-07 \n",
            "Epoch 9521/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1067e-07 \n",
            "Epoch 9522/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2597e-07 \n",
            "Epoch 9523/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4005e-07 \n",
            "Epoch 9524/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1933e-07 \n",
            "Epoch 9525/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4544e-07 \n",
            "Epoch 9526/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1793e-07 \n",
            "Epoch 9527/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1717e-07 \n",
            "Epoch 9528/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2051e-07 \n",
            "Epoch 9529/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4574e-07 \n",
            "Epoch 9530/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1956e-07 \n",
            "Epoch 9531/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0868e-07 \n",
            "Epoch 9532/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8753e-08 \n",
            "Epoch 9533/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4039e-07 \n",
            "Epoch 9534/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1767e-07 \n",
            "Epoch 9535/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3081e-07 \n",
            "Epoch 9536/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0613e-07 \n",
            "Epoch 9537/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1642e-07 \n",
            "Epoch 9538/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0124e-07 \n",
            "Epoch 9539/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2212e-07 \n",
            "Epoch 9540/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0584e-07 \n",
            "Epoch 9541/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1951e-07 \n",
            "Epoch 9542/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0661e-07 \n",
            "Epoch 9543/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0813e-07 \n",
            "Epoch 9544/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1536e-07 \n",
            "Epoch 9545/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0406e-07 \n",
            "Epoch 9546/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0192e-07 \n",
            "Epoch 9547/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9907e-08 \n",
            "Epoch 9548/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1986e-07 \n",
            "Epoch 9549/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7889e-08 \n",
            "Epoch 9550/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0744e-07 \n",
            "Epoch 9551/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5854e-08 \n",
            "Epoch 9552/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0580e-07 \n",
            "Epoch 9553/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2956e-08 \n",
            "Epoch 9554/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8580e-08 \n",
            "Epoch 9555/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3612e-08 \n",
            "Epoch 9556/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7956e-08 \n",
            "Epoch 9557/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2165e-08 \n",
            "Epoch 9558/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0288e-07 \n",
            "Epoch 9559/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6507e-08 \n",
            "Epoch 9560/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0986e-08 \n",
            "Epoch 9561/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1588e-08 \n",
            "Epoch 9562/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4463e-08 \n",
            "Epoch 9563/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0401e-07 \n",
            "Epoch 9564/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3248e-08 \n",
            "Epoch 9565/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9713e-08 \n",
            "Epoch 9566/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5854e-08 \n",
            "Epoch 9567/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9381e-08 \n",
            "Epoch 9568/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8552e-08 \n",
            "Epoch 9569/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0619e-08 \n",
            "Epoch 9570/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5218e-08 \n",
            "Epoch 9571/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7488e-08 \n",
            "Epoch 9572/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6099e-08 \n",
            "Epoch 9573/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3468e-08 \n",
            "Epoch 9574/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0561e-08 \n",
            "Epoch 9575/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7089e-08 \n",
            "Epoch 9576/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2431e-08 \n",
            "Epoch 9577/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3911e-08 \n",
            "Epoch 9578/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9472e-08 \n",
            "Epoch 9579/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7847e-08 \n",
            "Epoch 9580/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5226e-08 \n",
            "Epoch 9581/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6952e-08 \n",
            "Epoch 9582/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3983e-08 \n",
            "Epoch 9583/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6574e-08 \n",
            "Epoch 9584/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3142e-08 \n",
            "Epoch 9585/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5692e-08 \n",
            "Epoch 9586/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1305e-08 \n",
            "Epoch 9587/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9332e-08 \n",
            "Epoch 9588/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6731e-08 \n",
            "Epoch 9589/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0507e-08 \n",
            "Epoch 9590/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3956e-08 \n",
            "Epoch 9591/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0939e-08 \n",
            "Epoch 9592/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9217e-08 \n",
            "Epoch 9593/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8473e-08 \n",
            "Epoch 9594/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6898e-08 \n",
            "Epoch 9595/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9369e-08 \n",
            "Epoch 9596/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7399e-08 \n",
            "Epoch 9597/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3326e-08 \n",
            "Epoch 9598/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9966e-08 \n",
            "Epoch 9599/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2810e-08 \n",
            "Epoch 9600/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 7.0781e-08\n",
            "Test accuracy at epoch 9600: 32.59%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.1939e-08\n",
            "Epoch 9601/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5957e-08 \n",
            "Epoch 9602/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1310e-08 \n",
            "Epoch 9603/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2823e-08 \n",
            "Epoch 9604/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0818e-08 \n",
            "Epoch 9605/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9202e-08 \n",
            "Epoch 9606/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3267e-08 \n",
            "Epoch 9607/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8345e-08 \n",
            "Epoch 9608/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7997e-08 \n",
            "Epoch 9609/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0035e-08 \n",
            "Epoch 9610/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9714e-08 \n",
            "Epoch 9611/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4069e-08 \n",
            "Epoch 9612/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2226e-08 \n",
            "Epoch 9613/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6906e-08 \n",
            "Epoch 9614/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0436e-08 \n",
            "Epoch 9615/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9462e-08 \n",
            "Epoch 9616/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5860e-08 \n",
            "Epoch 9617/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9513e-08 \n",
            "Epoch 9618/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6302e-08 \n",
            "Epoch 9619/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2417e-08 \n",
            "Epoch 9620/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7161e-08 \n",
            "Epoch 9621/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9017e-08 \n",
            "Epoch 9622/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7754e-08 \n",
            "Epoch 9623/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7274e-08 \n",
            "Epoch 9624/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2329e-08 \n",
            "Epoch 9625/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6260e-08 \n",
            "Epoch 9626/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0661e-08 \n",
            "Epoch 9627/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3799e-08 \n",
            "Epoch 9628/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6855e-08 \n",
            "Epoch 9629/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0583e-08 \n",
            "Epoch 9630/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2851e-08 \n",
            "Epoch 9631/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2780e-08 \n",
            "Epoch 9632/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6389e-08 \n",
            "Epoch 9633/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6718e-08 \n",
            "Epoch 9634/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8571e-08 \n",
            "Epoch 9635/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2698e-08 \n",
            "Epoch 9636/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9022e-08 \n",
            "Epoch 9637/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2543e-08 \n",
            "Epoch 9638/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1308e-08 \n",
            "Epoch 9639/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8981e-08 \n",
            "Epoch 9640/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2663e-08 \n",
            "Epoch 9641/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0593e-08 \n",
            "Epoch 9642/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3277e-08 \n",
            "Epoch 9643/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5398e-08 \n",
            "Epoch 9644/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2324e-08 \n",
            "Epoch 9645/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5175e-08 \n",
            "Epoch 9646/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7522e-08 \n",
            "Epoch 9647/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8942e-08 \n",
            "Epoch 9648/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8602e-08 \n",
            "Epoch 9649/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4489e-08 \n",
            "Epoch 9650/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8603e-08 \n",
            "Epoch 9651/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3934e-08 \n",
            "Epoch 9652/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7316e-08 \n",
            "Epoch 9653/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8297e-08 \n",
            "Epoch 9654/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9408e-08 \n",
            "Epoch 9655/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1346e-08 \n",
            "Epoch 9656/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7356e-08 \n",
            "Epoch 9657/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5683e-08 \n",
            "Epoch 9658/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8049e-08 \n",
            "Epoch 9659/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4148e-08 \n",
            "Epoch 9660/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2765e-08 \n",
            "Epoch 9661/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1712e-08 \n",
            "Epoch 9662/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5496e-08 \n",
            "Epoch 9663/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4658e-08 \n",
            "Epoch 9664/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3250e-08 \n",
            "Epoch 9665/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5176e-08 \n",
            "Epoch 9666/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1425e-08 \n",
            "Epoch 9667/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0545e-08 \n",
            "Epoch 9668/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9594e-08 \n",
            "Epoch 9669/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8526e-08 \n",
            "Epoch 9670/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1995e-08 \n",
            "Epoch 9671/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8944e-08 \n",
            "Epoch 9672/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6128e-08 \n",
            "Epoch 9673/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9941e-08 \n",
            "Epoch 9674/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7247e-08 \n",
            "Epoch 9675/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7307e-08 \n",
            "Epoch 9676/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7533e-08 \n",
            "Epoch 9677/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0676e-08 \n",
            "Epoch 9678/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7270e-08 \n",
            "Epoch 9679/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3972e-08 \n",
            "Epoch 9680/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4830e-08 \n",
            "Epoch 9681/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6989e-08 \n",
            "Epoch 9682/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6191e-08 \n",
            "Epoch 9683/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4422e-08 \n",
            "Epoch 9684/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4983e-08 \n",
            "Epoch 9685/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7835e-08 \n",
            "Epoch 9686/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2937e-08 \n",
            "Epoch 9687/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0943e-08 \n",
            "Epoch 9688/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2389e-08 \n",
            "Epoch 9689/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3770e-08 \n",
            "Epoch 9690/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8267e-08 \n",
            "Epoch 9691/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8311e-08 \n",
            "Epoch 9692/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5377e-08 \n",
            "Epoch 9693/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0513e-08 \n",
            "Epoch 9694/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1361e-08 \n",
            "Epoch 9695/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3882e-08 \n",
            "Epoch 9696/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0740e-08 \n",
            "Epoch 9697/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0963e-08 \n",
            "Epoch 9698/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8901e-08 \n",
            "Epoch 9699/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3586e-08 \n",
            "Epoch 9700/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.8626e-08\n",
            "Test accuracy at epoch 9700: 32.52%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.6018e-08\n",
            "Epoch 9701/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4883e-08 \n",
            "Epoch 9702/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7257e-08 \n",
            "Epoch 9703/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4895e-08 \n",
            "Epoch 9704/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6010e-08 \n",
            "Epoch 9705/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3551e-08 \n",
            "Epoch 9706/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1697e-08 \n",
            "Epoch 9707/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9489e-08 \n",
            "Epoch 9708/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9282e-08 \n",
            "Epoch 9709/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9777e-08 \n",
            "Epoch 9710/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7906e-08 \n",
            "Epoch 9711/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0667e-08 \n",
            "Epoch 9712/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0794e-08 \n",
            "Epoch 9713/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9919e-08 \n",
            "Epoch 9714/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6315e-08 \n",
            "Epoch 9715/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0697e-08 \n",
            "Epoch 9716/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8921e-08 \n",
            "Epoch 9717/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6433e-08 \n",
            "Epoch 9718/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9390e-08 \n",
            "Epoch 9719/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7891e-08 \n",
            "Epoch 9720/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8672e-08 \n",
            "Epoch 9721/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8632e-08 \n",
            "Epoch 9722/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6770e-08 \n",
            "Epoch 9723/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4151e-08 \n",
            "Epoch 9724/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4589e-08 \n",
            "Epoch 9725/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3134e-08 \n",
            "Epoch 9726/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4018e-08 \n",
            "Epoch 9727/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5746e-08 \n",
            "Epoch 9728/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4324e-08 \n",
            "Epoch 9729/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4395e-08 \n",
            "Epoch 9730/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5388e-08 \n",
            "Epoch 9731/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6746e-08 \n",
            "Epoch 9732/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4026e-08 \n",
            "Epoch 9733/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3979e-08 \n",
            "Epoch 9734/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0523e-08 \n",
            "Epoch 9735/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9609e-08 \n",
            "Epoch 9736/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5401e-08 \n",
            "Epoch 9737/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5513e-08 \n",
            "Epoch 9738/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3267e-08 \n",
            "Epoch 9739/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2682e-08 \n",
            "Epoch 9740/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7050e-08 \n",
            "Epoch 9741/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1252e-08 \n",
            "Epoch 9742/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6783e-09 \n",
            "Epoch 9743/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6667e-09 \n",
            "Epoch 9744/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5833e-08 \n",
            "Epoch 9745/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4061e-08 \n",
            "Epoch 9746/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1183e-08 \n",
            "Epoch 9747/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3764e-08 \n",
            "Epoch 9748/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7108e-08 \n",
            "Epoch 9749/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5855e-08 \n",
            "Epoch 9750/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3934e-08 \n",
            "Epoch 9751/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1764e-08 \n",
            "Epoch 9752/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3367e-08 \n",
            "Epoch 9753/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4568e-08 \n",
            "Epoch 9754/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0866e-08 \n",
            "Epoch 9755/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1164e-08 \n",
            "Epoch 9756/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1970e-08 \n",
            "Epoch 9757/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2314e-08 \n",
            "Epoch 9758/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0671e-08 \n",
            "Epoch 9759/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4640e-08 \n",
            "Epoch 9760/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0625e-08 \n",
            "Epoch 9761/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1146e-08 \n",
            "Epoch 9762/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1205e-08 \n",
            "Epoch 9763/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2070e-08 \n",
            "Epoch 9764/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2551e-09 \n",
            "Epoch 9765/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1930e-08 \n",
            "Epoch 9766/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0627e-08 \n",
            "Epoch 9767/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0847e-08 \n",
            "Epoch 9768/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0400e-08 \n",
            "Epoch 9769/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1665e-08 \n",
            "Epoch 9770/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3111e-08 \n",
            "Epoch 9771/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0255e-08 \n",
            "Epoch 9772/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0322e-08 \n",
            "Epoch 9773/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5676e-09 \n",
            "Epoch 9774/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6943e-09 \n",
            "Epoch 9775/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9842e-09 \n",
            "Epoch 9776/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1382e-08 \n",
            "Epoch 9777/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0623e-08 \n",
            "Epoch 9778/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6060e-09 \n",
            "Epoch 9779/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0237e-08 \n",
            "Epoch 9780/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0265e-08 \n",
            "Epoch 9781/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9702e-09 \n",
            "Epoch 9782/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0939e-09 \n",
            "Epoch 9783/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0177e-09 \n",
            "Epoch 9784/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9276e-09 \n",
            "Epoch 9785/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8632e-09 \n",
            "Epoch 9786/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1457e-08 \n",
            "Epoch 9787/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1201e-08 \n",
            "Epoch 9788/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2324e-09 \n",
            "Epoch 9789/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5323e-09 \n",
            "Epoch 9790/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3850e-09 \n",
            "Epoch 9791/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4134e-09 \n",
            "Epoch 9792/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8098e-09 \n",
            "Epoch 9793/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9828e-09 \n",
            "Epoch 9794/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2950e-09 \n",
            "Epoch 9795/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0284e-08 \n",
            "Epoch 9796/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2149e-09 \n",
            "Epoch 9797/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4930e-09 \n",
            "Epoch 9798/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1648e-09 \n",
            "Epoch 9799/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3045e-09 \n",
            "Epoch 9800/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Test accuracy at epoch 9800: 32.67%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.4092e-09\n",
            "Epoch 9801/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6650e-09 \n",
            "Epoch 9802/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9656e-09 \n",
            "Epoch 9803/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7818e-09 \n",
            "Epoch 9804/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4477e-09 \n",
            "Epoch 9805/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3698e-09 \n",
            "Epoch 9806/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3789e-09 \n",
            "Epoch 9807/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4505e-09 \n",
            "Epoch 9808/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6370e-09 \n",
            "Epoch 9809/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3048e-09 \n",
            "Epoch 9810/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4023e-09 \n",
            "Epoch 9811/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9323e-09 \n",
            "Epoch 9812/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1803e-09 \n",
            "Epoch 9813/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4699e-09 \n",
            "Epoch 9814/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8643e-09 \n",
            "Epoch 9815/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5130e-09 \n",
            "Epoch 9816/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3066e-09 \n",
            "Epoch 9817/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1048e-09 \n",
            "Epoch 9818/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4458e-09 \n",
            "Epoch 9819/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7384e-09 \n",
            "Epoch 9820/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9129e-09 \n",
            "Epoch 9821/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2639e-09 \n",
            "Epoch 9822/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5230e-09 \n",
            "Epoch 9823/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4279e-09 \n",
            "Epoch 9824/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3893e-09 \n",
            "Epoch 9825/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1000e-09 \n",
            "Epoch 9826/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3242e-09 \n",
            "Epoch 9827/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5554e-09 \n",
            "Epoch 9828/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7379e-09 \n",
            "Epoch 9829/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7759e-09 \n",
            "Epoch 9830/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6430e-09 \n",
            "Epoch 9831/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4060e-09 \n",
            "Epoch 9832/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0131e-09 \n",
            "Epoch 9833/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2846e-09 \n",
            "Epoch 9834/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2845e-09 \n",
            "Epoch 9835/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0063e-09 \n",
            "Epoch 9836/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7730e-09 \n",
            "Epoch 9837/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5743e-09 \n",
            "Epoch 9838/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1639e-09 \n",
            "Epoch 9839/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7815e-09 \n",
            "Epoch 9840/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2259e-09 \n",
            "Epoch 9841/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8005e-09 \n",
            "Epoch 9842/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2821e-09 \n",
            "Epoch 9843/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7094e-09 \n",
            "Epoch 9844/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7469e-09 \n",
            "Epoch 9845/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3400e-09 \n",
            "Epoch 9846/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3857e-09 \n",
            "Epoch 9847/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8340e-09 \n",
            "Epoch 9848/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2767e-09 \n",
            "Epoch 9849/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6002e-09 \n",
            "Epoch 9850/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6187e-09 \n",
            "Epoch 9851/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4993e-09 \n",
            "Epoch 9852/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4311e-09 \n",
            "Epoch 9853/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3417e-09 \n",
            "Epoch 9854/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8948e-09 \n",
            "Epoch 9855/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2273e-09 \n",
            "Epoch 9856/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6371e-09 \n",
            "Epoch 9857/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6054e-09 \n",
            "Epoch 9858/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5480e-09 \n",
            "Epoch 9859/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5344e-09 \n",
            "Epoch 9860/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5899e-09 \n",
            "Epoch 9861/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4236e-09 \n",
            "Epoch 9862/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4988e-09 \n",
            "Epoch 9863/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0274e-09 \n",
            "Epoch 9864/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2618e-09 \n",
            "Epoch 9865/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1018e-09 \n",
            "Epoch 9866/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0222e-09 \n",
            "Epoch 9867/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1024e-09 \n",
            "Epoch 9868/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8811e-09 \n",
            "Epoch 9869/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9072e-09 \n",
            "Epoch 9870/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4435e-09 \n",
            "Epoch 9871/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5938e-09 \n",
            "Epoch 9872/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9142e-09 \n",
            "Epoch 9873/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5375e-09 \n",
            "Epoch 9874/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2793e-09 \n",
            "Epoch 9875/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5614e-09 \n",
            "Epoch 9876/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0443e-09 \n",
            "Epoch 9877/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5969e-09 \n",
            "Epoch 9878/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1200e-09 \n",
            "Epoch 9879/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4949e-09 \n",
            "Epoch 9880/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1129e-09 \n",
            "Epoch 9881/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9124e-09 \n",
            "Epoch 9882/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5254e-09 \n",
            "Epoch 9883/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0249e-09 \n",
            "Epoch 9884/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0978e-09 \n",
            "Epoch 9885/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8502e-09 \n",
            "Epoch 9886/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3988e-09 \n",
            "Epoch 9887/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9393e-09 \n",
            "Epoch 9888/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5556e-09 \n",
            "Epoch 9889/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1980e-09 \n",
            "Epoch 9890/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6890e-09 \n",
            "Epoch 9891/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6144e-09 \n",
            "Epoch 9892/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1413e-09 \n",
            "Epoch 9893/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1046e-09 \n",
            "Epoch 9894/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7260e-09 \n",
            "Epoch 9895/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3181e-09 \n",
            "Epoch 9896/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2014e-09 \n",
            "Epoch 9897/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1583e-09 \n",
            "Epoch 9898/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2430e-09 \n",
            "Epoch 9899/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8969e-09 \n",
            "Epoch 9900/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.7253e-09\n",
            "Test accuracy at epoch 9900: 32.76%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.5093e-09\n",
            "Epoch 9901/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6084e-09 \n",
            "Epoch 9902/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9017e-09 \n",
            "Epoch 9903/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8201e-09 \n",
            "Epoch 9904/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9880e-09 \n",
            "Epoch 9905/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9971e-09 \n",
            "Epoch 9906/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6139e-09 \n",
            "Epoch 9907/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3732e-09 \n",
            "Epoch 9908/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4308e-09 \n",
            "Epoch 9909/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5361e-09 \n",
            "Epoch 9910/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9502e-09 \n",
            "Epoch 9911/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5958e-09 \n",
            "Epoch 9912/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2331e-09 \n",
            "Epoch 9913/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4626e-09 \n",
            "Epoch 9914/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9987e-09 \n",
            "Epoch 9915/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0027e-09 \n",
            "Epoch 9916/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7523e-09 \n",
            "Epoch 9917/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5766e-09 \n",
            "Epoch 9918/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8493e-09 \n",
            "Epoch 9919/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9548e-09 \n",
            "Epoch 9920/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3130e-09 \n",
            "Epoch 9921/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5544e-09 \n",
            "Epoch 9922/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2422e-09 \n",
            "Epoch 9923/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0117e-09 \n",
            "Epoch 9924/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0712e-09 \n",
            "Epoch 9925/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3359e-09 \n",
            "Epoch 9926/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3150e-09 \n",
            "Epoch 9927/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3256e-09 \n",
            "Epoch 9928/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6561e-09 \n",
            "Epoch 9929/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7303e-09 \n",
            "Epoch 9930/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0642e-09 \n",
            "Epoch 9931/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5862e-09 \n",
            "Epoch 9932/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0614e-09 \n",
            "Epoch 9933/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8993e-09 \n",
            "Epoch 9934/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6235e-09 \n",
            "Epoch 9935/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9869e-09 \n",
            "Epoch 9936/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0649e-09 \n",
            "Epoch 9937/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5806e-09 \n",
            "Epoch 9938/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7529e-09 \n",
            "Epoch 9939/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7941e-09 \n",
            "Epoch 9940/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1296e-09 \n",
            "Epoch 9941/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0972e-09 \n",
            "Epoch 9942/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4315e-09 \n",
            "Epoch 9943/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3713e-09 \n",
            "Epoch 9944/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7568e-09 \n",
            "Epoch 9945/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3771e-09 \n",
            "Epoch 9946/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6308e-09 \n",
            "Epoch 9947/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4475e-09 \n",
            "Epoch 9948/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7985e-09 \n",
            "Epoch 9949/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8712e-09 \n",
            "Epoch 9950/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8697e-09 \n",
            "Epoch 9951/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2678e-09 \n",
            "Epoch 9952/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3477e-09 \n",
            "Epoch 9953/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7705e-09 \n",
            "Epoch 9954/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1141e-09 \n",
            "Epoch 9955/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1739e-09 \n",
            "Epoch 9956/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5340e-09 \n",
            "Epoch 9957/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6363e-09 \n",
            "Epoch 9958/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4559e-09 \n",
            "Epoch 9959/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4159e-09 \n",
            "Epoch 9960/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4243e-09 \n",
            "Epoch 9961/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5900e-09 \n",
            "Epoch 9962/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0280e-09 \n",
            "Epoch 9963/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0509e-09 \n",
            "Epoch 9964/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5497e-09 \n",
            "Epoch 9965/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0074e-09 \n",
            "Epoch 9966/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1767e-09 \n",
            "Epoch 9967/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9396e-09 \n",
            "Epoch 9968/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0593e-09 \n",
            "Epoch 9969/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8933e-09 \n",
            "Epoch 9970/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3222e-09 \n",
            "Epoch 9971/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8222e-09 \n",
            "Epoch 9972/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1346e-09 \n",
            "Epoch 9973/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4697e-09 \n",
            "Epoch 9974/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9579e-09 \n",
            "Epoch 9975/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1412e-09 \n",
            "Epoch 9976/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4686e-09 \n",
            "Epoch 9977/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6565e-09 \n",
            "Epoch 9978/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1035e-09 \n",
            "Epoch 9979/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0180e-09 \n",
            "Epoch 9980/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4513e-09 \n",
            "Epoch 9981/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1848e-09 \n",
            "Epoch 9982/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9383e-08 \n",
            "Epoch 9983/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5341e-09 \n",
            "Epoch 9984/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4090e-09 \n",
            "Epoch 9985/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7795e-09 \n",
            "Epoch 9986/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8237e-09 \n",
            "Epoch 9987/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5177e-09 \n",
            "Epoch 9988/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3971e-09 \n",
            "Epoch 9989/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3527e-09 \n",
            "Epoch 9990/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6186e-09 \n",
            "Epoch 9991/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2551e-09 \n",
            "Epoch 9992/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9221e-09 \n",
            "Epoch 9993/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6123e-09 \n",
            "Epoch 9994/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5592e-09 \n",
            "Epoch 9995/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8854e-09 \n",
            "Epoch 9996/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2374e-09 \n",
            "Epoch 9997/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2037e-08 \n",
            "Epoch 9998/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2516e-08 \n",
            "Epoch 9999/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6738e-09 \n",
            "Epoch 10000/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.4506e-09\n",
            "Test accuracy at epoch 10000: 32.88%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.0266e-09\n"
          ]
        }
      ],
      "source": [
        "model_baseline.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "base_line_hist=model_baseline.fit(X_train_label, y_train_label, epochs=10000,callbacks=[baseline(test_data)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8DtA-PiCXbk",
        "outputId": "2e69c30e-0d65-4cda-a171-5f9b34ca68c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cifar_baseline_model_saved\n"
          ]
        }
      ],
      "source": [
        "model_baseline.save('cifar_baseline_trained_model.h5')\n",
        "print(\"cifar_baseline_model_saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUAnuiKYPsMi",
        "outputId": "174f9292-ddce-464b-9be1-6778dd696731"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "pretext_model = models.load_model('cifar10_unlabble_trained_model (2).h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nU0RyhzuR8S"
      },
      "source": [
        "Applying transfer learning and agjusting the learning rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDCNyDRw14Ck"
      },
      "source": [
        "Process i followed for transfer learning is.\n",
        "1. I have loaded the weights of pre text model into the new model architecture.\n",
        "2. Then intialized freezed the traning layers of the new model by just keeping the classification layer actve. Now i trained the model on 1e-3 learning rate.\n",
        "3. Later i have unfreezed all the layers and trained the model on 1e-5 learning rate.\n",
        "This helps in adjusting the leanring rates while performing transfer learning.\n",
        "\n",
        "I have also tried to develop a custom training function that could train various layers with customized learning rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCtGM5cgDdBc",
        "outputId": "ea12bc67-44b8-4047-d165-1882552995bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model_transfer_learning = models.Sequential([\n",
        "    layers.Conv2D(10, (5,5), strides=1,activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Conv2D(10,(5,5),strides=1,activation='relu'),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(20, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax',kernel_initializer=tf.keras.initializers.HeNormal())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9t23U39urNs"
      },
      "outputs": [],
      "source": [
        "for layer_new, layer_pretext in zip(model_transfer_learning.layers[:-1], pretext_model.layers[:-1]):\n",
        "    if layer_new.trainable and len(layer_new.get_weights()) > 0:\n",
        "        layer_new.set_weights(layer_pretext.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylLpA-b1E06f"
      },
      "outputs": [],
      "source": [
        "for layer in model_transfer_learning.layers[:-1]:\n",
        "    layer.trainable = False  # Unfreeze all layers in the pretext model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOR134L0qKrc"
      },
      "outputs": [],
      "source": [
        "model_transfer_learning.layers[-1].trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jo7RCQk9QAYJ"
      },
      "outputs": [],
      "source": [
        "# Step 4: Re-compile the pretext model with a low learning rate (1e-6)\n",
        "from tensorflow.keras import optimizers\n",
        "model_transfer_learning.compile(optimizer=optimizers.Adam(learning_rate=1e-3),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jrybXNmS89O",
        "outputId": "aba93879-b008-4a3c-d99d-9d6a7c9c488b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3681 - loss: 1.8172 \n",
            "Epoch 2/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3499 - loss: 1.8239 \n",
            "Epoch 3/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3806 - loss: 1.8034 \n",
            "Epoch 4/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3537 - loss: 1.7691 \n",
            "Epoch 5/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3821 - loss: 1.7050 \n",
            "Epoch 6/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3736 - loss: 1.7951 \n",
            "Epoch 7/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3585 - loss: 1.7439 \n",
            "Epoch 8/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3466 - loss: 1.8046 \n",
            "Epoch 9/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4068 - loss: 1.7190 \n",
            "Epoch 10/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3809 - loss: 1.7361 \n",
            "Epoch 11/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3612 - loss: 1.8426 \n",
            "Epoch 12/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3858 - loss: 1.7595 \n",
            "Epoch 13/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3826 - loss: 1.7442 \n",
            "Epoch 14/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3899 - loss: 1.7345 \n",
            "Epoch 15/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3864 - loss: 1.7501 \n",
            "Epoch 16/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4150 - loss: 1.7626 \n",
            "Epoch 17/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3906 - loss: 1.7146 \n",
            "Epoch 18/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3924 - loss: 1.6892 \n",
            "Epoch 19/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3597 - loss: 1.7718 \n",
            "Epoch 20/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4032 - loss: 1.7765 \n",
            "Epoch 21/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4326 - loss: 1.6561 \n",
            "Epoch 22/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3916 - loss: 1.6973 \n",
            "Epoch 23/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3655 - loss: 1.7039 \n",
            "Epoch 24/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3959 - loss: 1.7668 \n",
            "Epoch 25/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3639 - loss: 1.7139 \n",
            "Epoch 26/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4305 - loss: 1.6552 \n",
            "Epoch 27/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3958 - loss: 1.6958 \n",
            "Epoch 28/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4212 - loss: 1.6423 \n",
            "Epoch 29/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4380 - loss: 1.6528 \n",
            "Epoch 30/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4144 - loss: 1.7231 \n",
            "Epoch 31/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4246 - loss: 1.6558 \n",
            "Epoch 32/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4001 - loss: 1.6555 \n",
            "Epoch 33/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4132 - loss: 1.6762 \n",
            "Epoch 34/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4119 - loss: 1.6784 \n",
            "Epoch 35/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4162 - loss: 1.6418 \n",
            "Epoch 36/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4220 - loss: 1.6257 \n",
            "Epoch 37/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4133 - loss: 1.6384 \n",
            "Epoch 38/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3983 - loss: 1.6722 \n",
            "Epoch 39/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4029 - loss: 1.6804 \n",
            "Epoch 40/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4254 - loss: 1.6613 \n",
            "Epoch 41/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4463 - loss: 1.6155 \n",
            "Epoch 42/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4015 - loss: 1.6997 \n",
            "Epoch 43/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4024 - loss: 1.6826 \n",
            "Epoch 44/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3966 - loss: 1.6918 \n",
            "Epoch 45/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4098 - loss: 1.6258 \n",
            "Epoch 46/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4191 - loss: 1.6731 \n",
            "Epoch 47/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3944 - loss: 1.7032 \n",
            "Epoch 48/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4222 - loss: 1.5895 \n",
            "Epoch 49/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4232 - loss: 1.6745 \n",
            "Epoch 50/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4206 - loss: 1.6340 \n",
            "Epoch 51/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4172 - loss: 1.6465 \n",
            "Epoch 52/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4143 - loss: 1.6217 \n",
            "Epoch 53/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3871 - loss: 1.7108 \n",
            "Epoch 54/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4423 - loss: 1.6185 \n",
            "Epoch 55/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4097 - loss: 1.7223 \n",
            "Epoch 56/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4470 - loss: 1.5845\n",
            "Epoch 57/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4286 - loss: 1.6662 \n",
            "Epoch 58/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4285 - loss: 1.6003 \n",
            "Epoch 59/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4335 - loss: 1.5956 \n",
            "Epoch 60/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4256 - loss: 1.6002 \n",
            "Epoch 61/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4174 - loss: 1.6407 \n",
            "Epoch 62/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4254 - loss: 1.6075 \n",
            "Epoch 63/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4360 - loss: 1.5997 \n",
            "Epoch 64/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4049 - loss: 1.6870 \n",
            "Epoch 65/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4158 - loss: 1.6686 \n",
            "Epoch 66/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4307 - loss: 1.6173 \n",
            "Epoch 67/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3978 - loss: 1.7386 \n",
            "Epoch 68/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4342 - loss: 1.6288 \n",
            "Epoch 69/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4281 - loss: 1.6600 \n",
            "Epoch 70/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4157 - loss: 1.6597 \n",
            "Epoch 71/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4069 - loss: 1.6746 \n",
            "Epoch 72/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4316 - loss: 1.6198 \n",
            "Epoch 73/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4311 - loss: 1.6023 \n",
            "Epoch 74/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4193 - loss: 1.6410 \n",
            "Epoch 75/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4104 - loss: 1.6328 \n",
            "Epoch 76/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4218 - loss: 1.6089 \n",
            "Epoch 77/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3822 - loss: 1.6991 \n",
            "Epoch 78/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4198 - loss: 1.6623 \n",
            "Epoch 79/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4265 - loss: 1.5888 \n",
            "Epoch 80/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4118 - loss: 1.6501 \n",
            "Epoch 81/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4123 - loss: 1.6463 \n",
            "Epoch 82/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3819 - loss: 1.6914 \n",
            "Epoch 83/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4160 - loss: 1.7186 \n",
            "Epoch 84/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3980 - loss: 1.6964 \n",
            "Epoch 85/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4261 - loss: 1.6139 \n",
            "Epoch 86/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4058 - loss: 1.6629 \n",
            "Epoch 87/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4144 - loss: 1.6651 \n",
            "Epoch 88/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3959 - loss: 1.6834 \n",
            "Epoch 89/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3820 - loss: 1.6872 \n",
            "Epoch 90/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3963 - loss: 1.6368 \n",
            "Epoch 91/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4179 - loss: 1.6417 \n",
            "Epoch 92/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4114 - loss: 1.6722 \n",
            "Epoch 93/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4220 - loss: 1.6878 \n",
            "Epoch 94/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4322 - loss: 1.6246 \n",
            "Epoch 95/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3691 - loss: 1.6496 \n",
            "Epoch 96/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3895 - loss: 1.6368 \n",
            "Epoch 97/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4263 - loss: 1.6288 \n",
            "Epoch 98/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3981 - loss: 1.6473 \n",
            "Epoch 99/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4210 - loss: 1.6582 \n",
            "Epoch 100/200\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3125 - loss: 1.5912\n",
            "Test accuracy at epoch 100: 28.33%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.3899 - loss: 1.6323\n",
            "Epoch 101/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4303 - loss: 1.6103 \n",
            "Epoch 102/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4219 - loss: 1.6236 \n",
            "Epoch 103/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4517 - loss: 1.6155 \n",
            "Epoch 104/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4158 - loss: 1.6134 \n",
            "Epoch 105/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4111 - loss: 1.6421 \n",
            "Epoch 106/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4141 - loss: 1.6633 \n",
            "Epoch 107/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4164 - loss: 1.6506 \n",
            "Epoch 108/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4025 - loss: 1.6735 \n",
            "Epoch 109/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4148 - loss: 1.6487 \n",
            "Epoch 110/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4333 - loss: 1.5895 \n",
            "Epoch 111/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4042 - loss: 1.6543 \n",
            "Epoch 112/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4217 - loss: 1.6197 \n",
            "Epoch 113/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4067 - loss: 1.6299 \n",
            "Epoch 114/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4135 - loss: 1.6957 \n",
            "Epoch 115/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4192 - loss: 1.6191 \n",
            "Epoch 116/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3838 - loss: 1.6547 \n",
            "Epoch 117/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4028 - loss: 1.7018 \n",
            "Epoch 118/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4125 - loss: 1.5958 \n",
            "Epoch 119/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4201 - loss: 1.5919 \n",
            "Epoch 120/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3762 - loss: 1.7666 \n",
            "Epoch 121/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4145 - loss: 1.6533 \n",
            "Epoch 122/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4299 - loss: 1.6071 \n",
            "Epoch 123/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4089 - loss: 1.6118 \n",
            "Epoch 124/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4119 - loss: 1.6552 \n",
            "Epoch 125/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4055 - loss: 1.6808 \n",
            "Epoch 126/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4180 - loss: 1.6597 \n",
            "Epoch 127/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4132 - loss: 1.6101 \n",
            "Epoch 128/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3782 - loss: 1.7231 \n",
            "Epoch 129/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4596 - loss: 1.5977 \n",
            "Epoch 130/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4207 - loss: 1.6193 \n",
            "Epoch 131/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4157 - loss: 1.6358 \n",
            "Epoch 132/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4421 - loss: 1.6644 \n",
            "Epoch 133/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4176 - loss: 1.6441 \n",
            "Epoch 134/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4330 - loss: 1.6151 \n",
            "Epoch 135/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4393 - loss: 1.6113 \n",
            "Epoch 136/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3985 - loss: 1.6836 \n",
            "Epoch 137/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3995 - loss: 1.6485 \n",
            "Epoch 138/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4166 - loss: 1.6005 \n",
            "Epoch 139/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4544 - loss: 1.6000 \n",
            "Epoch 140/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4266 - loss: 1.6011 \n",
            "Epoch 141/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4083 - loss: 1.5897 \n",
            "Epoch 142/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4286 - loss: 1.5887 \n",
            "Epoch 143/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4156 - loss: 1.6110 \n",
            "Epoch 144/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4157 - loss: 1.6723 \n",
            "Epoch 145/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4242 - loss: 1.6080 \n",
            "Epoch 146/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4214 - loss: 1.6248 \n",
            "Epoch 147/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3832 - loss: 1.6774 \n",
            "Epoch 148/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4052 - loss: 1.6463 \n",
            "Epoch 149/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4003 - loss: 1.6388 \n",
            "Epoch 150/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4109 - loss: 1.6235 \n",
            "Epoch 151/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4449 - loss: 1.6050 \n",
            "Epoch 152/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4242 - loss: 1.5885 \n",
            "Epoch 153/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4360 - loss: 1.6050 \n",
            "Epoch 154/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4014 - loss: 1.7122 \n",
            "Epoch 155/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4494 - loss: 1.5853 \n",
            "Epoch 156/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3885 - loss: 1.6839 \n",
            "Epoch 157/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4149 - loss: 1.6253 \n",
            "Epoch 158/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4066 - loss: 1.6409 \n",
            "Epoch 159/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4098 - loss: 1.6437 \n",
            "Epoch 160/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3988 - loss: 1.6475 \n",
            "Epoch 161/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3911 - loss: 1.6776 \n",
            "Epoch 162/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4318 - loss: 1.6111 \n",
            "Epoch 163/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3987 - loss: 1.6054 \n",
            "Epoch 164/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4373 - loss: 1.5858 \n",
            "Epoch 165/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3921 - loss: 1.6598 \n",
            "Epoch 166/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4504 - loss: 1.5355 \n",
            "Epoch 167/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4216 - loss: 1.6395 \n",
            "Epoch 168/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4197 - loss: 1.6356 \n",
            "Epoch 169/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3870 - loss: 1.6486 \n",
            "Epoch 170/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4101 - loss: 1.6193 \n",
            "Epoch 171/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3967 - loss: 1.6623 \n",
            "Epoch 172/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4149 - loss: 1.6334 \n",
            "Epoch 173/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4459 - loss: 1.5889 \n",
            "Epoch 174/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4388 - loss: 1.6348 \n",
            "Epoch 175/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4389 - loss: 1.6035 \n",
            "Epoch 176/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4316 - loss: 1.5823 \n",
            "Epoch 177/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4219 - loss: 1.6284 \n",
            "Epoch 178/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4134 - loss: 1.6567 \n",
            "Epoch 179/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4240 - loss: 1.5975 \n",
            "Epoch 180/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4572 - loss: 1.5839 \n",
            "Epoch 181/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4631 - loss: 1.5951 \n",
            "Epoch 182/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4043 - loss: 1.6181 \n",
            "Epoch 183/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3945 - loss: 1.6041 \n",
            "Epoch 184/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4237 - loss: 1.6009 \n",
            "Epoch 185/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3822 - loss: 1.6352 \n",
            "Epoch 186/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4177 - loss: 1.6395 \n",
            "Epoch 187/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4132 - loss: 1.6149 \n",
            "Epoch 188/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4229 - loss: 1.5797 \n",
            "Epoch 189/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4223 - loss: 1.6021 \n",
            "Epoch 190/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4242 - loss: 1.5970 \n",
            "Epoch 191/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4134 - loss: 1.6542 \n",
            "Epoch 192/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4337 - loss: 1.5881 \n",
            "Epoch 193/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4346 - loss: 1.6138 \n",
            "Epoch 194/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4444 - loss: 1.6014 \n",
            "Epoch 195/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4441 - loss: 1.5740 \n",
            "Epoch 196/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4293 - loss: 1.6089 \n",
            "Epoch 197/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4231 - loss: 1.5975 \n",
            "Epoch 198/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3865 - loss: 1.6344 \n",
            "Epoch 199/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4326 - loss: 1.6295 \n",
            "Epoch 200/200\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3750 - loss: 1.5956\n",
            "Test accuracy at epoch 200: 28.27%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.4034 - loss: 1.6240\n"
          ]
        }
      ],
      "source": [
        "Train_classfier=model_transfer_learning.fit(X_train_label, y_train_label, epochs=200,callbacks=[pretrained(test_data)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7RwA6JXQJx7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "model_transfer_learning.compile(optimizer=optimizers.Adam(learning_rate=1e-5),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh9IwUeqrcfb"
      },
      "outputs": [],
      "source": [
        "for layer in model_transfer_learning.layers[:-1]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5c1S_UTrnf7"
      },
      "outputs": [],
      "source": [
        "model_transfer_learning.layers[-1].trainable=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzGtCVyKPpp-",
        "outputId": "3e5f6747-8b04-4d63-f5c6-ac371f524f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 7526/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1146e-04 \n",
            "Epoch 7527/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0554e-04 \n",
            "Epoch 7528/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7431e-04 \n",
            "Epoch 7529/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7925e-04 \n",
            "Epoch 7530/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5752e-04 \n",
            "Epoch 7531/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5542e-04 \n",
            "Epoch 7532/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9792e-04 \n",
            "Epoch 7533/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7105e-04 \n",
            "Epoch 7534/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3289e-04 \n",
            "Epoch 7535/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6533e-04 \n",
            "Epoch 7536/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2284e-04 \n",
            "Epoch 7537/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8199e-04 \n",
            "Epoch 7538/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1047e-04 \n",
            "Epoch 7539/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8657e-04 \n",
            "Epoch 7540/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1272e-04 \n",
            "Epoch 7541/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0862e-04 \n",
            "Epoch 7542/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5993e-04\n",
            "Epoch 7543/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2339e-04 \n",
            "Epoch 7544/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3567e-04 \n",
            "Epoch 7545/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1420e-04 \n",
            "Epoch 7546/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9429e-04 \n",
            "Epoch 7547/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8023e-04 \n",
            "Epoch 7548/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9607e-04 \n",
            "Epoch 7549/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2234e-04 \n",
            "Epoch 7550/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0028e-04\n",
            "Epoch 7551/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3448e-04\n",
            "Epoch 7552/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4597e-04 \n",
            "Epoch 7553/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9821e-04 \n",
            "Epoch 7554/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5398e-04 \n",
            "Epoch 7555/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7113e-04 \n",
            "Epoch 7556/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6404e-04\n",
            "Epoch 7557/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5802e-04 \n",
            "Epoch 7558/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1511e-04 \n",
            "Epoch 7559/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3748e-04 \n",
            "Epoch 7560/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3261e-04 \n",
            "Epoch 7561/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5334e-04 \n",
            "Epoch 7562/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0677e-04 \n",
            "Epoch 7563/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9458e-04 \n",
            "Epoch 7564/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4962e-04 \n",
            "Epoch 7565/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5967e-04 \n",
            "Epoch 7566/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0031e-04 \n",
            "Epoch 7567/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1381e-04 \n",
            "Epoch 7568/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3127e-04\n",
            "Epoch 7569/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2314e-04 \n",
            "Epoch 7570/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9764e-04 \n",
            "Epoch 7571/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5220e-04 \n",
            "Epoch 7572/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1741e-04\n",
            "Epoch 7573/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2587e-04 \n",
            "Epoch 7574/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2073e-04 \n",
            "Epoch 7575/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9462e-04\n",
            "Epoch 7576/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8977e-04\n",
            "Epoch 7577/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9209e-04 \n",
            "Epoch 7578/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3190e-04 \n",
            "Epoch 7579/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9164e-04 \n",
            "Epoch 7580/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3605e-04 \n",
            "Epoch 7581/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4646e-04 \n",
            "Epoch 7582/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1626e-04 \n",
            "Epoch 7583/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7535e-04 \n",
            "Epoch 7584/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2989e-04 \n",
            "Epoch 7585/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0563e-04 \n",
            "Epoch 7586/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0032e-04 \n",
            "Epoch 7587/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3201e-04 \n",
            "Epoch 7588/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1781e-04 \n",
            "Epoch 7589/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8226e-04\n",
            "Epoch 7590/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1433e-04 \n",
            "Epoch 7591/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5308e-04 \n",
            "Epoch 7592/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5422e-04 \n",
            "Epoch 7593/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2853e-04 \n",
            "Epoch 7594/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3495e-04 \n",
            "Epoch 7595/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9037e-04 \n",
            "Epoch 7596/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7810e-04 \n",
            "Epoch 7597/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6395e-04 \n",
            "Epoch 7598/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5119e-04\n",
            "Epoch 7599/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9624e-04\n",
            "Epoch 7600/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.3884e-04\n",
            "Test accuracy at epoch 7600: 33.25%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.8889e-04\n",
            "Epoch 7601/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8626e-04 \n",
            "Epoch 7602/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6471e-04 \n",
            "Epoch 7603/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9801e-04 \n",
            "Epoch 7604/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4087e-04 \n",
            "Epoch 7605/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6319e-04 \n",
            "Epoch 7606/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9285e-04 \n",
            "Epoch 7607/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4167e-04 \n",
            "Epoch 7608/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7329e-04 \n",
            "Epoch 7609/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6099e-04 \n",
            "Epoch 7610/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0812e-04 \n",
            "Epoch 7611/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3417e-04 \n",
            "Epoch 7612/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7414e-04 \n",
            "Epoch 7613/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8966e-04 \n",
            "Epoch 7614/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4413e-04 \n",
            "Epoch 7615/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0925e-04 \n",
            "Epoch 7616/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7899e-04 \n",
            "Epoch 7617/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0430e-04 \n",
            "Epoch 7618/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2497e-04 \n",
            "Epoch 7619/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1877e-04 \n",
            "Epoch 7620/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5507e-04 \n",
            "Epoch 7621/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6018e-04 \n",
            "Epoch 7622/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2764e-04 \n",
            "Epoch 7623/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6404e-04 \n",
            "Epoch 7624/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0718e-04\n",
            "Epoch 7625/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4684e-04 \n",
            "Epoch 7626/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0177e-04 \n",
            "Epoch 7627/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7440e-04 \n",
            "Epoch 7628/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1293e-04 \n",
            "Epoch 7629/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7767e-04 \n",
            "Epoch 7630/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5152e-04 \n",
            "Epoch 7631/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3105e-04 \n",
            "Epoch 7632/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1210e-04 \n",
            "Epoch 7633/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8389e-04 \n",
            "Epoch 7634/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3621e-04\n",
            "Epoch 7635/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9644e-04 \n",
            "Epoch 7636/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0020e-04 \n",
            "Epoch 7637/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9908e-04 \n",
            "Epoch 7638/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1816e-04\n",
            "Epoch 7639/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7845e-04 \n",
            "Epoch 7640/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1165e-04 \n",
            "Epoch 7641/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5974e-04 \n",
            "Epoch 7642/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9911e-04 \n",
            "Epoch 7643/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3052e-04 \n",
            "Epoch 7644/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8852e-04 \n",
            "Epoch 7645/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4137e-04 \n",
            "Epoch 7646/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8979e-04 \n",
            "Epoch 7647/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1593e-04 \n",
            "Epoch 7648/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5462e-04 \n",
            "Epoch 7649/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9898e-04 \n",
            "Epoch 7650/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2596e-04 \n",
            "Epoch 7651/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7476e-04 \n",
            "Epoch 7652/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1275e-04 \n",
            "Epoch 7653/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5052e-04 \n",
            "Epoch 7654/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1425e-04 \n",
            "Epoch 7655/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7724e-04 \n",
            "Epoch 7656/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0992e-04 \n",
            "Epoch 7657/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4164e-04 \n",
            "Epoch 7658/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0162e-04 \n",
            "Epoch 7659/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0097e-04 \n",
            "Epoch 7660/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2929e-04 \n",
            "Epoch 7661/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7939e-04 \n",
            "Epoch 7662/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7000e-04 \n",
            "Epoch 7663/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4747e-04 \n",
            "Epoch 7664/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8410e-04 \n",
            "Epoch 7665/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5194e-04 \n",
            "Epoch 7666/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5100e-04 \n",
            "Epoch 7667/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9320e-04 \n",
            "Epoch 7668/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5794e-04 \n",
            "Epoch 7669/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8868e-04 \n",
            "Epoch 7670/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9231e-04 \n",
            "Epoch 7671/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9331e-04 \n",
            "Epoch 7672/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4740e-04 \n",
            "Epoch 7673/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0955e-04 \n",
            "Epoch 7674/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7598e-04 \n",
            "Epoch 7675/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1350e-04 \n",
            "Epoch 7676/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1557e-04 \n",
            "Epoch 7677/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6344e-04 \n",
            "Epoch 7678/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2617e-04 \n",
            "Epoch 7679/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4612e-04 \n",
            "Epoch 7680/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1801e-04 \n",
            "Epoch 7681/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5242e-04\n",
            "Epoch 7682/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5280e-04 \n",
            "Epoch 7683/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6940e-04 \n",
            "Epoch 7684/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5710e-04 \n",
            "Epoch 7685/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2594e-04 \n",
            "Epoch 7686/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6552e-04 \n",
            "Epoch 7687/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9719e-04 \n",
            "Epoch 7688/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7885e-04 \n",
            "Epoch 7689/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8719e-04 \n",
            "Epoch 7690/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1533e-04 \n",
            "Epoch 7691/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4944e-04\n",
            "Epoch 7692/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8135e-04 \n",
            "Epoch 7693/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5023e-04 \n",
            "Epoch 7694/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5072e-04 \n",
            "Epoch 7695/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9120e-04 \n",
            "Epoch 7696/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8178e-04 \n",
            "Epoch 7697/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3503e-04\n",
            "Epoch 7698/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4791e-04 \n",
            "Epoch 7699/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8107e-04 \n",
            "Epoch 7700/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.1896e-04\n",
            "Test accuracy at epoch 7700: 33.18%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.9559e-04\n",
            "Epoch 7701/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3956e-04 \n",
            "Epoch 7702/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5516e-04 \n",
            "Epoch 7703/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6867e-04 \n",
            "Epoch 7704/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9310e-04 \n",
            "Epoch 7705/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4506e-04 \n",
            "Epoch 7706/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6504e-04 \n",
            "Epoch 7707/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0297e-04 \n",
            "Epoch 7708/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2136e-04 \n",
            "Epoch 7709/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3870e-04 \n",
            "Epoch 7710/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5246e-04 \n",
            "Epoch 7711/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1203e-04 \n",
            "Epoch 7712/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5327e-04 \n",
            "Epoch 7713/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9292e-04 \n",
            "Epoch 7714/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2166e-04 \n",
            "Epoch 7715/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1459e-04 \n",
            "Epoch 7716/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2704e-04 \n",
            "Epoch 7717/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2704e-04 \n",
            "Epoch 7718/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5348e-04 \n",
            "Epoch 7719/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7079e-04 \n",
            "Epoch 7720/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6774e-04 \n",
            "Epoch 7721/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0076e-04 \n",
            "Epoch 7722/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0116e-04 \n",
            "Epoch 7723/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0369e-04 \n",
            "Epoch 7724/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0220e-04 \n",
            "Epoch 7725/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0370e-04 \n",
            "Epoch 7726/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1761e-04 \n",
            "Epoch 7727/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1745e-04 \n",
            "Epoch 7728/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1430e-04 \n",
            "Epoch 7729/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2954e-04 \n",
            "Epoch 7730/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8856e-04 \n",
            "Epoch 7731/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0433e-04 \n",
            "Epoch 7732/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7440e-04 \n",
            "Epoch 7733/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3508e-04 \n",
            "Epoch 7734/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9382e-04 \n",
            "Epoch 7735/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5358e-04 \n",
            "Epoch 7736/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5504e-04 \n",
            "Epoch 7737/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8994e-04 \n",
            "Epoch 7738/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4299e-04 \n",
            "Epoch 7739/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1659e-04 \n",
            "Epoch 7740/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8131e-04 \n",
            "Epoch 7741/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3799e-04 \n",
            "Epoch 7742/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9175e-04 \n",
            "Epoch 7743/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9355e-04 \n",
            "Epoch 7744/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3658e-04 \n",
            "Epoch 7745/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8145e-04 \n",
            "Epoch 7746/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8348e-04 \n",
            "Epoch 7747/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5472e-04 \n",
            "Epoch 7748/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6460e-04 \n",
            "Epoch 7749/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7246e-04 \n",
            "Epoch 7750/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8579e-04 \n",
            "Epoch 7751/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3070e-04 \n",
            "Epoch 7752/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3115e-04 \n",
            "Epoch 7753/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8742e-04 \n",
            "Epoch 7754/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8684e-04 \n",
            "Epoch 7755/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8344e-04 \n",
            "Epoch 7756/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6863e-04 \n",
            "Epoch 7757/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7843e-04 \n",
            "Epoch 7758/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4673e-04 \n",
            "Epoch 7759/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8371e-04 \n",
            "Epoch 7760/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0271e-04 \n",
            "Epoch 7761/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1399e-04 \n",
            "Epoch 7762/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1669e-04 \n",
            "Epoch 7763/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0948e-04 \n",
            "Epoch 7764/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0695e-04 \n",
            "Epoch 7765/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7118e-04 \n",
            "Epoch 7766/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6092e-04 \n",
            "Epoch 7767/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0465e-04 \n",
            "Epoch 7768/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5427e-04 \n",
            "Epoch 7769/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6011e-04 \n",
            "Epoch 7770/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1993e-04 \n",
            "Epoch 7771/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0302e-04 \n",
            "Epoch 7772/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2538e-04 \n",
            "Epoch 7773/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9835e-04 \n",
            "Epoch 7774/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2126e-04 \n",
            "Epoch 7775/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8044e-04 \n",
            "Epoch 7776/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7746e-04 \n",
            "Epoch 7777/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5658e-04 \n",
            "Epoch 7778/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2191e-04 \n",
            "Epoch 7779/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6229e-04 \n",
            "Epoch 7780/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7893e-04 \n",
            "Epoch 7781/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0254e-04 \n",
            "Epoch 7782/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6471e-04 \n",
            "Epoch 7783/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3804e-04 \n",
            "Epoch 7784/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7341e-04 \n",
            "Epoch 7785/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7262e-04 \n",
            "Epoch 7786/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3678e-04 \n",
            "Epoch 7787/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1108e-04 \n",
            "Epoch 7788/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6175e-04 \n",
            "Epoch 7789/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0970e-04 \n",
            "Epoch 7790/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5583e-04 \n",
            "Epoch 7791/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9290e-04 \n",
            "Epoch 7792/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7479e-04 \n",
            "Epoch 7793/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1201e-04 \n",
            "Epoch 7794/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3007e-04 \n",
            "Epoch 7795/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4127e-04 \n",
            "Epoch 7796/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4110e-04 \n",
            "Epoch 7797/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0809e-04 \n",
            "Epoch 7798/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4503e-04 \n",
            "Epoch 7799/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9230e-04 \n",
            "Epoch 7800/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.6416e-04\n",
            "Test accuracy at epoch 7800: 33.16%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.6890e-04\n",
            "Epoch 7801/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3103e-04 \n",
            "Epoch 7802/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7867e-04 \n",
            "Epoch 7803/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9749e-04 \n",
            "Epoch 7804/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5759e-04 \n",
            "Epoch 7805/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5813e-04 \n",
            "Epoch 7806/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3730e-04 \n",
            "Epoch 7807/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6486e-04 \n",
            "Epoch 7808/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3468e-04 \n",
            "Epoch 7809/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8478e-04 \n",
            "Epoch 7810/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7546e-04 \n",
            "Epoch 7811/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4199e-04 \n",
            "Epoch 7812/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7208e-04 \n",
            "Epoch 7813/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4721e-04 \n",
            "Epoch 7814/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3959e-04 \n",
            "Epoch 7815/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9522e-04 \n",
            "Epoch 7816/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2291e-04 \n",
            "Epoch 7817/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0327e-04 \n",
            "Epoch 7818/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3599e-04 \n",
            "Epoch 7819/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2274e-04 \n",
            "Epoch 7820/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8737e-04 \n",
            "Epoch 7821/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8986e-04 \n",
            "Epoch 7822/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4446e-04 \n",
            "Epoch 7823/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9148e-04 \n",
            "Epoch 7824/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0457e-04 \n",
            "Epoch 7825/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4817e-04 \n",
            "Epoch 7826/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0785e-04 \n",
            "Epoch 7827/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7297e-04 \n",
            "Epoch 7828/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3276e-04 \n",
            "Epoch 7829/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9751e-04 \n",
            "Epoch 7830/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7990e-04 \n",
            "Epoch 7831/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2624e-04 \n",
            "Epoch 7832/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8357e-04 \n",
            "Epoch 7833/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9018e-04 \n",
            "Epoch 7834/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5679e-04 \n",
            "Epoch 7835/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0086e-04 \n",
            "Epoch 7836/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9966e-04 \n",
            "Epoch 7837/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7806e-04 \n",
            "Epoch 7838/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6059e-04 \n",
            "Epoch 7839/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6493e-04 \n",
            "Epoch 7840/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6945e-04 \n",
            "Epoch 7841/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9197e-04 \n",
            "Epoch 7842/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7530e-04 \n",
            "Epoch 7843/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8362e-04 \n",
            "Epoch 7844/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3617e-04 \n",
            "Epoch 7845/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8323e-04 \n",
            "Epoch 7846/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7303e-04 \n",
            "Epoch 7847/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3303e-04 \n",
            "Epoch 7848/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3011e-04 \n",
            "Epoch 7849/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8480e-04 \n",
            "Epoch 7850/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7151e-04 \n",
            "Epoch 7851/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3372e-04 \n",
            "Epoch 7852/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9888e-04 \n",
            "Epoch 7853/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8560e-04 \n",
            "Epoch 7854/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7890e-04 \n",
            "Epoch 7855/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6702e-04 \n",
            "Epoch 7856/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6249e-04 \n",
            "Epoch 7857/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1951e-04 \n",
            "Epoch 7858/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5088e-04 \n",
            "Epoch 7859/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9159e-04 \n",
            "Epoch 7860/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3978e-04 \n",
            "Epoch 7861/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5926e-04 \n",
            "Epoch 7862/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2098e-04 \n",
            "Epoch 7863/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8150e-04 \n",
            "Epoch 7864/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6862e-04 \n",
            "Epoch 7865/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8260e-04 \n",
            "Epoch 7866/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1316e-04 \n",
            "Epoch 7867/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7621e-04 \n",
            "Epoch 7868/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9129e-04 \n",
            "Epoch 7869/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5635e-04 \n",
            "Epoch 7870/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7215e-04 \n",
            "Epoch 7871/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5736e-04 \n",
            "Epoch 7872/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0300e-04 \n",
            "Epoch 7873/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1302e-04 \n",
            "Epoch 7874/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0870e-04 \n",
            "Epoch 7875/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4445e-04 \n",
            "Epoch 7876/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2580e-04 \n",
            "Epoch 7877/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5162e-04 \n",
            "Epoch 7878/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8234e-04 \n",
            "Epoch 7879/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7301e-04 \n",
            "Epoch 7880/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2721e-04 \n",
            "Epoch 7881/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3514e-04 \n",
            "Epoch 7882/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6172e-04 \n",
            "Epoch 7883/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4586e-04 \n",
            "Epoch 7884/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4700e-04 \n",
            "Epoch 7885/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1915e-04 \n",
            "Epoch 7886/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4582e-04 \n",
            "Epoch 7887/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9897e-04 \n",
            "Epoch 7888/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2573e-04 \n",
            "Epoch 7889/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3340e-04 \n",
            "Epoch 7890/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4631e-04 \n",
            "Epoch 7891/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3323e-04 \n",
            "Epoch 7892/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2317e-04 \n",
            "Epoch 7893/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6719e-04 \n",
            "Epoch 7894/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8069e-04 \n",
            "Epoch 7895/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0943e-04 \n",
            "Epoch 7896/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0401e-04 \n",
            "Epoch 7897/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8871e-04 \n",
            "Epoch 7898/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4759e-04 \n",
            "Epoch 7899/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4143e-04 \n",
            "Epoch 7900/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.5899e-04\n",
            "Test accuracy at epoch 7900: 33.23%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.5488e-04\n",
            "Epoch 7901/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0353e-04 \n",
            "Epoch 7902/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4294e-04 \n",
            "Epoch 7903/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3782e-04 \n",
            "Epoch 7904/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8578e-04 \n",
            "Epoch 7905/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3745e-04 \n",
            "Epoch 7906/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4621e-04 \n",
            "Epoch 7907/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4841e-04 \n",
            "Epoch 7908/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1717e-04 \n",
            "Epoch 7909/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0150e-04 \n",
            "Epoch 7910/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0276e-04 \n",
            "Epoch 7911/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1146e-04 \n",
            "Epoch 7912/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9935e-04 \n",
            "Epoch 7913/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1759e-04 \n",
            "Epoch 7914/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8203e-04 \n",
            "Epoch 7915/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9631e-04 \n",
            "Epoch 7916/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0493e-04 \n",
            "Epoch 7917/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9469e-04 \n",
            "Epoch 7918/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9305e-04 \n",
            "Epoch 7919/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1739e-04 \n",
            "Epoch 7920/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2104e-04 \n",
            "Epoch 7921/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1986e-04 \n",
            "Epoch 7922/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1231e-04 \n",
            "Epoch 7923/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1972e-04 \n",
            "Epoch 7924/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2293e-04 \n",
            "Epoch 7925/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1651e-04 \n",
            "Epoch 7926/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1877e-04 \n",
            "Epoch 7927/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3792e-04 \n",
            "Epoch 7928/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0721e-04 \n",
            "Epoch 7929/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6555e-04 \n",
            "Epoch 7930/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0922e-04 \n",
            "Epoch 7931/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9484e-04 \n",
            "Epoch 7932/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1606e-04 \n",
            "Epoch 7933/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8150e-04 \n",
            "Epoch 7934/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8205e-04 \n",
            "Epoch 7935/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7318e-04 \n",
            "Epoch 7936/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9072e-04 \n",
            "Epoch 7937/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1848e-04 \n",
            "Epoch 7938/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1313e-04 \n",
            "Epoch 7939/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9514e-04 \n",
            "Epoch 7940/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3453e-04 \n",
            "Epoch 7941/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5822e-04 \n",
            "Epoch 7942/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4894e-04 \n",
            "Epoch 7943/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6394e-04 \n",
            "Epoch 7944/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8757e-04 \n",
            "Epoch 7945/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4483e-04 \n",
            "Epoch 7946/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9844e-04 \n",
            "Epoch 7947/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7842e-04 \n",
            "Epoch 7948/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2247e-04 \n",
            "Epoch 7949/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9519e-04 \n",
            "Epoch 7950/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9145e-04 \n",
            "Epoch 7951/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6945e-04 \n",
            "Epoch 7952/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2225e-04 \n",
            "Epoch 7953/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7942e-04 \n",
            "Epoch 7954/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6178e-04 \n",
            "Epoch 7955/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7426e-04 \n",
            "Epoch 7956/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5361e-04 \n",
            "Epoch 7957/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8522e-04 \n",
            "Epoch 7958/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5930e-04 \n",
            "Epoch 7959/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8186e-04 \n",
            "Epoch 7960/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5167e-04 \n",
            "Epoch 7961/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5502e-04 \n",
            "Epoch 7962/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7108e-04 \n",
            "Epoch 7963/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4122e-04 \n",
            "Epoch 7964/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2339e-04 \n",
            "Epoch 7965/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5850e-04 \n",
            "Epoch 7966/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7690e-04 \n",
            "Epoch 7967/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7423e-04 \n",
            "Epoch 7968/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7876e-04 \n",
            "Epoch 7969/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6168e-04 \n",
            "Epoch 7970/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9316e-04 \n",
            "Epoch 7971/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9932e-04 \n",
            "Epoch 7972/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5867e-04 \n",
            "Epoch 7973/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5446e-04 \n",
            "Epoch 7974/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7132e-04 \n",
            "Epoch 7975/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8575e-04 \n",
            "Epoch 7976/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8009e-04 \n",
            "Epoch 7977/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4926e-04 \n",
            "Epoch 7978/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3615e-04 \n",
            "Epoch 7979/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6932e-04 \n",
            "Epoch 7980/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4895e-04 \n",
            "Epoch 7981/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4643e-04 \n",
            "Epoch 7982/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6848e-04 \n",
            "Epoch 7983/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1226e-04 \n",
            "Epoch 7984/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7535e-04 \n",
            "Epoch 7985/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5909e-04 \n",
            "Epoch 7986/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2826e-04 \n",
            "Epoch 7987/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3038e-04 \n",
            "Epoch 7988/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5742e-04 \n",
            "Epoch 7989/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9561e-04 \n",
            "Epoch 7990/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1451e-04 \n",
            "Epoch 7991/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4580e-04 \n",
            "Epoch 7992/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3592e-04 \n",
            "Epoch 7993/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7202e-04 \n",
            "Epoch 7994/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4002e-04 \n",
            "Epoch 7995/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8901e-04 \n",
            "Epoch 7996/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3378e-04 \n",
            "Epoch 7997/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7904e-04 \n",
            "Epoch 7998/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7796e-04 \n",
            "Epoch 7999/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3558e-04 \n",
            "Epoch 8000/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.6842e-04\n",
            "Test accuracy at epoch 8000: 33.29%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7810e-04\n",
            "Epoch 8001/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7032e-04 \n",
            "Epoch 8002/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7124e-04 \n",
            "Epoch 8003/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4592e-04 \n",
            "Epoch 8004/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4177e-04 \n",
            "Epoch 8005/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6258e-04 \n",
            "Epoch 8006/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4685e-04 \n",
            "Epoch 8007/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9655e-04 \n",
            "Epoch 8008/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4845e-04 \n",
            "Epoch 8009/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7377e-04 \n",
            "Epoch 8010/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7791e-04 \n",
            "Epoch 8011/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5379e-04 \n",
            "Epoch 8012/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3655e-04 \n",
            "Epoch 8013/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9853e-04 \n",
            "Epoch 8014/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8822e-04 \n",
            "Epoch 8015/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6155e-04 \n",
            "Epoch 8016/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5388e-04 \n",
            "Epoch 8017/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4001e-04 \n",
            "Epoch 8018/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6006e-04 \n",
            "Epoch 8019/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9058e-04 \n",
            "Epoch 8020/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4790e-04 \n",
            "Epoch 8021/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4897e-04 \n",
            "Epoch 8022/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4933e-04 \n",
            "Epoch 8023/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3836e-04 \n",
            "Epoch 8024/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4251e-04 \n",
            "Epoch 8025/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2881e-04 \n",
            "Epoch 8026/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4765e-04 \n",
            "Epoch 8027/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5032e-04 \n",
            "Epoch 8028/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0249e-04 \n",
            "Epoch 8029/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3493e-04 \n",
            "Epoch 8030/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3566e-04 \n",
            "Epoch 8031/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6790e-04 \n",
            "Epoch 8032/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3286e-04 \n",
            "Epoch 8033/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5574e-04 \n",
            "Epoch 8034/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1914e-04 \n",
            "Epoch 8035/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1965e-04 \n",
            "Epoch 8036/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5781e-04 \n",
            "Epoch 8037/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6586e-04 \n",
            "Epoch 8038/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2485e-04 \n",
            "Epoch 8039/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1515e-04 \n",
            "Epoch 8040/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6475e-04 \n",
            "Epoch 8041/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2967e-04 \n",
            "Epoch 8042/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1243e-04 \n",
            "Epoch 8043/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3848e-04 \n",
            "Epoch 8044/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3674e-04 \n",
            "Epoch 8045/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1963e-04 \n",
            "Epoch 8046/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1803e-04 \n",
            "Epoch 8047/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1448e-04 \n",
            "Epoch 8048/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7225e-04 \n",
            "Epoch 8049/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5360e-04 \n",
            "Epoch 8050/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1487e-04 \n",
            "Epoch 8051/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1666e-04 \n",
            "Epoch 8052/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3896e-04 \n",
            "Epoch 8053/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2767e-04 \n",
            "Epoch 8054/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0591e-04 \n",
            "Epoch 8055/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3101e-04 \n",
            "Epoch 8056/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4327e-04 \n",
            "Epoch 8057/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1268e-04 \n",
            "Epoch 8058/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2027e-04 \n",
            "Epoch 8059/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1700e-04 \n",
            "Epoch 8060/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3245e-04 \n",
            "Epoch 8061/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4775e-04 \n",
            "Epoch 8062/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1722e-04 \n",
            "Epoch 8063/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2102e-04 \n",
            "Epoch 8064/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1309e-04 \n",
            "Epoch 8065/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2546e-04 \n",
            "Epoch 8066/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2776e-04 \n",
            "Epoch 8067/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0863e-04 \n",
            "Epoch 8068/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4138e-04 \n",
            "Epoch 8069/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9752e-04 \n",
            "Epoch 8070/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1647e-04 \n",
            "Epoch 8071/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0984e-04 \n",
            "Epoch 8072/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3603e-04 \n",
            "Epoch 8073/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4681e-04 \n",
            "Epoch 8074/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1101e-04 \n",
            "Epoch 8075/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0028e-04 \n",
            "Epoch 8076/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4049e-04 \n",
            "Epoch 8077/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3738e-04 \n",
            "Epoch 8078/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5157e-04 \n",
            "Epoch 8079/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9394e-04 \n",
            "Epoch 8080/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0257e-04 \n",
            "Epoch 8081/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0397e-04 \n",
            "Epoch 8082/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9748e-04 \n",
            "Epoch 8083/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1644e-04 \n",
            "Epoch 8084/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4073e-04 \n",
            "Epoch 8085/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0088e-04 \n",
            "Epoch 8086/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1902e-04 \n",
            "Epoch 8087/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5239e-04 \n",
            "Epoch 8088/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0821e-04 \n",
            "Epoch 8089/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9184e-04 \n",
            "Epoch 8090/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4304e-04 \n",
            "Epoch 8091/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8522e-04 \n",
            "Epoch 8092/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9252e-04 \n",
            "Epoch 8093/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1569e-04 \n",
            "Epoch 8094/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0624e-04 \n",
            "Epoch 8095/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9511e-04 \n",
            "Epoch 8096/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2774e-04 \n",
            "Epoch 8097/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7936e-04 \n",
            "Epoch 8098/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0213e-04 \n",
            "Epoch 8099/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9216e-04 \n",
            "Epoch 8100/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.4787e-04\n",
            "Test accuracy at epoch 8100: 33.45%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8594e-04\n",
            "Epoch 8101/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2374e-04 \n",
            "Epoch 8102/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7516e-04 \n",
            "Epoch 8103/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1613e-04 \n",
            "Epoch 8104/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7078e-04 \n",
            "Epoch 8105/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9284e-04 \n",
            "Epoch 8106/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2271e-04 \n",
            "Epoch 8107/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0626e-04 \n",
            "Epoch 8108/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8017e-04 \n",
            "Epoch 8109/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9149e-04 \n",
            "Epoch 8110/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6648e-04 \n",
            "Epoch 8111/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0854e-04 \n",
            "Epoch 8112/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7386e-04 \n",
            "Epoch 8113/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8367e-04 \n",
            "Epoch 8114/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8884e-04 \n",
            "Epoch 8115/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9073e-04 \n",
            "Epoch 8116/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8653e-04 \n",
            "Epoch 8117/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0112e-04 \n",
            "Epoch 8118/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8866e-04 \n",
            "Epoch 8119/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0407e-04 \n",
            "Epoch 8120/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8287e-04 \n",
            "Epoch 8121/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7883e-04 \n",
            "Epoch 8122/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7093e-04 \n",
            "Epoch 8123/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0654e-04 \n",
            "Epoch 8124/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8756e-04 \n",
            "Epoch 8125/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8702e-04 \n",
            "Epoch 8126/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2905e-04 \n",
            "Epoch 8127/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8635e-04 \n",
            "Epoch 8128/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7609e-04 \n",
            "Epoch 8129/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7672e-04 \n",
            "Epoch 8130/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8398e-04 \n",
            "Epoch 8131/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1885e-04 \n",
            "Epoch 8132/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5916e-04 \n",
            "Epoch 8133/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8440e-04 \n",
            "Epoch 8134/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8465e-04 \n",
            "Epoch 8135/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8082e-04 \n",
            "Epoch 8136/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8181e-04 \n",
            "Epoch 8137/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7044e-04 \n",
            "Epoch 8138/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8556e-04 \n",
            "Epoch 8139/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8055e-04 \n",
            "Epoch 8140/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7112e-04 \n",
            "Epoch 8141/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6451e-04 \n",
            "Epoch 8142/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7928e-04 \n",
            "Epoch 8143/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7018e-04 \n",
            "Epoch 8144/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9061e-04 \n",
            "Epoch 8145/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6850e-04 \n",
            "Epoch 8146/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6848e-04 \n",
            "Epoch 8147/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8299e-04 \n",
            "Epoch 8148/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8876e-04 \n",
            "Epoch 8149/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5044e-04 \n",
            "Epoch 8150/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0331e-04 \n",
            "Epoch 8151/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8074e-04 \n",
            "Epoch 8152/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7282e-04 \n",
            "Epoch 8153/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8301e-04 \n",
            "Epoch 8154/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6527e-04 \n",
            "Epoch 8155/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9395e-04 \n",
            "Epoch 8156/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7111e-04 \n",
            "Epoch 8157/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7893e-04 \n",
            "Epoch 8158/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9611e-04 \n",
            "Epoch 8159/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5237e-04 \n",
            "Epoch 8160/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6935e-04 \n",
            "Epoch 8161/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5759e-04 \n",
            "Epoch 8162/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6049e-04 \n",
            "Epoch 8163/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6267e-04 \n",
            "Epoch 8164/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8782e-04 \n",
            "Epoch 8165/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8797e-04 \n",
            "Epoch 8166/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6007e-04 \n",
            "Epoch 8167/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7470e-04 \n",
            "Epoch 8168/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6713e-04 \n",
            "Epoch 8169/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6713e-04 \n",
            "Epoch 8170/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8216e-04 \n",
            "Epoch 8171/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6047e-04 \n",
            "Epoch 8172/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5507e-04 \n",
            "Epoch 8173/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6707e-04 \n",
            "Epoch 8174/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6745e-04 \n",
            "Epoch 8175/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5882e-04 \n",
            "Epoch 8176/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7264e-04 \n",
            "Epoch 8177/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4410e-04 \n",
            "Epoch 8178/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6916e-04 \n",
            "Epoch 8179/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5151e-04 \n",
            "Epoch 8180/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8647e-04 \n",
            "Epoch 8181/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4586e-04 \n",
            "Epoch 8182/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6005e-04 \n",
            "Epoch 8183/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6766e-04 \n",
            "Epoch 8184/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6118e-04 \n",
            "Epoch 8185/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5947e-04 \n",
            "Epoch 8186/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2736e-04 \n",
            "Epoch 8187/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7410e-04 \n",
            "Epoch 8188/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8117e-04 \n",
            "Epoch 8189/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6016e-04 \n",
            "Epoch 8190/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4581e-04 \n",
            "Epoch 8191/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4427e-04 \n",
            "Epoch 8192/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3835e-04 \n",
            "Epoch 8193/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6336e-04 \n",
            "Epoch 8194/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7723e-04 \n",
            "Epoch 8195/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5190e-04 \n",
            "Epoch 8196/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5186e-04 \n",
            "Epoch 8197/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5389e-04 \n",
            "Epoch 8198/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6104e-04 \n",
            "Epoch 8199/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6910e-04 \n",
            "Epoch 8200/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.3802e-04\n",
            "Test accuracy at epoch 8200: 33.47%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.4377e-04\n",
            "Epoch 8201/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4961e-04 \n",
            "Epoch 8202/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4820e-04 \n",
            "Epoch 8203/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6456e-04 \n",
            "Epoch 8204/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6418e-04 \n",
            "Epoch 8205/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6233e-04 \n",
            "Epoch 8206/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5771e-04 \n",
            "Epoch 8207/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6090e-04 \n",
            "Epoch 8208/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5661e-04 \n",
            "Epoch 8209/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5900e-04 \n",
            "Epoch 8210/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5512e-04 \n",
            "Epoch 8211/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4341e-04 \n",
            "Epoch 8212/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4464e-04 \n",
            "Epoch 8213/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4951e-04 \n",
            "Epoch 8214/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4738e-04 \n",
            "Epoch 8215/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4198e-04 \n",
            "Epoch 8216/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7982e-04 \n",
            "Epoch 8217/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4791e-04 \n",
            "Epoch 8218/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3469e-04 \n",
            "Epoch 8219/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5988e-04 \n",
            "Epoch 8220/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4633e-04 \n",
            "Epoch 8221/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3599e-04 \n",
            "Epoch 8222/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4779e-04 \n",
            "Epoch 8223/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6820e-04 \n",
            "Epoch 8224/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3663e-04 \n",
            "Epoch 8225/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3101e-04 \n",
            "Epoch 8226/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4171e-04 \n",
            "Epoch 8227/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4731e-04 \n",
            "Epoch 8228/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5687e-04 \n",
            "Epoch 8229/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4606e-04 \n",
            "Epoch 8230/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3787e-04 \n",
            "Epoch 8231/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2780e-04 \n",
            "Epoch 8232/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6652e-04 \n",
            "Epoch 8233/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6242e-04 \n",
            "Epoch 8234/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2650e-04 \n",
            "Epoch 8235/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3191e-04 \n",
            "Epoch 8236/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2651e-04 \n",
            "Epoch 8237/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5336e-04 \n",
            "Epoch 8238/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3223e-04 \n",
            "Epoch 8239/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3448e-04 \n",
            "Epoch 8240/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2588e-04 \n",
            "Epoch 8241/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1691e-04 \n",
            "Epoch 8242/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2650e-04 \n",
            "Epoch 8243/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3154e-04 \n",
            "Epoch 8244/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2607e-04 \n",
            "Epoch 8245/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4825e-04 \n",
            "Epoch 8246/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3123e-04 \n",
            "Epoch 8247/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3621e-04 \n",
            "Epoch 8248/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2006e-04 \n",
            "Epoch 8249/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3952e-04 \n",
            "Epoch 8250/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3716e-04 \n",
            "Epoch 8251/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3566e-04 \n",
            "Epoch 8252/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4189e-04 \n",
            "Epoch 8253/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2509e-04 \n",
            "Epoch 8254/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2109e-04 \n",
            "Epoch 8255/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2715e-04 \n",
            "Epoch 8256/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4545e-04 \n",
            "Epoch 8257/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2703e-04 \n",
            "Epoch 8258/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2772e-04 \n",
            "Epoch 8259/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2866e-04 \n",
            "Epoch 8260/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3230e-04 \n",
            "Epoch 8261/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3506e-04 \n",
            "Epoch 8262/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2172e-04 \n",
            "Epoch 8263/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5169e-04 \n",
            "Epoch 8264/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2254e-04 \n",
            "Epoch 8265/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2934e-04 \n",
            "Epoch 8266/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2564e-04 \n",
            "Epoch 8267/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2817e-04 \n",
            "Epoch 8268/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2462e-04 \n",
            "Epoch 8269/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2185e-04 \n",
            "Epoch 8270/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4737e-04 \n",
            "Epoch 8271/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4339e-04 \n",
            "Epoch 8272/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2717e-04 \n",
            "Epoch 8273/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4076e-04 \n",
            "Epoch 8274/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4235e-04 \n",
            "Epoch 8275/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2777e-04 \n",
            "Epoch 8276/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2200e-04 \n",
            "Epoch 8277/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4898e-04 \n",
            "Epoch 8278/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2945e-04 \n",
            "Epoch 8279/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3039e-04 \n",
            "Epoch 8280/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1147e-04 \n",
            "Epoch 8281/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2362e-04 \n",
            "Epoch 8282/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1920e-04 \n",
            "Epoch 8283/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3128e-04 \n",
            "Epoch 8284/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3810e-04 \n",
            "Epoch 8285/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4443e-04 \n",
            "Epoch 8286/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3509e-04 \n",
            "Epoch 8287/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3732e-04 \n",
            "Epoch 8288/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2622e-04 \n",
            "Epoch 8289/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1297e-04 \n",
            "Epoch 8290/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1961e-04 \n",
            "Epoch 8291/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0162e-04 \n",
            "Epoch 8292/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1494e-04 \n",
            "Epoch 8293/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3130e-04 \n",
            "Epoch 8294/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1186e-04 \n",
            "Epoch 8295/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2192e-04 \n",
            "Epoch 8296/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2903e-04 \n",
            "Epoch 8297/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2524e-04 \n",
            "Epoch 8298/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1337e-04 \n",
            "Epoch 8299/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1327e-04 \n",
            "Epoch 8300/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.7217e-05\n",
            "Test accuracy at epoch 8300: 33.47%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0330e-04\n",
            "Epoch 8301/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1815e-04 \n",
            "Epoch 8302/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1165e-04 \n",
            "Epoch 8303/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2305e-04 \n",
            "Epoch 8304/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2052e-04 \n",
            "Epoch 8305/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2022e-04 \n",
            "Epoch 8306/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3076e-04 \n",
            "Epoch 8307/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1672e-04 \n",
            "Epoch 8308/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1033e-04 \n",
            "Epoch 8309/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2224e-04 \n",
            "Epoch 8310/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0704e-04 \n",
            "Epoch 8311/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1060e-04 \n",
            "Epoch 8312/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1446e-04 \n",
            "Epoch 8313/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0224e-04 \n",
            "Epoch 8314/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2300e-04 \n",
            "Epoch 8315/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1345e-04 \n",
            "Epoch 8316/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2664e-04 \n",
            "Epoch 8317/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1629e-04 \n",
            "Epoch 8318/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2768e-04 \n",
            "Epoch 8319/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0235e-04 \n",
            "Epoch 8320/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0772e-04 \n",
            "Epoch 8321/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0201e-04 \n",
            "Epoch 8322/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1054e-04 \n",
            "Epoch 8323/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1464e-04 \n",
            "Epoch 8324/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0717e-04 \n",
            "Epoch 8325/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1002e-04 \n",
            "Epoch 8326/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1323e-04 \n",
            "Epoch 8327/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0987e-04 \n",
            "Epoch 8328/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0703e-04 \n",
            "Epoch 8329/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0563e-04 \n",
            "Epoch 8330/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2025e-04 \n",
            "Epoch 8331/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0594e-04 \n",
            "Epoch 8332/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1373e-04 \n",
            "Epoch 8333/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2393e-04 \n",
            "Epoch 8334/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1597e-04 \n",
            "Epoch 8335/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0499e-04 \n",
            "Epoch 8336/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1907e-04 \n",
            "Epoch 8337/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0624e-04 \n",
            "Epoch 8338/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1659e-05 \n",
            "Epoch 8339/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4175e-04 \n",
            "Epoch 8340/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1660e-04 \n",
            "Epoch 8341/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0966e-04 \n",
            "Epoch 8342/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1478e-04 \n",
            "Epoch 8343/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1435e-04 \n",
            "Epoch 8344/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0630e-04 \n",
            "Epoch 8345/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0059e-05 \n",
            "Epoch 8346/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9858e-05 \n",
            "Epoch 8347/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6397e-05 \n",
            "Epoch 8348/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0527e-04 \n",
            "Epoch 8349/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1286e-04 \n",
            "Epoch 8350/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1348e-04 \n",
            "Epoch 8351/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8331e-05 \n",
            "Epoch 8352/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0365e-04 \n",
            "Epoch 8353/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1450e-04 \n",
            "Epoch 8354/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0901e-04 \n",
            "Epoch 8355/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4543e-05 \n",
            "Epoch 8356/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5328e-05 \n",
            "Epoch 8357/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7700e-05 \n",
            "Epoch 8358/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0666e-04 \n",
            "Epoch 8359/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9850e-05 \n",
            "Epoch 8360/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7610e-05 \n",
            "Epoch 8361/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7174e-05 \n",
            "Epoch 8362/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0676e-04 \n",
            "Epoch 8363/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0577e-04 \n",
            "Epoch 8364/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2094e-05 \n",
            "Epoch 8365/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1218e-04 \n",
            "Epoch 8366/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0735e-04 \n",
            "Epoch 8367/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5493e-05 \n",
            "Epoch 8368/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6822e-05 \n",
            "Epoch 8369/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0774e-04 \n",
            "Epoch 8370/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3222e-05 \n",
            "Epoch 8371/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9988e-05 \n",
            "Epoch 8372/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9506e-05 \n",
            "Epoch 8373/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8516e-05 \n",
            "Epoch 8374/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0392e-04 \n",
            "Epoch 8375/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1594e-05 \n",
            "Epoch 8376/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0182e-04 \n",
            "Epoch 8377/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0357e-04 \n",
            "Epoch 8378/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0378e-04 \n",
            "Epoch 8379/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7445e-05 \n",
            "Epoch 8380/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5445e-05 \n",
            "Epoch 8381/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8949e-05 \n",
            "Epoch 8382/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3305e-05 \n",
            "Epoch 8383/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4347e-05 \n",
            "Epoch 8384/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5280e-05 \n",
            "Epoch 8385/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0515e-04 \n",
            "Epoch 8386/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9229e-05 \n",
            "Epoch 8387/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0625e-04 \n",
            "Epoch 8388/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0835e-04 \n",
            "Epoch 8389/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2584e-05 \n",
            "Epoch 8390/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6651e-05 \n",
            "Epoch 8391/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4694e-05 \n",
            "Epoch 8392/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1665e-05 \n",
            "Epoch 8393/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9706e-05 \n",
            "Epoch 8394/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3022e-05 \n",
            "Epoch 8395/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2741e-05 \n",
            "Epoch 8396/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8182e-05 \n",
            "Epoch 8397/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4359e-05 \n",
            "Epoch 8398/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5950e-05 \n",
            "Epoch 8399/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2259e-05 \n",
            "Epoch 8400/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.4143e-04\n",
            "Test accuracy at epoch 8400: 33.55%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0457e-04\n",
            "Epoch 8401/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6195e-05 \n",
            "Epoch 8402/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0702e-04 \n",
            "Epoch 8403/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4873e-05 \n",
            "Epoch 8404/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5549e-05 \n",
            "Epoch 8405/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1001e-05 \n",
            "Epoch 8406/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6312e-05 \n",
            "Epoch 8407/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2525e-05 \n",
            "Epoch 8408/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5399e-05 \n",
            "Epoch 8409/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2866e-05 \n",
            "Epoch 8410/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2169e-05 \n",
            "Epoch 8411/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0680e-05 \n",
            "Epoch 8412/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4141e-05 \n",
            "Epoch 8413/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2950e-05 \n",
            "Epoch 8414/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1289e-05 \n",
            "Epoch 8415/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7382e-05 \n",
            "Epoch 8416/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1278e-05 \n",
            "Epoch 8417/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8665e-05 \n",
            "Epoch 8418/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6189e-05 \n",
            "Epoch 8419/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5310e-05 \n",
            "Epoch 8420/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9392e-05 \n",
            "Epoch 8421/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3038e-05 \n",
            "Epoch 8422/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0285e-04 \n",
            "Epoch 8423/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1272e-05 \n",
            "Epoch 8424/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6190e-05 \n",
            "Epoch 8425/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8933e-05 \n",
            "Epoch 8426/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4878e-05 \n",
            "Epoch 8427/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8172e-05 \n",
            "Epoch 8428/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3597e-05 \n",
            "Epoch 8429/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0837e-05 \n",
            "Epoch 8430/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6146e-05 \n",
            "Epoch 8431/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6547e-05 \n",
            "Epoch 8432/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0450e-04 \n",
            "Epoch 8433/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0869e-05 \n",
            "Epoch 8434/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1836e-05 \n",
            "Epoch 8435/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2123e-05 \n",
            "Epoch 8436/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8499e-05 \n",
            "Epoch 8437/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2456e-05 \n",
            "Epoch 8438/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9707e-05 \n",
            "Epoch 8439/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8409e-05 \n",
            "Epoch 8440/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4780e-05 \n",
            "Epoch 8441/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6273e-05 \n",
            "Epoch 8442/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6314e-05 \n",
            "Epoch 8443/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1720e-05 \n",
            "Epoch 8444/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3009e-05 \n",
            "Epoch 8445/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0558e-05 \n",
            "Epoch 8446/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3862e-05 \n",
            "Epoch 8447/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4624e-05 \n",
            "Epoch 8448/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2682e-05 \n",
            "Epoch 8449/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7254e-05 \n",
            "Epoch 8450/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9900e-05 \n",
            "Epoch 8451/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1600e-05 \n",
            "Epoch 8452/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2234e-05 \n",
            "Epoch 8453/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5630e-05 \n",
            "Epoch 8454/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5793e-05 \n",
            "Epoch 8455/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3745e-05 \n",
            "Epoch 8456/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6433e-05 \n",
            "Epoch 8457/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8408e-05 \n",
            "Epoch 8458/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0690e-05 \n",
            "Epoch 8459/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3762e-05 \n",
            "Epoch 8460/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3962e-05 \n",
            "Epoch 8461/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0708e-05 \n",
            "Epoch 8462/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8770e-05 \n",
            "Epoch 8463/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3142e-05 \n",
            "Epoch 8464/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2448e-05 \n",
            "Epoch 8465/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3013e-05 \n",
            "Epoch 8466/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3744e-05 \n",
            "Epoch 8467/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6497e-05 \n",
            "Epoch 8468/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7911e-05 \n",
            "Epoch 8469/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5577e-05 \n",
            "Epoch 8470/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9569e-05 \n",
            "Epoch 8471/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8920e-05 \n",
            "Epoch 8472/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6866e-05 \n",
            "Epoch 8473/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6659e-05 \n",
            "Epoch 8474/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7829e-05 \n",
            "Epoch 8475/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8562e-05 \n",
            "Epoch 8476/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7851e-05 \n",
            "Epoch 8477/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3812e-05 \n",
            "Epoch 8478/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2205e-05 \n",
            "Epoch 8479/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0620e-05 \n",
            "Epoch 8480/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4667e-05 \n",
            "Epoch 8481/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3673e-05 \n",
            "Epoch 8482/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5770e-05 \n",
            "Epoch 8483/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1654e-05 \n",
            "Epoch 8484/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5177e-05 \n",
            "Epoch 8485/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3610e-05 \n",
            "Epoch 8486/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1787e-05 \n",
            "Epoch 8487/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5344e-05 \n",
            "Epoch 8488/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4884e-05 \n",
            "Epoch 8489/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0991e-05 \n",
            "Epoch 8490/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0281e-05 \n",
            "Epoch 8491/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0229e-05 \n",
            "Epoch 8492/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9940e-05 \n",
            "Epoch 8493/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6975e-05 \n",
            "Epoch 8494/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2659e-05 \n",
            "Epoch 8495/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9390e-05 \n",
            "Epoch 8496/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2677e-05 \n",
            "Epoch 8497/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1944e-05 \n",
            "Epoch 8498/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9198e-05 \n",
            "Epoch 8499/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5745e-05 \n",
            "Epoch 8500/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.1711e-05\n",
            "Test accuracy at epoch 8500: 33.52%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.9598e-05\n",
            "Epoch 8501/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3341e-05 \n",
            "Epoch 8502/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3193e-05 \n",
            "Epoch 8503/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3741e-05 \n",
            "Epoch 8504/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9210e-05 \n",
            "Epoch 8505/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9833e-05 \n",
            "Epoch 8506/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2432e-05 \n",
            "Epoch 8507/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3677e-05 \n",
            "Epoch 8508/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4128e-05 \n",
            "Epoch 8509/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4672e-05 \n",
            "Epoch 8510/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4040e-05 \n",
            "Epoch 8511/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0831e-05 \n",
            "Epoch 8512/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6821e-05 \n",
            "Epoch 8513/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6710e-05 \n",
            "Epoch 8514/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5876e-05 \n",
            "Epoch 8515/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6535e-05 \n",
            "Epoch 8516/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1802e-05 \n",
            "Epoch 8517/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9698e-05 \n",
            "Epoch 8518/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3170e-05 \n",
            "Epoch 8519/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2342e-05 \n",
            "Epoch 8520/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8481e-05 \n",
            "Epoch 8521/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0212e-05 \n",
            "Epoch 8522/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1509e-05 \n",
            "Epoch 8523/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1883e-05 \n",
            "Epoch 8524/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7567e-05 \n",
            "Epoch 8525/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4751e-05 \n",
            "Epoch 8526/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5399e-05 \n",
            "Epoch 8527/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1043e-05 \n",
            "Epoch 8528/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1997e-05 \n",
            "Epoch 8529/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1860e-05 \n",
            "Epoch 8530/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5033e-05 \n",
            "Epoch 8531/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9380e-05 \n",
            "Epoch 8532/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9945e-05 \n",
            "Epoch 8533/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9003e-05 \n",
            "Epoch 8534/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2277e-05 \n",
            "Epoch 8535/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2832e-05 \n",
            "Epoch 8536/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5543e-05 \n",
            "Epoch 8537/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2023e-05 \n",
            "Epoch 8538/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9715e-05 \n",
            "Epoch 8539/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4308e-05 \n",
            "Epoch 8540/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0041e-05 \n",
            "Epoch 8541/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5854e-05 \n",
            "Epoch 8542/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4270e-05 \n",
            "Epoch 8543/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1592e-05 \n",
            "Epoch 8544/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2128e-05 \n",
            "Epoch 8545/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6676e-05 \n",
            "Epoch 8546/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4223e-05 \n",
            "Epoch 8547/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4270e-05 \n",
            "Epoch 8548/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6259e-05 \n",
            "Epoch 8549/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2828e-05 \n",
            "Epoch 8550/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5605e-05 \n",
            "Epoch 8551/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9603e-05 \n",
            "Epoch 8552/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2769e-05 \n",
            "Epoch 8553/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8878e-05 \n",
            "Epoch 8554/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9585e-05 \n",
            "Epoch 8555/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6455e-05 \n",
            "Epoch 8556/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7342e-05 \n",
            "Epoch 8557/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0033e-05 \n",
            "Epoch 8558/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2487e-05 \n",
            "Epoch 8559/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5017e-05 \n",
            "Epoch 8560/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6840e-05 \n",
            "Epoch 8561/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0163e-05 \n",
            "Epoch 8562/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9413e-05 \n",
            "Epoch 8563/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5756e-05 \n",
            "Epoch 8564/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9997e-05 \n",
            "Epoch 8565/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4924e-05 \n",
            "Epoch 8566/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5461e-05 \n",
            "Epoch 8567/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9394e-05 \n",
            "Epoch 8568/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8075e-05 \n",
            "Epoch 8569/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5031e-05 \n",
            "Epoch 8570/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4224e-05 \n",
            "Epoch 8571/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3005e-05 \n",
            "Epoch 8572/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5450e-05 \n",
            "Epoch 8573/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4264e-05 \n",
            "Epoch 8574/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4338e-05 \n",
            "Epoch 8575/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4456e-05 \n",
            "Epoch 8576/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6639e-05 \n",
            "Epoch 8577/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9587e-05 \n",
            "Epoch 8578/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1775e-05 \n",
            "Epoch 8579/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2849e-05 \n",
            "Epoch 8580/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5194e-05 \n",
            "Epoch 8581/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3754e-05 \n",
            "Epoch 8582/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9239e-05 \n",
            "Epoch 8583/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4030e-05 \n",
            "Epoch 8584/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9132e-05 \n",
            "Epoch 8585/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4550e-05 \n",
            "Epoch 8586/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5773e-05 \n",
            "Epoch 8587/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4361e-05 \n",
            "Epoch 8588/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5148e-05 \n",
            "Epoch 8589/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6954e-05 \n",
            "Epoch 8590/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7159e-05 \n",
            "Epoch 8591/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4890e-05 \n",
            "Epoch 8592/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5058e-05 \n",
            "Epoch 8593/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8670e-05 \n",
            "Epoch 8594/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5374e-05 \n",
            "Epoch 8595/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4184e-05 \n",
            "Epoch 8596/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2743e-05 \n",
            "Epoch 8597/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8936e-05 \n",
            "Epoch 8598/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3829e-05 \n",
            "Epoch 8599/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5868e-05 \n",
            "Epoch 8600/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.8761e-05\n",
            "Test accuracy at epoch 8600: 33.49%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.0355e-05\n",
            "Epoch 8601/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2822e-05 \n",
            "Epoch 8602/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1967e-05 \n",
            "Epoch 8603/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6883e-05 \n",
            "Epoch 8604/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9232e-05 \n",
            "Epoch 8605/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8235e-05 \n",
            "Epoch 8606/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1611e-05 \n",
            "Epoch 8607/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7205e-05 \n",
            "Epoch 8608/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5535e-05 \n",
            "Epoch 8609/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6899e-05 \n",
            "Epoch 8610/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1312e-05 \n",
            "Epoch 8611/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1486e-05 \n",
            "Epoch 8612/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3586e-05 \n",
            "Epoch 8613/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4331e-05 \n",
            "Epoch 8614/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1700e-05 \n",
            "Epoch 8615/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1696e-05 \n",
            "Epoch 8616/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9936e-05 \n",
            "Epoch 8617/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3463e-05 \n",
            "Epoch 8618/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7211e-05 \n",
            "Epoch 8619/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5806e-05 \n",
            "Epoch 8620/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6232e-05 \n",
            "Epoch 8621/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9659e-05 \n",
            "Epoch 8622/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5244e-05 \n",
            "Epoch 8623/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2296e-05 \n",
            "Epoch 8624/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8498e-05 \n",
            "Epoch 8625/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8022e-05 \n",
            "Epoch 8626/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8993e-05 \n",
            "Epoch 8627/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9242e-05 \n",
            "Epoch 8628/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5532e-05 \n",
            "Epoch 8629/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2371e-05 \n",
            "Epoch 8630/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6422e-05 \n",
            "Epoch 8631/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0927e-05 \n",
            "Epoch 8632/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4511e-05 \n",
            "Epoch 8633/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3561e-05 \n",
            "Epoch 8634/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9940e-05 \n",
            "Epoch 8635/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3983e-05 \n",
            "Epoch 8636/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7926e-05 \n",
            "Epoch 8637/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8925e-05 \n",
            "Epoch 8638/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3444e-05 \n",
            "Epoch 8639/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4657e-05 \n",
            "Epoch 8640/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0070e-05 \n",
            "Epoch 8641/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0877e-05 \n",
            "Epoch 8642/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1712e-05 \n",
            "Epoch 8643/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7215e-05 \n",
            "Epoch 8644/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3474e-05 \n",
            "Epoch 8645/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9707e-05 \n",
            "Epoch 8646/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5461e-05 \n",
            "Epoch 8647/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1084e-05 \n",
            "Epoch 8648/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6372e-05 \n",
            "Epoch 8649/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5933e-05 \n",
            "Epoch 8650/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5193e-05 \n",
            "Epoch 8651/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1126e-05 \n",
            "Epoch 8652/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2824e-05 \n",
            "Epoch 8653/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6718e-05 \n",
            "Epoch 8654/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1499e-05 \n",
            "Epoch 8655/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8775e-05 \n",
            "Epoch 8656/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3989e-05 \n",
            "Epoch 8657/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5378e-05 \n",
            "Epoch 8658/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1626e-05 \n",
            "Epoch 8659/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5935e-05 \n",
            "Epoch 8660/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6454e-05 \n",
            "Epoch 8661/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5096e-05 \n",
            "Epoch 8662/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0657e-05 \n",
            "Epoch 8663/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5686e-05 \n",
            "Epoch 8664/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5496e-05 \n",
            "Epoch 8665/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6505e-05 \n",
            "Epoch 8666/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3785e-05 \n",
            "Epoch 8667/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0666e-05 \n",
            "Epoch 8668/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5032e-05 \n",
            "Epoch 8669/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9834e-05 \n",
            "Epoch 8670/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8670e-05 \n",
            "Epoch 8671/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5114e-05 \n",
            "Epoch 8672/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3701e-05 \n",
            "Epoch 8673/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2267e-05 \n",
            "Epoch 8674/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5061e-05 \n",
            "Epoch 8675/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6910e-05 \n",
            "Epoch 8676/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6198e-05 \n",
            "Epoch 8677/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1468e-05 \n",
            "Epoch 8678/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4444e-05 \n",
            "Epoch 8679/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4250e-05 \n",
            "Epoch 8680/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1938e-05 \n",
            "Epoch 8681/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9364e-05 \n",
            "Epoch 8682/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6862e-05 \n",
            "Epoch 8683/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4285e-05 \n",
            "Epoch 8684/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6595e-05 \n",
            "Epoch 8685/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6937e-05 \n",
            "Epoch 8686/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8026e-05 \n",
            "Epoch 8687/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7745e-05 \n",
            "Epoch 8688/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1873e-05 \n",
            "Epoch 8689/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8948e-05 \n",
            "Epoch 8690/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4779e-05 \n",
            "Epoch 8691/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3740e-05 \n",
            "Epoch 8692/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3036e-05 \n",
            "Epoch 8693/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6370e-05 \n",
            "Epoch 8694/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7827e-05 \n",
            "Epoch 8695/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2861e-05 \n",
            "Epoch 8696/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3237e-05 \n",
            "Epoch 8697/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3154e-05 \n",
            "Epoch 8698/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2310e-05 \n",
            "Epoch 8699/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1190e-05 \n",
            "Epoch 8700/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.1373e-05\n",
            "Test accuracy at epoch 8700: 33.50%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.5668e-05\n",
            "Epoch 8701/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9655e-05 \n",
            "Epoch 8702/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0393e-05 \n",
            "Epoch 8703/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1818e-05 \n",
            "Epoch 8704/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2960e-05 \n",
            "Epoch 8705/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8590e-05 \n",
            "Epoch 8706/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9553e-05 \n",
            "Epoch 8707/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1408e-05 \n",
            "Epoch 8708/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1750e-05 \n",
            "Epoch 8709/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8855e-05 \n",
            "Epoch 8710/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6317e-05 \n",
            "Epoch 8711/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3329e-05 \n",
            "Epoch 8712/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8411e-05 \n",
            "Epoch 8713/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9681e-05 \n",
            "Epoch 8714/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2634e-05 \n",
            "Epoch 8715/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9400e-05 \n",
            "Epoch 8716/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0631e-05 \n",
            "Epoch 8717/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9800e-05 \n",
            "Epoch 8718/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6432e-05 \n",
            "Epoch 8719/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0185e-05 \n",
            "Epoch 8720/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0426e-05 \n",
            "Epoch 8721/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1915e-05 \n",
            "Epoch 8722/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0827e-05 \n",
            "Epoch 8723/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5523e-05 \n",
            "Epoch 8724/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2670e-05 \n",
            "Epoch 8725/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2811e-05 \n",
            "Epoch 8726/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7446e-05 \n",
            "Epoch 8727/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1514e-05 \n",
            "Epoch 8728/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7718e-05 \n",
            "Epoch 8729/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8053e-05 \n",
            "Epoch 8730/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3171e-05 \n",
            "Epoch 8731/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8653e-05 \n",
            "Epoch 8732/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0963e-05 \n",
            "Epoch 8733/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0408e-05 \n",
            "Epoch 8734/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5630e-05 \n",
            "Epoch 8735/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3050e-05 \n",
            "Epoch 8736/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7556e-05 \n",
            "Epoch 8737/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2697e-05 \n",
            "Epoch 8738/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1371e-05 \n",
            "Epoch 8739/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0437e-05 \n",
            "Epoch 8740/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0065e-05 \n",
            "Epoch 8741/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7895e-05 \n",
            "Epoch 8742/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5779e-05 \n",
            "Epoch 8743/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5406e-05 \n",
            "Epoch 8744/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3855e-05 \n",
            "Epoch 8745/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8401e-05 \n",
            "Epoch 8746/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5603e-05 \n",
            "Epoch 8747/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7432e-05 \n",
            "Epoch 8748/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3293e-05 \n",
            "Epoch 8749/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2715e-05 \n",
            "Epoch 8750/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5729e-05 \n",
            "Epoch 8751/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4836e-05 \n",
            "Epoch 8752/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7581e-05 \n",
            "Epoch 8753/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9732e-05 \n",
            "Epoch 8754/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4580e-05 \n",
            "Epoch 8755/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7231e-05 \n",
            "Epoch 8756/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6964e-05 \n",
            "Epoch 8757/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3941e-05 \n",
            "Epoch 8758/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4010e-05 \n",
            "Epoch 8759/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6184e-05 \n",
            "Epoch 8760/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8880e-05 \n",
            "Epoch 8761/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5359e-05 \n",
            "Epoch 8762/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5580e-05 \n",
            "Epoch 8763/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6338e-05 \n",
            "Epoch 8764/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2908e-05 \n",
            "Epoch 8765/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3526e-05 \n",
            "Epoch 8766/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1654e-05 \n",
            "Epoch 8767/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3869e-05 \n",
            "Epoch 8768/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2158e-05 \n",
            "Epoch 8769/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3085e-05 \n",
            "Epoch 8770/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9978e-05 \n",
            "Epoch 8771/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7698e-05 \n",
            "Epoch 8772/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7100e-05 \n",
            "Epoch 8773/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1133e-05 \n",
            "Epoch 8774/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2138e-05 \n",
            "Epoch 8775/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1016e-05 \n",
            "Epoch 8776/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0666e-05 \n",
            "Epoch 8777/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2880e-05 \n",
            "Epoch 8778/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4757e-05 \n",
            "Epoch 8779/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2110e-05 \n",
            "Epoch 8780/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0331e-05 \n",
            "Epoch 8781/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5177e-05 \n",
            "Epoch 8782/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5983e-05 \n",
            "Epoch 8783/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5409e-05 \n",
            "Epoch 8784/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0676e-05 \n",
            "Epoch 8785/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5816e-05 \n",
            "Epoch 8786/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8216e-05 \n",
            "Epoch 8787/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9149e-05 \n",
            "Epoch 8788/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1018e-05 \n",
            "Epoch 8789/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7609e-05 \n",
            "Epoch 8790/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7227e-05 \n",
            "Epoch 8791/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0606e-05  \n",
            "Epoch 8792/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9262e-05 \n",
            "Epoch 8793/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1055e-05 \n",
            "Epoch 8794/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1758e-05 \n",
            "Epoch 8795/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8596e-05 \n",
            "Epoch 8796/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0433e-05 \n",
            "Epoch 8797/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3139e-05 \n",
            "Epoch 8798/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8881e-05 \n",
            "Epoch 8799/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3017e-05 \n",
            "Epoch 8800/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.8347e-05\n",
            "Test accuracy at epoch 8800: 33.55%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.1875e-05\n",
            "Epoch 8801/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5080e-05 \n",
            "Epoch 8802/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1370e-05 \n",
            "Epoch 8803/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0361e-05 \n",
            "Epoch 8804/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8506e-05 \n",
            "Epoch 8805/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2516e-05 \n",
            "Epoch 8806/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9749e-05 \n",
            "Epoch 8807/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2499e-05 \n",
            "Epoch 8808/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9941e-05 \n",
            "Epoch 8809/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9792e-05 \n",
            "Epoch 8810/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3533e-05 \n",
            "Epoch 8811/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9002e-05 \n",
            "Epoch 8812/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6992e-05 \n",
            "Epoch 8813/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8969e-05 \n",
            "Epoch 8814/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5971e-05 \n",
            "Epoch 8815/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7170e-05 \n",
            "Epoch 8816/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8911e-05 \n",
            "Epoch 8817/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6437e-05 \n",
            "Epoch 8818/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0773e-05 \n",
            "Epoch 8819/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3909e-05 \n",
            "Epoch 8820/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0170e-05 \n",
            "Epoch 8821/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8605e-05 \n",
            "Epoch 8822/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9378e-05 \n",
            "Epoch 8823/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0893e-05 \n",
            "Epoch 8824/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4696e-05 \n",
            "Epoch 8825/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7807e-05 \n",
            "Epoch 8826/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0084e-05 \n",
            "Epoch 8827/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8496e-05 \n",
            "Epoch 8828/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8491e-05 \n",
            "Epoch 8829/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7782e-05 \n",
            "Epoch 8830/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4730e-05 \n",
            "Epoch 8831/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7670e-05 \n",
            "Epoch 8832/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4227e-05 \n",
            "Epoch 8833/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7680e-05 \n",
            "Epoch 8834/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6118e-05 \n",
            "Epoch 8835/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6381e-05 \n",
            "Epoch 8836/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7762e-05 \n",
            "Epoch 8837/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5315e-05 \n",
            "Epoch 8838/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6364e-05 \n",
            "Epoch 8839/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8947e-05 \n",
            "Epoch 8840/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7597e-05 \n",
            "Epoch 8841/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7571e-05 \n",
            "Epoch 8842/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4181e-05 \n",
            "Epoch 8843/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7876e-05 \n",
            "Epoch 8844/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8325e-05 \n",
            "Epoch 8845/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8137e-05 \n",
            "Epoch 8846/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6076e-05 \n",
            "Epoch 8847/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7611e-05 \n",
            "Epoch 8848/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8476e-05 \n",
            "Epoch 8849/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0764e-05 \n",
            "Epoch 8850/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6167e-05 \n",
            "Epoch 8851/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6975e-05 \n",
            "Epoch 8852/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4788e-05 \n",
            "Epoch 8853/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2414e-05 \n",
            "Epoch 8854/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4943e-05 \n",
            "Epoch 8855/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7501e-05 \n",
            "Epoch 8856/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3850e-05 \n",
            "Epoch 8857/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3457e-05 \n",
            "Epoch 8858/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4160e-05 \n",
            "Epoch 8859/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4344e-05 \n",
            "Epoch 8860/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6404e-05 \n",
            "Epoch 8861/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3488e-05 \n",
            "Epoch 8862/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7848e-05 \n",
            "Epoch 8863/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4347e-05 \n",
            "Epoch 8864/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5741e-05 \n",
            "Epoch 8865/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5247e-05 \n",
            "Epoch 8866/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4785e-05 \n",
            "Epoch 8867/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5710e-05 \n",
            "Epoch 8868/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9531e-05 \n",
            "Epoch 8869/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5405e-05 \n",
            "Epoch 8870/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6084e-05 \n",
            "Epoch 8871/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2127e-05 \n",
            "Epoch 8872/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4698e-05 \n",
            "Epoch 8873/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5419e-05 \n",
            "Epoch 8874/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4006e-05 \n",
            "Epoch 8875/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5488e-05 \n",
            "Epoch 8876/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8750e-05 \n",
            "Epoch 8877/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6742e-05 \n",
            "Epoch 8878/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2657e-05 \n",
            "Epoch 8879/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0380e-05 \n",
            "Epoch 8880/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3054e-05 \n",
            "Epoch 8881/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4433e-05 \n",
            "Epoch 8882/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8645e-05 \n",
            "Epoch 8883/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3938e-05 \n",
            "Epoch 8884/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5690e-05 \n",
            "Epoch 8885/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6874e-05 \n",
            "Epoch 8886/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4329e-05 \n",
            "Epoch 8887/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4023e-05 \n",
            "Epoch 8888/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3067e-05 \n",
            "Epoch 8889/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3939e-05 \n",
            "Epoch 8890/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4061e-05 \n",
            "Epoch 8891/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7411e-05 \n",
            "Epoch 8892/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2163e-05 \n",
            "Epoch 8893/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2396e-05 \n",
            "Epoch 8894/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6703e-05 \n",
            "Epoch 8895/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3239e-05 \n",
            "Epoch 8896/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1275e-05 \n",
            "Epoch 8897/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2049e-05 \n",
            "Epoch 8898/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3200e-05 \n",
            "Epoch 8899/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2359e-05 \n",
            "Epoch 8900/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.3230e-05\n",
            "Test accuracy at epoch 8900: 33.58%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.3588e-05\n",
            "Epoch 8901/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0516e-05 \n",
            "Epoch 8902/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2110e-05 \n",
            "Epoch 8903/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6036e-05 \n",
            "Epoch 8904/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2528e-05 \n",
            "Epoch 8905/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2521e-05 \n",
            "Epoch 8906/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2561e-05 \n",
            "Epoch 8907/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1969e-05 \n",
            "Epoch 8908/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3086e-05 \n",
            "Epoch 8909/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2717e-05 \n",
            "Epoch 8910/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0803e-05 \n",
            "Epoch 8911/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2368e-05 \n",
            "Epoch 8912/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1881e-05 \n",
            "Epoch 8913/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9925e-05 \n",
            "Epoch 8914/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9174e-05 \n",
            "Epoch 8915/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1372e-05 \n",
            "Epoch 8916/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1134e-05 \n",
            "Epoch 8917/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3551e-05 \n",
            "Epoch 8918/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2070e-05 \n",
            "Epoch 8919/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2927e-05 \n",
            "Epoch 8920/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1187e-05 \n",
            "Epoch 8921/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7367e-05 \n",
            "Epoch 8922/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0276e-05 \n",
            "Epoch 8923/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0063e-05 \n",
            "Epoch 8924/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4267e-05 \n",
            "Epoch 8925/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0591e-05 \n",
            "Epoch 8926/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3518e-05 \n",
            "Epoch 8927/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2079e-05 \n",
            "Epoch 8928/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1793e-05 \n",
            "Epoch 8929/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2822e-05 \n",
            "Epoch 8930/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2382e-05 \n",
            "Epoch 8931/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9776e-05 \n",
            "Epoch 8932/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1664e-05 \n",
            "Epoch 8933/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0929e-05 \n",
            "Epoch 8934/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1451e-05 \n",
            "Epoch 8935/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0393e-05 \n",
            "Epoch 8936/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3255e-05 \n",
            "Epoch 8937/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0643e-05 \n",
            "Epoch 8938/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9673e-05 \n",
            "Epoch 8939/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9300e-05 \n",
            "Epoch 8940/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2996e-05 \n",
            "Epoch 8941/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0439e-05 \n",
            "Epoch 8942/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0061e-05 \n",
            "Epoch 8943/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2369e-05 \n",
            "Epoch 8944/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2656e-05 \n",
            "Epoch 8945/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0288e-05 \n",
            "Epoch 8946/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0156e-05 \n",
            "Epoch 8947/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9063e-05 \n",
            "Epoch 8948/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1623e-05 \n",
            "Epoch 8949/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0191e-05 \n",
            "Epoch 8950/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0570e-05 \n",
            "Epoch 8951/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1655e-05 \n",
            "Epoch 8952/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8496e-05 \n",
            "Epoch 8953/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0419e-05 \n",
            "Epoch 8954/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9535e-05 \n",
            "Epoch 8955/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0982e-05 \n",
            "Epoch 8956/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0054e-05 \n",
            "Epoch 8957/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0472e-05 \n",
            "Epoch 8958/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0751e-05 \n",
            "Epoch 8959/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0053e-05 \n",
            "Epoch 8960/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9860e-05 \n",
            "Epoch 8961/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0412e-05 \n",
            "Epoch 8962/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8789e-05 \n",
            "Epoch 8963/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8524e-05 \n",
            "Epoch 8964/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6587e-05 \n",
            "Epoch 8965/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8362e-05 \n",
            "Epoch 8966/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9275e-05 \n",
            "Epoch 8967/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0281e-05 \n",
            "Epoch 8968/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8448e-05 \n",
            "Epoch 8969/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8460e-05 \n",
            "Epoch 8970/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9905e-05 \n",
            "Epoch 8971/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7457e-05 \n",
            "Epoch 8972/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1850e-05 \n",
            "Epoch 8973/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9692e-05 \n",
            "Epoch 8974/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7916e-05 \n",
            "Epoch 8975/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7169e-05 \n",
            "Epoch 8976/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7092e-05 \n",
            "Epoch 8977/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9413e-05 \n",
            "Epoch 8978/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8295e-05 \n",
            "Epoch 8979/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8694e-05 \n",
            "Epoch 8980/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7181e-05 \n",
            "Epoch 8981/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8622e-05 \n",
            "Epoch 8982/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7217e-05 \n",
            "Epoch 8983/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8121e-05 \n",
            "Epoch 8984/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5877e-05 \n",
            "Epoch 8985/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6650e-05 \n",
            "Epoch 8986/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8918e-05 \n",
            "Epoch 8987/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7945e-05 \n",
            "Epoch 8988/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7468e-05 \n",
            "Epoch 8989/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8046e-05 \n",
            "Epoch 8990/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6178e-05 \n",
            "Epoch 8991/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7533e-05 \n",
            "Epoch 8992/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6999e-05 \n",
            "Epoch 8993/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8960e-05 \n",
            "Epoch 8994/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8493e-05 \n",
            "Epoch 8995/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6420e-05 \n",
            "Epoch 8996/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7740e-05 \n",
            "Epoch 8997/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8558e-05 \n",
            "Epoch 8998/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4551e-05 \n",
            "Epoch 8999/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9066e-05 \n",
            "Epoch 9000/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.9385e-05\n",
            "Test accuracy at epoch 9000: 33.62%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8975e-05\n",
            "Epoch 9001/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8908e-05 \n",
            "Epoch 9002/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8368e-05 \n",
            "Epoch 9003/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8273e-05 \n",
            "Epoch 9004/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6167e-05 \n",
            "Epoch 9005/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7859e-05 \n",
            "Epoch 9006/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6387e-05 \n",
            "Epoch 9007/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7282e-05 \n",
            "Epoch 9008/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9759e-05 \n",
            "Epoch 9009/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6787e-05 \n",
            "Epoch 9010/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8341e-05 \n",
            "Epoch 9011/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6030e-05 \n",
            "Epoch 9012/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6101e-05 \n",
            "Epoch 9013/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5057e-05 \n",
            "Epoch 9014/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6006e-05 \n",
            "Epoch 9015/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7133e-05 \n",
            "Epoch 9016/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7344e-05 \n",
            "Epoch 9017/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7643e-05 \n",
            "Epoch 9018/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8182e-05 \n",
            "Epoch 9019/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5494e-05 \n",
            "Epoch 9020/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6495e-05 \n",
            "Epoch 9021/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8797e-05 \n",
            "Epoch 9022/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5621e-05 \n",
            "Epoch 9023/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6913e-05 \n",
            "Epoch 9024/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6472e-05 \n",
            "Epoch 9025/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5835e-05 \n",
            "Epoch 9026/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7849e-05 \n",
            "Epoch 9027/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5272e-05 \n",
            "Epoch 9028/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6589e-05 \n",
            "Epoch 9029/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9322e-05 \n",
            "Epoch 9030/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6847e-05 \n",
            "Epoch 9031/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6299e-05 \n",
            "Epoch 9032/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5716e-05 \n",
            "Epoch 9033/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6558e-05 \n",
            "Epoch 9034/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6411e-05 \n",
            "Epoch 9035/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8249e-05 \n",
            "Epoch 9036/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5075e-05 \n",
            "Epoch 9037/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6124e-05 \n",
            "Epoch 9038/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6125e-05 \n",
            "Epoch 9039/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6487e-05 \n",
            "Epoch 9040/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5955e-05 \n",
            "Epoch 9041/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5338e-05 \n",
            "Epoch 9042/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8572e-05 \n",
            "Epoch 9043/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5965e-05 \n",
            "Epoch 9044/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2479e-05 \n",
            "Epoch 9045/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2909e-05 \n",
            "Epoch 9046/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6888e-05 \n",
            "Epoch 9047/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4760e-05 \n",
            "Epoch 9048/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4508e-05 \n",
            "Epoch 9049/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5241e-05 \n",
            "Epoch 9050/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4773e-05 \n",
            "Epoch 9051/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6203e-05 \n",
            "Epoch 9052/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5666e-05 \n",
            "Epoch 9053/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3343e-05 \n",
            "Epoch 9054/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4770e-05 \n",
            "Epoch 9055/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5371e-05 \n",
            "Epoch 9056/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4702e-05 \n",
            "Epoch 9057/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4972e-05 \n",
            "Epoch 9058/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4683e-05 \n",
            "Epoch 9059/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3978e-05 \n",
            "Epoch 9060/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3484e-05 \n",
            "Epoch 9061/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5699e-05 \n",
            "Epoch 9062/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3873e-05 \n",
            "Epoch 9063/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4597e-05 \n",
            "Epoch 9064/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5463e-05 \n",
            "Epoch 9065/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5375e-05 \n",
            "Epoch 9066/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4664e-05 \n",
            "Epoch 9067/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3479e-05 \n",
            "Epoch 9068/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4507e-05 \n",
            "Epoch 9069/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5467e-05 \n",
            "Epoch 9070/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3101e-05 \n",
            "Epoch 9071/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4401e-05 \n",
            "Epoch 9072/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5121e-05 \n",
            "Epoch 9073/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4279e-05 \n",
            "Epoch 9074/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3228e-05 \n",
            "Epoch 9075/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3885e-05 \n",
            "Epoch 9076/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1902e-05 \n",
            "Epoch 9077/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3795e-05 \n",
            "Epoch 9078/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3653e-05 \n",
            "Epoch 9079/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3566e-05 \n",
            "Epoch 9080/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3968e-05 \n",
            "Epoch 9081/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3767e-05 \n",
            "Epoch 9082/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4683e-05 \n",
            "Epoch 9083/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4136e-05 \n",
            "Epoch 9084/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2880e-05 \n",
            "Epoch 9085/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5017e-05 \n",
            "Epoch 9086/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2785e-05 \n",
            "Epoch 9087/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5245e-05 \n",
            "Epoch 9088/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3167e-05 \n",
            "Epoch 9089/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4515e-05 \n",
            "Epoch 9090/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3360e-05 \n",
            "Epoch 9091/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2911e-05 \n",
            "Epoch 9092/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5684e-05 \n",
            "Epoch 9093/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3159e-05 \n",
            "Epoch 9094/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3279e-05 \n",
            "Epoch 9095/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3688e-05 \n",
            "Epoch 9096/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3240e-05 \n",
            "Epoch 9097/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2227e-05 \n",
            "Epoch 9098/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6398e-05 \n",
            "Epoch 9099/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3074e-05 \n",
            "Epoch 9100/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.0175e-05\n",
            "Test accuracy at epoch 9100: 33.64%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.4509e-05\n",
            "Epoch 9101/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3603e-05 \n",
            "Epoch 9102/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2769e-05 \n",
            "Epoch 9103/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1211e-05 \n",
            "Epoch 9104/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2310e-05 \n",
            "Epoch 9105/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2166e-05 \n",
            "Epoch 9106/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3627e-05 \n",
            "Epoch 9107/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4486e-05 \n",
            "Epoch 9108/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2740e-05 \n",
            "Epoch 9109/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1861e-05 \n",
            "Epoch 9110/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2551e-05 \n",
            "Epoch 9111/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3271e-05 \n",
            "Epoch 9112/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3221e-05 \n",
            "Epoch 9113/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1502e-05 \n",
            "Epoch 9114/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4255e-05 \n",
            "Epoch 9115/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2384e-05 \n",
            "Epoch 9116/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2410e-05 \n",
            "Epoch 9117/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0808e-05 \n",
            "Epoch 9118/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2293e-05 \n",
            "Epoch 9119/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2825e-05 \n",
            "Epoch 9120/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2342e-05 \n",
            "Epoch 9121/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1813e-05 \n",
            "Epoch 9122/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3285e-05 \n",
            "Epoch 9123/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1122e-05 \n",
            "Epoch 9124/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1673e-05 \n",
            "Epoch 9125/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1727e-05 \n",
            "Epoch 9126/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2632e-05 \n",
            "Epoch 9127/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1671e-05 \n",
            "Epoch 9128/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2031e-05 \n",
            "Epoch 9129/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1968e-05 \n",
            "Epoch 9130/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2347e-05 \n",
            "Epoch 9131/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3120e-05 \n",
            "Epoch 9132/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0987e-05 \n",
            "Epoch 9133/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0864e-05 \n",
            "Epoch 9134/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1191e-05 \n",
            "Epoch 9135/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0949e-05 \n",
            "Epoch 9136/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2318e-05 \n",
            "Epoch 9137/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2202e-05 \n",
            "Epoch 9138/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3798e-05 \n",
            "Epoch 9139/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0144e-05 \n",
            "Epoch 9140/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1485e-05 \n",
            "Epoch 9141/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1920e-05 \n",
            "Epoch 9142/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1996e-05 \n",
            "Epoch 9143/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1034e-05 \n",
            "Epoch 9144/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1378e-05 \n",
            "Epoch 9145/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8310e-06 \n",
            "Epoch 9146/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1430e-05 \n",
            "Epoch 9147/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1503e-05 \n",
            "Epoch 9148/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0486e-05 \n",
            "Epoch 9149/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0718e-05 \n",
            "Epoch 9150/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1572e-05 \n",
            "Epoch 9151/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1686e-05 \n",
            "Epoch 9152/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1265e-05 \n",
            "Epoch 9153/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2246e-05 \n",
            "Epoch 9154/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1021e-05 \n",
            "Epoch 9155/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2676e-05 \n",
            "Epoch 9156/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2086e-05 \n",
            "Epoch 9157/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2048e-05 \n",
            "Epoch 9158/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0134e-05 \n",
            "Epoch 9159/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0776e-05 \n",
            "Epoch 9160/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1883e-05 \n",
            "Epoch 9161/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0717e-05 \n",
            "Epoch 9162/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1423e-05 \n",
            "Epoch 9163/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1718e-05 \n",
            "Epoch 9164/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0575e-05 \n",
            "Epoch 9165/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1314e-05 \n",
            "Epoch 9166/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0435e-05 \n",
            "Epoch 9167/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0809e-05 \n",
            "Epoch 9168/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0129e-05 \n",
            "Epoch 9169/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1045e-05 \n",
            "Epoch 9170/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2227e-06 \n",
            "Epoch 9171/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1811e-05 \n",
            "Epoch 9172/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0192e-05 \n",
            "Epoch 9173/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0943e-05 \n",
            "Epoch 9174/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6431e-06 \n",
            "Epoch 9175/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0391e-05 \n",
            "Epoch 9176/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6506e-06 \n",
            "Epoch 9177/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1756e-05 \n",
            "Epoch 9178/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8925e-06 \n",
            "Epoch 9179/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0034e-05 \n",
            "Epoch 9180/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9134e-06 \n",
            "Epoch 9181/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7561e-06 \n",
            "Epoch 9182/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0492e-05 \n",
            "Epoch 9183/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0738e-05 \n",
            "Epoch 9184/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1267e-05 \n",
            "Epoch 9185/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2880e-06 \n",
            "Epoch 9186/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7973e-06 \n",
            "Epoch 9187/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9514e-06 \n",
            "Epoch 9188/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0503e-05 \n",
            "Epoch 9189/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0787e-05 \n",
            "Epoch 9190/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0073e-05 \n",
            "Epoch 9191/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0802e-05 \n",
            "Epoch 9192/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0222e-05 \n",
            "Epoch 9193/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6923e-06 \n",
            "Epoch 9194/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3615e-06 \n",
            "Epoch 9195/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0581e-05 \n",
            "Epoch 9196/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5736e-06 \n",
            "Epoch 9197/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4424e-06 \n",
            "Epoch 9198/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1311e-06 \n",
            "Epoch 9199/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4290e-06 \n",
            "Epoch 9200/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.8545e-06\n",
            "Test accuracy at epoch 9200: 33.68%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.9123e-06\n",
            "Epoch 9201/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0017e-05 \n",
            "Epoch 9202/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4315e-06 \n",
            "Epoch 9203/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0026e-05 \n",
            "Epoch 9204/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6758e-06 \n",
            "Epoch 9205/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0237e-05 \n",
            "Epoch 9206/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8486e-06 \n",
            "Epoch 9207/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6863e-06 \n",
            "Epoch 9208/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8029e-06 \n",
            "Epoch 9209/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0003e-05 \n",
            "Epoch 9210/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1960e-06 \n",
            "Epoch 9211/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8284e-06 \n",
            "Epoch 9212/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4798e-06 \n",
            "Epoch 9213/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2542e-06 \n",
            "Epoch 9214/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9669e-06 \n",
            "Epoch 9215/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9327e-06 \n",
            "Epoch 9216/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1108e-06 \n",
            "Epoch 9217/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3338e-06 \n",
            "Epoch 9218/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8386e-06 \n",
            "Epoch 9219/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2629e-06 \n",
            "Epoch 9220/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0502e-05 \n",
            "Epoch 9221/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7420e-06 \n",
            "Epoch 9222/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8122e-06 \n",
            "Epoch 9223/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7052e-06 \n",
            "Epoch 9224/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9698e-06 \n",
            "Epoch 9225/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3017e-06 \n",
            "Epoch 9226/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9288e-06 \n",
            "Epoch 9227/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0082e-06 \n",
            "Epoch 9228/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3918e-06 \n",
            "Epoch 9229/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6135e-06 \n",
            "Epoch 9230/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0374e-06 \n",
            "Epoch 9231/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6905e-06 \n",
            "Epoch 9232/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0356e-05 \n",
            "Epoch 9233/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6958e-06 \n",
            "Epoch 9234/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9914e-06 \n",
            "Epoch 9235/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2293e-06 \n",
            "Epoch 9236/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0656e-05 \n",
            "Epoch 9237/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4473e-06 \n",
            "Epoch 9238/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1984e-06 \n",
            "Epoch 9239/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0191e-05 \n",
            "Epoch 9240/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8761e-06 \n",
            "Epoch 9241/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3824e-06 \n",
            "Epoch 9242/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5900e-06 \n",
            "Epoch 9243/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0765e-05 \n",
            "Epoch 9244/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8753e-06 \n",
            "Epoch 9245/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5006e-06 \n",
            "Epoch 9246/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1114e-06 \n",
            "Epoch 9247/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0004e-06 \n",
            "Epoch 9248/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5489e-06 \n",
            "Epoch 9249/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1840e-06 \n",
            "Epoch 9250/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9246e-06 \n",
            "Epoch 9251/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9223e-06 \n",
            "Epoch 9252/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7580e-06 \n",
            "Epoch 9253/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9532e-06 \n",
            "Epoch 9254/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7654e-06 \n",
            "Epoch 9255/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2748e-06 \n",
            "Epoch 9256/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9803e-06 \n",
            "Epoch 9257/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4344e-06 \n",
            "Epoch 9258/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7825e-06 \n",
            "Epoch 9259/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9177e-06 \n",
            "Epoch 9260/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5455e-06 \n",
            "Epoch 9261/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1850e-06 \n",
            "Epoch 9262/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6876e-06 \n",
            "Epoch 9263/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4928e-06 \n",
            "Epoch 9264/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8005e-06 \n",
            "Epoch 9265/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9913e-06 \n",
            "Epoch 9266/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3813e-06 \n",
            "Epoch 9267/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0334e-06 \n",
            "Epoch 9268/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7682e-06 \n",
            "Epoch 9269/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3400e-06 \n",
            "Epoch 9270/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3189e-06 \n",
            "Epoch 9271/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7134e-06 \n",
            "Epoch 9272/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0731e-06 \n",
            "Epoch 9273/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9227e-06 \n",
            "Epoch 9274/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9406e-06 \n",
            "Epoch 9275/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5639e-06 \n",
            "Epoch 9276/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7026e-06 \n",
            "Epoch 9277/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7810e-06 \n",
            "Epoch 9278/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5430e-06 \n",
            "Epoch 9279/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6149e-06 \n",
            "Epoch 9280/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2076e-06 \n",
            "Epoch 9281/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4032e-06 \n",
            "Epoch 9282/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8401e-06 \n",
            "Epoch 9283/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4680e-06 \n",
            "Epoch 9284/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5204e-06 \n",
            "Epoch 9285/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8887e-06 \n",
            "Epoch 9286/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8183e-06 \n",
            "Epoch 9287/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6425e-06 \n",
            "Epoch 9288/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7459e-06 \n",
            "Epoch 9289/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4369e-06 \n",
            "Epoch 9290/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2341e-06 \n",
            "Epoch 9291/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6764e-06 \n",
            "Epoch 9292/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1746e-06 \n",
            "Epoch 9293/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0899e-06 \n",
            "Epoch 9294/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1571e-06 \n",
            "Epoch 9295/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2006e-06 \n",
            "Epoch 9296/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9491e-06 \n",
            "Epoch 9297/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1466e-06 \n",
            "Epoch 9298/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7013e-06 \n",
            "Epoch 9299/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9404e-06 \n",
            "Epoch 9300/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.7517e-06\n",
            "Test accuracy at epoch 9300: 33.69%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.2219e-06\n",
            "Epoch 9301/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3349e-06 \n",
            "Epoch 9302/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5696e-06 \n",
            "Epoch 9303/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2517e-06 \n",
            "Epoch 9304/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3739e-06 \n",
            "Epoch 9305/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1317e-06 \n",
            "Epoch 9306/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9745e-06 \n",
            "Epoch 9307/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2763e-06 \n",
            "Epoch 9308/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7098e-06 \n",
            "Epoch 9309/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4741e-06 \n",
            "Epoch 9310/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1121e-06 \n",
            "Epoch 9311/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4657e-06 \n",
            "Epoch 9312/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3225e-06 \n",
            "Epoch 9313/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1616e-06 \n",
            "Epoch 9314/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2553e-06 \n",
            "Epoch 9315/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9355e-06 \n",
            "Epoch 9316/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0961e-06 \n",
            "Epoch 9317/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0748e-06 \n",
            "Epoch 9318/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2259e-06 \n",
            "Epoch 9319/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9634e-06 \n",
            "Epoch 9320/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3101e-06 \n",
            "Epoch 9321/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1218e-06 \n",
            "Epoch 9322/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1713e-06 \n",
            "Epoch 9323/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2584e-06 \n",
            "Epoch 9324/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6193e-06 \n",
            "Epoch 9325/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7660e-06 \n",
            "Epoch 9326/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3672e-06 \n",
            "Epoch 9327/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7135e-06 \n",
            "Epoch 9328/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5467e-06 \n",
            "Epoch 9329/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2010e-06 \n",
            "Epoch 9330/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0627e-06 \n",
            "Epoch 9331/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8140e-06 \n",
            "Epoch 9332/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9466e-06 \n",
            "Epoch 9333/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4410e-06 \n",
            "Epoch 9334/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6724e-06 \n",
            "Epoch 9335/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4798e-06 \n",
            "Epoch 9336/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8588e-06 \n",
            "Epoch 9337/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3150e-06 \n",
            "Epoch 9338/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5148e-06 \n",
            "Epoch 9339/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5421e-06 \n",
            "Epoch 9340/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7939e-06 \n",
            "Epoch 9341/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3293e-06 \n",
            "Epoch 9342/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3159e-06 \n",
            "Epoch 9343/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6305e-06 \n",
            "Epoch 9344/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2923e-06 \n",
            "Epoch 9345/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0001e-06 \n",
            "Epoch 9346/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2913e-06 \n",
            "Epoch 9347/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1655e-06 \n",
            "Epoch 9348/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5398e-06 \n",
            "Epoch 9349/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7088e-06 \n",
            "Epoch 9350/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3857e-06 \n",
            "Epoch 9351/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8661e-06 \n",
            "Epoch 9352/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2943e-06 \n",
            "Epoch 9353/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1531e-06 \n",
            "Epoch 9354/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8066e-06 \n",
            "Epoch 9355/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3000e-06 \n",
            "Epoch 9356/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5568e-06 \n",
            "Epoch 9357/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1984e-06 \n",
            "Epoch 9358/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9427e-06 \n",
            "Epoch 9359/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7005e-06 \n",
            "Epoch 9360/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2764e-06 \n",
            "Epoch 9361/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3614e-06 \n",
            "Epoch 9362/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4473e-06 \n",
            "Epoch 9363/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6841e-06 \n",
            "Epoch 9364/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5223e-06 \n",
            "Epoch 9365/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6664e-06 \n",
            "Epoch 9366/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9471e-06 \n",
            "Epoch 9367/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0566e-06 \n",
            "Epoch 9368/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3240e-06 \n",
            "Epoch 9369/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4337e-06 \n",
            "Epoch 9370/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4418e-06 \n",
            "Epoch 9371/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3559e-06 \n",
            "Epoch 9372/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4641e-06 \n",
            "Epoch 9373/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0125e-06 \n",
            "Epoch 9374/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8900e-06 \n",
            "Epoch 9375/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1226e-06 \n",
            "Epoch 9376/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1380e-06 \n",
            "Epoch 9377/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3970e-06 \n",
            "Epoch 9378/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9671e-06 \n",
            "Epoch 9379/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7793e-06 \n",
            "Epoch 9380/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7003e-06 \n",
            "Epoch 9381/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1451e-06 \n",
            "Epoch 9382/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6269e-06 \n",
            "Epoch 9383/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8670e-06 \n",
            "Epoch 9384/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1642e-06 \n",
            "Epoch 9385/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4378e-06 \n",
            "Epoch 9386/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6110e-06 \n",
            "Epoch 9387/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1116e-06 \n",
            "Epoch 9388/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8621e-06 \n",
            "Epoch 9389/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5639e-06 \n",
            "Epoch 9390/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9448e-06 \n",
            "Epoch 9391/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3629e-06 \n",
            "Epoch 9392/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7615e-06 \n",
            "Epoch 9393/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2297e-06 \n",
            "Epoch 9394/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7035e-06 \n",
            "Epoch 9395/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5989e-06 \n",
            "Epoch 9396/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6198e-06 \n",
            "Epoch 9397/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7507e-06 \n",
            "Epoch 9398/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8355e-06 \n",
            "Epoch 9399/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8909e-06 \n",
            "Epoch 9400/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.6363e-06\n",
            "Test accuracy at epoch 9400: 33.69%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.5951e-06\n",
            "Epoch 9401/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8871e-06 \n",
            "Epoch 9402/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3652e-06 \n",
            "Epoch 9403/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0563e-06 \n",
            "Epoch 9404/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7308e-06 \n",
            "Epoch 9405/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9840e-06 \n",
            "Epoch 9406/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0460e-06 \n",
            "Epoch 9407/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5191e-06 \n",
            "Epoch 9408/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0405e-06 \n",
            "Epoch 9409/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5425e-06 \n",
            "Epoch 9410/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7858e-06 \n",
            "Epoch 9411/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9665e-06 \n",
            "Epoch 9412/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3094e-06 \n",
            "Epoch 9413/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0594e-06 \n",
            "Epoch 9414/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8750e-06 \n",
            "Epoch 9415/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1390e-06 \n",
            "Epoch 9416/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5896e-06 \n",
            "Epoch 9417/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0205e-06 \n",
            "Epoch 9418/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9389e-06 \n",
            "Epoch 9419/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9887e-06 \n",
            "Epoch 9420/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6527e-06 \n",
            "Epoch 9421/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6676e-06 \n",
            "Epoch 9422/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4054e-06 \n",
            "Epoch 9423/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3288e-06 \n",
            "Epoch 9424/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7459e-06 \n",
            "Epoch 9425/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2818e-06 \n",
            "Epoch 9426/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7083e-06 \n",
            "Epoch 9427/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7479e-06 \n",
            "Epoch 9428/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8053e-06 \n",
            "Epoch 9429/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0261e-06 \n",
            "Epoch 9430/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7118e-06 \n",
            "Epoch 9431/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8822e-06 \n",
            "Epoch 9432/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3847e-06 \n",
            "Epoch 9433/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0531e-06 \n",
            "Epoch 9434/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7769e-06 \n",
            "Epoch 9435/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6383e-06 \n",
            "Epoch 9436/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6973e-06 \n",
            "Epoch 9437/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2455e-06 \n",
            "Epoch 9438/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1913e-06 \n",
            "Epoch 9439/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6130e-06 \n",
            "Epoch 9440/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3456e-06 \n",
            "Epoch 9441/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6422e-06 \n",
            "Epoch 9442/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6255e-06 \n",
            "Epoch 9443/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7421e-06 \n",
            "Epoch 9444/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5652e-06 \n",
            "Epoch 9445/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6043e-06 \n",
            "Epoch 9446/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4575e-06 \n",
            "Epoch 9447/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0872e-06 \n",
            "Epoch 9448/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1513e-06 \n",
            "Epoch 9449/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7541e-06 \n",
            "Epoch 9450/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6687e-06 \n",
            "Epoch 9451/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9606e-06 \n",
            "Epoch 9452/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5049e-06 \n",
            "Epoch 9453/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8147e-06 \n",
            "Epoch 9454/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7281e-06 \n",
            "Epoch 9455/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2167e-06 \n",
            "Epoch 9456/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6436e-06 \n",
            "Epoch 9457/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8706e-06 \n",
            "Epoch 9458/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5417e-06 \n",
            "Epoch 9459/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8231e-06 \n",
            "Epoch 9460/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7524e-06 \n",
            "Epoch 9461/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3993e-06 \n",
            "Epoch 9462/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3890e-06 \n",
            "Epoch 9463/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5080e-06 \n",
            "Epoch 9464/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6573e-06 \n",
            "Epoch 9465/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0684e-06 \n",
            "Epoch 9466/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1315e-06 \n",
            "Epoch 9467/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3562e-06 \n",
            "Epoch 9468/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0733e-06 \n",
            "Epoch 9469/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4511e-06 \n",
            "Epoch 9470/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1351e-06 \n",
            "Epoch 9471/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7033e-06 \n",
            "Epoch 9472/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3701e-06 \n",
            "Epoch 9473/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4834e-06 \n",
            "Epoch 9474/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0972e-06 \n",
            "Epoch 9475/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7868e-06 \n",
            "Epoch 9476/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6944e-06 \n",
            "Epoch 9477/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4296e-06 \n",
            "Epoch 9478/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1047e-06 \n",
            "Epoch 9479/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1961e-06 \n",
            "Epoch 9480/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2900e-06 \n",
            "Epoch 9481/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9475e-06 \n",
            "Epoch 9482/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2365e-06 \n",
            "Epoch 9483/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3569e-06 \n",
            "Epoch 9484/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0247e-06 \n",
            "Epoch 9485/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6699e-06 \n",
            "Epoch 9486/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4478e-06 \n",
            "Epoch 9487/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9541e-06 \n",
            "Epoch 9488/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8565e-06 \n",
            "Epoch 9489/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1021e-06 \n",
            "Epoch 9490/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1783e-06 \n",
            "Epoch 9491/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0197e-06 \n",
            "Epoch 9492/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8295e-06 \n",
            "Epoch 9493/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9264e-06 \n",
            "Epoch 9494/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4545e-06 \n",
            "Epoch 9495/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9276e-06 \n",
            "Epoch 9496/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0243e-06 \n",
            "Epoch 9497/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3578e-06 \n",
            "Epoch 9498/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6421e-06 \n",
            "Epoch 9499/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9982e-06 \n",
            "Epoch 9500/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.7253e-06\n",
            "Test accuracy at epoch 9500: 33.75%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.1011e-06\n",
            "Epoch 9501/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3786e-06 \n",
            "Epoch 9502/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0846e-06 \n",
            "Epoch 9503/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7144e-06 \n",
            "Epoch 9504/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0568e-06 \n",
            "Epoch 9505/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7970e-06 \n",
            "Epoch 9506/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1157e-06 \n",
            "Epoch 9507/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8684e-06 \n",
            "Epoch 9508/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7415e-06 \n",
            "Epoch 9509/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6965e-06 \n",
            "Epoch 9510/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7193e-06 \n",
            "Epoch 9511/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7800e-06 \n",
            "Epoch 9512/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7047e-06 \n",
            "Epoch 9513/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8862e-06 \n",
            "Epoch 9514/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7714e-06 \n",
            "Epoch 9515/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7146e-06 \n",
            "Epoch 9516/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0604e-06 \n",
            "Epoch 9517/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5818e-06 \n",
            "Epoch 9518/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1119e-06 \n",
            "Epoch 9519/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2170e-06 \n",
            "Epoch 9520/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5525e-06 \n",
            "Epoch 9521/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0463e-06 \n",
            "Epoch 9522/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1754e-06 \n",
            "Epoch 9523/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8894e-06 \n",
            "Epoch 9524/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8098e-06 \n",
            "Epoch 9525/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0475e-06 \n",
            "Epoch 9526/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3699e-06 \n",
            "Epoch 9527/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7913e-06 \n",
            "Epoch 9528/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4295e-06 \n",
            "Epoch 9529/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4685e-06 \n",
            "Epoch 9530/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9514e-06 \n",
            "Epoch 9531/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5249e-06 \n",
            "Epoch 9532/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7333e-06 \n",
            "Epoch 9533/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3169e-06 \n",
            "Epoch 9534/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3282e-06 \n",
            "Epoch 9535/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9520e-06 \n",
            "Epoch 9536/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6509e-06 \n",
            "Epoch 9537/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4387e-06 \n",
            "Epoch 9538/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6817e-06 \n",
            "Epoch 9539/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8249e-06 \n",
            "Epoch 9540/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7648e-06 \n",
            "Epoch 9541/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6856e-06 \n",
            "Epoch 9542/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4071e-06 \n",
            "Epoch 9543/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4698e-06 \n",
            "Epoch 9544/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4281e-06 \n",
            "Epoch 9545/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9014e-06 \n",
            "Epoch 9546/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8773e-06 \n",
            "Epoch 9547/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3267e-06 \n",
            "Epoch 9548/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3679e-06 \n",
            "Epoch 9549/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6246e-06 \n",
            "Epoch 9550/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4425e-06 \n",
            "Epoch 9551/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2813e-06 \n",
            "Epoch 9552/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5940e-06 \n",
            "Epoch 9553/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5180e-06 \n",
            "Epoch 9554/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9641e-06 \n",
            "Epoch 9555/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2515e-06 \n",
            "Epoch 9556/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8006e-06 \n",
            "Epoch 9557/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4931e-06 \n",
            "Epoch 9558/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3373e-06 \n",
            "Epoch 9559/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3967e-06 \n",
            "Epoch 9560/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3135e-06 \n",
            "Epoch 9561/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2253e-06 \n",
            "Epoch 9562/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5225e-06 \n",
            "Epoch 9563/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3770e-06 \n",
            "Epoch 9564/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2287e-06 \n",
            "Epoch 9565/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0415e-06 \n",
            "Epoch 9566/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3820e-06 \n",
            "Epoch 9567/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9243e-06 \n",
            "Epoch 9568/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1971e-06 \n",
            "Epoch 9569/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2834e-06 \n",
            "Epoch 9570/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9380e-06 \n",
            "Epoch 9571/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8181e-06 \n",
            "Epoch 9572/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9986e-06 \n",
            "Epoch 9573/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8296e-06 \n",
            "Epoch 9574/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2414e-06 \n",
            "Epoch 9575/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1904e-06 \n",
            "Epoch 9576/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9403e-06 \n",
            "Epoch 9577/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4547e-06 \n",
            "Epoch 9578/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3480e-06 \n",
            "Epoch 9579/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6342e-06 \n",
            "Epoch 9580/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1301e-06 \n",
            "Epoch 9581/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6852e-06 \n",
            "Epoch 9582/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1952e-06 \n",
            "Epoch 9583/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0789e-06 \n",
            "Epoch 9584/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2369e-06 \n",
            "Epoch 9585/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3039e-06 \n",
            "Epoch 9586/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1192e-06 \n",
            "Epoch 9587/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1636e-06 \n",
            "Epoch 9588/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9507e-06 \n",
            "Epoch 9589/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9071e-06 \n",
            "Epoch 9590/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8232e-06 \n",
            "Epoch 9591/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1051e-06 \n",
            "Epoch 9592/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5858e-06 \n",
            "Epoch 9593/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1434e-06 \n",
            "Epoch 9594/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5294e-06 \n",
            "Epoch 9595/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7078e-06 \n",
            "Epoch 9596/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2269e-06 \n",
            "Epoch 9597/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1768e-06 \n",
            "Epoch 9598/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9972e-06 \n",
            "Epoch 9599/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1576e-06 \n",
            "Epoch 9600/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.5108e-06\n",
            "Test accuracy at epoch 9600: 33.77%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.9092e-06\n",
            "Epoch 9601/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5802e-06 \n",
            "Epoch 9602/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0135e-06 \n",
            "Epoch 9603/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2244e-06 \n",
            "Epoch 9604/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9601e-06 \n",
            "Epoch 9605/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4337e-06 \n",
            "Epoch 9606/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8686e-06 \n",
            "Epoch 9607/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2165e-06 \n",
            "Epoch 9608/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0866e-06 \n",
            "Epoch 9609/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1676e-06 \n",
            "Epoch 9610/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2138e-06 \n",
            "Epoch 9611/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7703e-06 \n",
            "Epoch 9612/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9523e-06 \n",
            "Epoch 9613/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9899e-06 \n",
            "Epoch 9614/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5466e-06 \n",
            "Epoch 9615/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9483e-06 \n",
            "Epoch 9616/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0463e-06 \n",
            "Epoch 9617/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9909e-06 \n",
            "Epoch 9618/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5047e-06 \n",
            "Epoch 9619/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7154e-06 \n",
            "Epoch 9620/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9177e-06 \n",
            "Epoch 9621/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0951e-06 \n",
            "Epoch 9622/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7088e-06 \n",
            "Epoch 9623/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6179e-06 \n",
            "Epoch 9624/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5661e-06 \n",
            "Epoch 9625/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4352e-06 \n",
            "Epoch 9626/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8663e-06 \n",
            "Epoch 9627/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4655e-06 \n",
            "Epoch 9628/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9468e-06 \n",
            "Epoch 9629/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8628e-06 \n",
            "Epoch 9630/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6299e-06 \n",
            "Epoch 9631/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7497e-06 \n",
            "Epoch 9632/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6111e-06 \n",
            "Epoch 9633/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9821e-06 \n",
            "Epoch 9634/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6110e-06 \n",
            "Epoch 9635/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6963e-06 \n",
            "Epoch 9636/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6864e-06 \n",
            "Epoch 9637/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6384e-06 \n",
            "Epoch 9638/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6655e-06 \n",
            "Epoch 9639/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5838e-06 \n",
            "Epoch 9640/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5942e-06 \n",
            "Epoch 9641/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6427e-06 \n",
            "Epoch 9642/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8199e-06 \n",
            "Epoch 9643/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6155e-06 \n",
            "Epoch 9644/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3000e-06 \n",
            "Epoch 9645/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4261e-06 \n",
            "Epoch 9646/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4811e-06 \n",
            "Epoch 9647/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4095e-06 \n",
            "Epoch 9648/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6977e-06 \n",
            "Epoch 9649/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4359e-06 \n",
            "Epoch 9650/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0625e-06 \n",
            "Epoch 9651/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4077e-06 \n",
            "Epoch 9652/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3618e-06 \n",
            "Epoch 9653/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3561e-06 \n",
            "Epoch 9654/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4480e-06 \n",
            "Epoch 9655/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3471e-06 \n",
            "Epoch 9656/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5786e-06 \n",
            "Epoch 9657/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6307e-06 \n",
            "Epoch 9658/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3659e-06 \n",
            "Epoch 9659/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1603e-06 \n",
            "Epoch 9660/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4282e-06 \n",
            "Epoch 9661/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7110e-06 \n",
            "Epoch 9662/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5993e-06 \n",
            "Epoch 9663/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5467e-06 \n",
            "Epoch 9664/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3336e-06 \n",
            "Epoch 9665/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7035e-06 \n",
            "Epoch 9666/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2800e-06 \n",
            "Epoch 9667/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2091e-06 \n",
            "Epoch 9668/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8793e-06 \n",
            "Epoch 9669/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3065e-06 \n",
            "Epoch 9670/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6294e-06 \n",
            "Epoch 9671/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0665e-06 \n",
            "Epoch 9672/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0432e-06 \n",
            "Epoch 9673/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4771e-06 \n",
            "Epoch 9674/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5656e-06 \n",
            "Epoch 9675/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2708e-06 \n",
            "Epoch 9676/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4545e-06 \n",
            "Epoch 9677/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3320e-06 \n",
            "Epoch 9678/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5785e-06 \n",
            "Epoch 9679/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3566e-06 \n",
            "Epoch 9680/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2485e-06 \n",
            "Epoch 9681/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3647e-06 \n",
            "Epoch 9682/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2446e-06 \n",
            "Epoch 9683/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3679e-06 \n",
            "Epoch 9684/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0867e-06 \n",
            "Epoch 9685/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3617e-06 \n",
            "Epoch 9686/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4552e-06 \n",
            "Epoch 9687/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4971e-06 \n",
            "Epoch 9688/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9961e-06 \n",
            "Epoch 9689/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2398e-06 \n",
            "Epoch 9690/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3297e-06 \n",
            "Epoch 9691/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4223e-06 \n",
            "Epoch 9692/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1794e-06 \n",
            "Epoch 9693/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1503e-06 \n",
            "Epoch 9694/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3773e-06 \n",
            "Epoch 9695/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2461e-06 \n",
            "Epoch 9696/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0890e-06 \n",
            "Epoch 9697/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0963e-06 \n",
            "Epoch 9698/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3776e-06 \n",
            "Epoch 9699/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0027e-06 \n",
            "Epoch 9700/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.8440e-06\n",
            "Test accuracy at epoch 9700: 33.81%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.1282e-06\n",
            "Epoch 9701/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2807e-06 \n",
            "Epoch 9702/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2690e-06 \n",
            "Epoch 9703/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0905e-06 \n",
            "Epoch 9704/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2576e-06 \n",
            "Epoch 9705/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2012e-06 \n",
            "Epoch 9706/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1520e-06 \n",
            "Epoch 9707/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9434e-06 \n",
            "Epoch 9708/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5540e-06 \n",
            "Epoch 9709/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2425e-06 \n",
            "Epoch 9710/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8816e-06 \n",
            "Epoch 9711/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9663e-06 \n",
            "Epoch 9712/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2030e-06 \n",
            "Epoch 9713/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9659e-06 \n",
            "Epoch 9714/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1408e-06 \n",
            "Epoch 9715/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9911e-06 \n",
            "Epoch 9716/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9282e-06 \n",
            "Epoch 9717/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0554e-06 \n",
            "Epoch 9718/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2223e-06 \n",
            "Epoch 9719/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9989e-06 \n",
            "Epoch 9720/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9405e-06 \n",
            "Epoch 9721/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1299e-06 \n",
            "Epoch 9722/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0544e-06 \n",
            "Epoch 9723/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9477e-06 \n",
            "Epoch 9724/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1755e-06 \n",
            "Epoch 9725/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1099e-06 \n",
            "Epoch 9726/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2072e-06 \n",
            "Epoch 9727/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9925e-06 \n",
            "Epoch 9728/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0264e-06 \n",
            "Epoch 9729/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0282e-06 \n",
            "Epoch 9730/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8856e-06 \n",
            "Epoch 9731/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0960e-06 \n",
            "Epoch 9732/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0808e-06 \n",
            "Epoch 9733/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8223e-06 \n",
            "Epoch 9734/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2863e-06 \n",
            "Epoch 9735/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0697e-06 \n",
            "Epoch 9736/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0957e-06 \n",
            "Epoch 9737/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0106e-06 \n",
            "Epoch 9738/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9718e-06 \n",
            "Epoch 9739/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9940e-06 \n",
            "Epoch 9740/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1914e-06 \n",
            "Epoch 9741/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0148e-06 \n",
            "Epoch 9742/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8510e-06 \n",
            "Epoch 9743/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7956e-06 \n",
            "Epoch 9744/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8918e-06 \n",
            "Epoch 9745/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8254e-06 \n",
            "Epoch 9746/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8736e-06 \n",
            "Epoch 9747/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8643e-06 \n",
            "Epoch 9748/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8041e-06 \n",
            "Epoch 9749/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9485e-06 \n",
            "Epoch 9750/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7234e-06 \n",
            "Epoch 9751/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0603e-06 \n",
            "Epoch 9752/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8719e-06 \n",
            "Epoch 9753/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0144e-06 \n",
            "Epoch 9754/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7536e-06 \n",
            "Epoch 9755/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1627e-06 \n",
            "Epoch 9756/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7813e-06 \n",
            "Epoch 9757/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7269e-06 \n",
            "Epoch 9758/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7460e-06 \n",
            "Epoch 9759/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9355e-06 \n",
            "Epoch 9760/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6360e-06 \n",
            "Epoch 9761/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8247e-06 \n",
            "Epoch 9762/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6625e-06 \n",
            "Epoch 9763/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6352e-06 \n",
            "Epoch 9764/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6182e-06 \n",
            "Epoch 9765/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7077e-06 \n",
            "Epoch 9766/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9278e-06 \n",
            "Epoch 9767/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9407e-06 \n",
            "Epoch 9768/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7898e-06 \n",
            "Epoch 9769/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8956e-06 \n",
            "Epoch 9770/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7082e-06 \n",
            "Epoch 9771/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8347e-06 \n",
            "Epoch 9772/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7762e-06 \n",
            "Epoch 9773/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8695e-06 \n",
            "Epoch 9774/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8191e-06 \n",
            "Epoch 9775/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0530e-06 \n",
            "Epoch 9776/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7651e-06 \n",
            "Epoch 9777/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8486e-06 \n",
            "Epoch 9778/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8655e-06 \n",
            "Epoch 9779/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6956e-06 \n",
            "Epoch 9780/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6940e-06 \n",
            "Epoch 9781/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6763e-06 \n",
            "Epoch 9782/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8123e-06 \n",
            "Epoch 9783/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8140e-06 \n",
            "Epoch 9784/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6954e-06 \n",
            "Epoch 9785/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7814e-06 \n",
            "Epoch 9786/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7465e-06 \n",
            "Epoch 9787/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3875e-06 \n",
            "Epoch 9788/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6218e-06 \n",
            "Epoch 9789/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7348e-06 \n",
            "Epoch 9790/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5487e-06 \n",
            "Epoch 9791/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6387e-06 \n",
            "Epoch 9792/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4633e-06 \n",
            "Epoch 9793/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6541e-06 \n",
            "Epoch 9794/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5755e-06 \n",
            "Epoch 9795/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6365e-06 \n",
            "Epoch 9796/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7732e-06 \n",
            "Epoch 9797/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6700e-06 \n",
            "Epoch 9798/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6759e-06 \n",
            "Epoch 9799/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7558e-06 \n",
            "Epoch 9800/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.3784e-06\n",
            "Test accuracy at epoch 9800: 33.86%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.4942e-06\n",
            "Epoch 9801/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3650e-06 \n",
            "Epoch 9802/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4539e-06 \n",
            "Epoch 9803/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4822e-06 \n",
            "Epoch 9804/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4290e-06 \n",
            "Epoch 9805/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7285e-06 \n",
            "Epoch 9806/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6750e-06 \n",
            "Epoch 9807/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4261e-06 \n",
            "Epoch 9808/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9804e-06 \n",
            "Epoch 9809/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5221e-06 \n",
            "Epoch 9810/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6667e-06 \n",
            "Epoch 9811/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4763e-06 \n",
            "Epoch 9812/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3832e-06 \n",
            "Epoch 9813/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4976e-06 \n",
            "Epoch 9814/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5700e-06 \n",
            "Epoch 9815/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5682e-06 \n",
            "Epoch 9816/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5949e-06 \n",
            "Epoch 9817/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4795e-06 \n",
            "Epoch 9818/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5523e-06 \n",
            "Epoch 9819/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4410e-06 \n",
            "Epoch 9820/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5212e-06 \n",
            "Epoch 9821/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5305e-06 \n",
            "Epoch 9822/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4053e-06 \n",
            "Epoch 9823/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4917e-06 \n",
            "Epoch 9824/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3672e-06 \n",
            "Epoch 9825/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3901e-06 \n",
            "Epoch 9826/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5807e-06 \n",
            "Epoch 9827/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4834e-06 \n",
            "Epoch 9828/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4376e-06 \n",
            "Epoch 9829/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5637e-06 \n",
            "Epoch 9830/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4477e-06 \n",
            "Epoch 9831/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4847e-06 \n",
            "Epoch 9832/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6311e-06 \n",
            "Epoch 9833/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4399e-06 \n",
            "Epoch 9834/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3874e-06 \n",
            "Epoch 9835/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2649e-06 \n",
            "Epoch 9836/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3875e-06 \n",
            "Epoch 9837/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4073e-06 \n",
            "Epoch 9838/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3122e-06 \n",
            "Epoch 9839/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5776e-06 \n",
            "Epoch 9840/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4279e-06 \n",
            "Epoch 9841/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4965e-06 \n",
            "Epoch 9842/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3951e-06 \n",
            "Epoch 9843/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3088e-06 \n",
            "Epoch 9844/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4802e-06 \n",
            "Epoch 9845/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3333e-06 \n",
            "Epoch 9846/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3083e-06 \n",
            "Epoch 9847/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3668e-06 \n",
            "Epoch 9848/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3586e-06 \n",
            "Epoch 9849/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5574e-06 \n",
            "Epoch 9850/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3586e-06 \n",
            "Epoch 9851/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2942e-06 \n",
            "Epoch 9852/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4155e-06 \n",
            "Epoch 9853/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3866e-06 \n",
            "Epoch 9854/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3410e-06 \n",
            "Epoch 9855/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4543e-06 \n",
            "Epoch 9856/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3065e-06 \n",
            "Epoch 9857/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2449e-06 \n",
            "Epoch 9858/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5545e-06 \n",
            "Epoch 9859/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2775e-06 \n",
            "Epoch 9860/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4554e-06 \n",
            "Epoch 9861/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4610e-06 \n",
            "Epoch 9862/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4154e-06 \n",
            "Epoch 9863/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3789e-06 \n",
            "Epoch 9864/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4065e-06 \n",
            "Epoch 9865/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2283e-06 \n",
            "Epoch 9866/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2708e-06 \n",
            "Epoch 9867/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5419e-06 \n",
            "Epoch 9868/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3810e-06 \n",
            "Epoch 9869/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3007e-06 \n",
            "Epoch 9870/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1160e-06 \n",
            "Epoch 9871/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3798e-06 \n",
            "Epoch 9872/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2507e-06 \n",
            "Epoch 9873/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3130e-06 \n",
            "Epoch 9874/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1809e-06 \n",
            "Epoch 9875/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2377e-06 \n",
            "Epoch 9876/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3759e-06 \n",
            "Epoch 9877/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2425e-06 \n",
            "Epoch 9878/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2394e-06 \n",
            "Epoch 9879/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6601e-06 \n",
            "Epoch 9880/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3997e-06 \n",
            "Epoch 9881/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2369e-06 \n",
            "Epoch 9882/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2396e-06 \n",
            "Epoch 9883/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4238e-06 \n",
            "Epoch 9884/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3575e-06 \n",
            "Epoch 9885/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2767e-06 \n",
            "Epoch 9886/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2960e-06 \n",
            "Epoch 9887/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2275e-06 \n",
            "Epoch 9888/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2498e-06 \n",
            "Epoch 9889/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2915e-06 \n",
            "Epoch 9890/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0549e-06 \n",
            "Epoch 9891/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2718e-06 \n",
            "Epoch 9892/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2013e-06 \n",
            "Epoch 9893/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0993e-06 \n",
            "Epoch 9894/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3049e-06 \n",
            "Epoch 9895/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3512e-06 \n",
            "Epoch 9896/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3024e-06 \n",
            "Epoch 9897/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3641e-06 \n",
            "Epoch 9898/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1808e-06 \n",
            "Epoch 9899/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1284e-06 \n",
            "Epoch 9900/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.9546e-07\n",
            "Test accuracy at epoch 9900: 33.92%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.2111e-06\n",
            "Epoch 9901/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3069e-06 \n",
            "Epoch 9902/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1113e-06 \n",
            "Epoch 9903/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1936e-06 \n",
            "Epoch 9904/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1287e-06 \n",
            "Epoch 9905/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3364e-06 \n",
            "Epoch 9906/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1287e-06 \n",
            "Epoch 9907/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1813e-06 \n",
            "Epoch 9908/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2752e-06 \n",
            "Epoch 9909/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0546e-06 \n",
            "Epoch 9910/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0459e-06 \n",
            "Epoch 9911/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2435e-06 \n",
            "Epoch 9912/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1967e-06 \n",
            "Epoch 9913/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0993e-06 \n",
            "Epoch 9914/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1256e-06 \n",
            "Epoch 9915/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0706e-06 \n",
            "Epoch 9916/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0801e-06 \n",
            "Epoch 9917/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1536e-06 \n",
            "Epoch 9918/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0645e-06 \n",
            "Epoch 9919/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0587e-06 \n",
            "Epoch 9920/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0846e-06 \n",
            "Epoch 9921/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0967e-06 \n",
            "Epoch 9922/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1196e-06 \n",
            "Epoch 9923/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1872e-06 \n",
            "Epoch 9924/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0945e-06 \n",
            "Epoch 9925/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1711e-06 \n",
            "Epoch 9926/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2261e-06 \n",
            "Epoch 9927/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6664e-07 \n",
            "Epoch 9928/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0063e-06 \n",
            "Epoch 9929/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7612e-07 \n",
            "Epoch 9930/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0589e-06 \n",
            "Epoch 9931/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2040e-06 \n",
            "Epoch 9932/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0671e-06 \n",
            "Epoch 9933/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0879e-06 \n",
            "Epoch 9934/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0709e-06 \n",
            "Epoch 9935/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0526e-06 \n",
            "Epoch 9936/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0826e-06 \n",
            "Epoch 9937/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1403e-06 \n",
            "Epoch 9938/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0727e-06 \n",
            "Epoch 9939/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0871e-06 \n",
            "Epoch 9940/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0046e-06 \n",
            "Epoch 9941/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0768e-06 \n",
            "Epoch 9942/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1334e-06 \n",
            "Epoch 9943/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8770e-07 \n",
            "Epoch 9944/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1836e-06 \n",
            "Epoch 9945/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0825e-06 \n",
            "Epoch 9946/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1332e-06 \n",
            "Epoch 9947/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0692e-06 \n",
            "Epoch 9948/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4318e-07 \n",
            "Epoch 9949/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0206e-06 \n",
            "Epoch 9950/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9281e-07 \n",
            "Epoch 9951/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4749e-07 \n",
            "Epoch 9952/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6864e-07 \n",
            "Epoch 9953/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4891e-07 \n",
            "Epoch 9954/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0355e-06 \n",
            "Epoch 9955/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1007e-06 \n",
            "Epoch 9956/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0278e-06 \n",
            "Epoch 9957/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0458e-06 \n",
            "Epoch 9958/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0120e-06 \n",
            "Epoch 9959/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2983e-07 \n",
            "Epoch 9960/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1024e-06 \n",
            "Epoch 9961/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1060e-07 \n",
            "Epoch 9962/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0759e-06 \n",
            "Epoch 9963/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0386e-06 \n",
            "Epoch 9964/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0907e-06 \n",
            "Epoch 9965/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6415e-07 \n",
            "Epoch 9966/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0333e-06 \n",
            "Epoch 9967/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8097e-07 \n",
            "Epoch 9968/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2112e-07 \n",
            "Epoch 9969/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9351e-07 \n",
            "Epoch 9970/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0813e-06 \n",
            "Epoch 9971/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0338e-06 \n",
            "Epoch 9972/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9052e-07 \n",
            "Epoch 9973/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9552e-07 \n",
            "Epoch 9974/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0529e-06 \n",
            "Epoch 9975/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6841e-07 \n",
            "Epoch 9976/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5192e-07 \n",
            "Epoch 9977/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5502e-07 \n",
            "Epoch 9978/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9930e-07 \n",
            "Epoch 9979/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7957e-07 \n",
            "Epoch 9980/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3651e-07 \n",
            "Epoch 9981/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8979e-07 \n",
            "Epoch 9982/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0153e-06 \n",
            "Epoch 9983/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1070e-07 \n",
            "Epoch 9984/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7784e-07 \n",
            "Epoch 9985/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6254e-07 \n",
            "Epoch 9986/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7891e-07 \n",
            "Epoch 9987/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1501e-07 \n",
            "Epoch 9988/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4184e-07 \n",
            "Epoch 9989/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3505e-07 \n",
            "Epoch 9990/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9880e-07 \n",
            "Epoch 9991/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0498e-07 \n",
            "Epoch 9992/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2595e-07 \n",
            "Epoch 9993/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3777e-07 \n",
            "Epoch 9994/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5597e-07 \n",
            "Epoch 9995/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0380e-07 \n",
            "Epoch 9996/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1176e-07 \n",
            "Epoch 9997/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3708e-07 \n",
            "Epoch 9998/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7527e-07 \n",
            "Epoch 9999/10000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0144e-07 \n",
            "Epoch 10000/10000\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.3074e-07\n",
            "Test accuracy at epoch 10000: 33.84%\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 8.5149e-07\n"
          ]
        }
      ],
      "source": [
        "Train_complete_model=model_transfer_learning.fit(X_train_label, y_train_label, epochs=10000,callbacks=[pretrained(test_data)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcxBJpUaI9_h",
        "outputId": "3b30110b-3da4-4dc3-d023-dc5457c29019"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model_transfer_learning.save('new_model_transfer_learning.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "QKukNloKzN-f",
        "outputId": "8c9e0c88-4d4f-4380-8e3e-a7436631d066"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Replace these with your actual arrays\n",
        "array1=pretrained.test_acc_2\n",
        "array2=baseline.test_acc\n",
        "\n",
        "# Plot both arrays\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(array1, label='Pre_Trained', marker='o')\n",
        "plt.plot(array2, label='Base line', marker='s')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epochs per 100')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of test Accuracy at every 100th Epoch')\n",
        "\n",
        "# Add grid and legend\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvhnWslNDQCH"
      },
      "source": [
        "So, ulimately the transfer learning model is performing better that the base line model. Using the weights of the pre text model effects the models featuer understanding ability postively. Hence results in better classfication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ajH_RSA0PBZ"
      },
      "source": [
        "Other method to execute Transfer learning using custom traning function. (Just a try)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DC-Zlnvf7rBJ"
      },
      "outputs": [],
      "source": [
        "model_transfer_learning_cust = models.Sequential([\n",
        "    layers.Conv2D(10, (5,5), strides=1,activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Conv2D(10,(5,5),strides=1,activation='relu'),\n",
        "    layers.MaxPooling2D((2,2),strides=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(20, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax',kernel_initializer=tf.keras.initializers.HeNormal())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARwDRBb47yh0"
      },
      "outputs": [],
      "source": [
        "for layer_new, layer_pretext in zip(model_transfer_learning_cust.layers[:-1], pretext_model.layers[:-1]):\n",
        "    if layer_new.trainable and len(layer_new.get_weights()) > 0:\n",
        "        layer_new.set_weights(layer_pretext.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-pBij4r0V63"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq5Cg6lK6i9d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Plr0qhC6GwN"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# Metrics to track training and test accuracy\n",
        "train_accuracy_metric = SparseCategoricalAccuracy()\n",
        "test_accuracy_metric = SparseCategoricalAccuracy()\n",
        "\n",
        "optimizer_slow = tf.keras.optimizers.Adam(learning_rate=0.00001)  # For initial layers\n",
        "optimizer_fast = tf.keras.optimizers.Adam(learning_rate=0.001)    # For the last layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yONHOgdlFhUI"
      },
      "outputs": [],
      "source": [
        "# Define batch size\n",
        "batch_size = 50  # Manually set the batch size\n",
        "num_batches = 500// batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTXiP5lF6Psr"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        predictions = model_transfer_learning_cust(images, training=True)\n",
        "        loss = loss_fn(labels, predictions)\n",
        "\n",
        "    # Get the trainable variables for different parts of the model\n",
        "    slow_layers = model_transfer_learning_cust.layers[:-1]  # All layers except the last one\n",
        "    fast_layers = [model_transfer_learning_cust.layers[-1]]  # Last layer\n",
        "\n",
        "    slow_trainable_vars = []\n",
        "    for layer in slow_layers:\n",
        "        slow_trainable_vars.extend(layer.trainable_variables)\n",
        "\n",
        "    fast_trainable_vars = fast_layers[0].trainable_variables\n",
        "\n",
        "    # Compute gradients\n",
        "    slow_gradients = tape.gradient(loss, slow_trainable_vars)\n",
        "    fast_gradients = tape.gradient(loss, fast_trainable_vars)\n",
        "\n",
        "    # Apply gradients to different optimizers\n",
        "    optimizer_slow.apply_gradients(zip(slow_gradients, slow_trainable_vars))\n",
        "    optimizer_fast.apply_gradients(zip(fast_gradients, fast_trainable_vars))\n",
        "\n",
        "    # Update the training accuracy\n",
        "    train_accuracy_metric.update_state(labels, predictions)\n",
        "\n",
        "    # Clean up the tape\n",
        "    del tape\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEejoyCr6Ut0"
      },
      "outputs": [],
      "source": [
        "# Test step to calculate accuracy on test data\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    predictions = model_transfer_learning_cust(images, training=False)\n",
        "    test_accuracy_metric.update_state(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWNuuoYIFuHm"
      },
      "outputs": [],
      "source": [
        "train_data = X_train_label\n",
        "train_labels = y_train_label\n",
        "test_data = X_test_org\n",
        "test_labels = y_test_org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td2m0u046M2h",
        "outputId": "d1580b87-1702-4bde-b526-fed719b6299f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 5051/10000, Loss: 0.013891147449612617, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5052/10000, Loss: 0.013993852771818638, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5053/10000, Loss: 0.013884883373975754, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5054/10000, Loss: 2.932544873601728e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5055/10000, Loss: 0.013919132761657238, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5056/10000, Loss: 0.013896758668124676, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5057/10000, Loss: 0.013891726732254028, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5058/10000, Loss: 1.0394926448498154e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5059/10000, Loss: 8.249205620813882e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5060/10000, Loss: 4.408238055475522e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5061/10000, Loss: 8.985702879726887e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5062/10000, Loss: 0.05552287772297859, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5063/10000, Loss: 0.013894109055399895, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5064/10000, Loss: 0.013872187584638596, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5065/10000, Loss: 0.027803443372249603, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5066/10000, Loss: 1.1610890169322374e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5067/10000, Loss: 9.230558134731837e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5068/10000, Loss: 3.274601840530522e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5069/10000, Loss: 0.013890420086681843, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5070/10000, Loss: 0.013909787870943546, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5071/10000, Loss: 0.027760246768593788, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5072/10000, Loss: 4.486897978495108e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5073/10000, Loss: 0.027759943157434464, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5074/10000, Loss: 3.163762085023336e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5075/10000, Loss: 2.2411309430481197e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5076/10000, Loss: 0.013894883915781975, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5077/10000, Loss: 0.027779506519436836, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5078/10000, Loss: 0.01390064600855112, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5079/10000, Loss: 1.3518252899302752e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5080/10000, Loss: 0.01401497796177864, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5081/10000, Loss: 3.24954885400075e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5082/10000, Loss: 0.027841145172715187, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5083/10000, Loss: 7.454621936631156e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5084/10000, Loss: 0.013899886049330235, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5085/10000, Loss: 0.013870197348296642, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5086/10000, Loss: 2.584391040727496e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5087/10000, Loss: 6.882417437736876e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5088/10000, Loss: 0.013977219350636005, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5089/10000, Loss: 0.04164593666791916, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5090/10000, Loss: 4.935253627991187e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5091/10000, Loss: 0.01389638427644968, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5092/10000, Loss: 0.02776142582297325, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5093/10000, Loss: 0.027764078229665756, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5094/10000, Loss: 0.013879598118364811, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5095/10000, Loss: 2.2339256702252897e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5096/10000, Loss: 4.1007899653777713e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5097/10000, Loss: 0.013888122513890266, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5098/10000, Loss: 0.013897144235670567, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5099/10000, Loss: 0.02787993662059307, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5100/10000, Loss: 1.9359024463483365e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 5100: 0.3230090027570726\n",
            "Epoch 5101/10000, Loss: 8.559143793718249e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5102/10000, Loss: 7.426002866850467e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5103/10000, Loss: 7.867784006521106e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5104/10000, Loss: 2.9488270229194313e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5105/10000, Loss: 0.013884597457945347, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5106/10000, Loss: 0.02776513062417507, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5107/10000, Loss: 0.01389069203287363, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5108/10000, Loss: 0.01388057041913271, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5109/10000, Loss: 2.981270881718956e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5110/10000, Loss: 0.013912280090153217, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5111/10000, Loss: 0.041640471667051315, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5112/10000, Loss: 8.107860594464e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5113/10000, Loss: 6.23392270426848e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5114/10000, Loss: 8.650020754430443e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5115/10000, Loss: 0.02781795524060726, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5116/10000, Loss: 0.027761399745941162, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5117/10000, Loss: 1.3923485084887943e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5118/10000, Loss: 1.2516844662968651e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5119/10000, Loss: 7.535711574746529e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5120/10000, Loss: 3.668991666927468e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5121/10000, Loss: 3.2066559469967615e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5122/10000, Loss: 0.013894099742174149, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5123/10000, Loss: 0.027843045070767403, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5124/10000, Loss: 2.3078603135218145e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5125/10000, Loss: 0.013883762992918491, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5126/10000, Loss: 0.013905134052038193, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5127/10000, Loss: 0.013897751457989216, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5128/10000, Loss: 0.01388294342905283, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5129/10000, Loss: 8.061531116254628e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5130/10000, Loss: 1.026296831696527e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5131/10000, Loss: 4.963589617545949e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5132/10000, Loss: 6.958760423003696e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5133/10000, Loss: 0.013904673978686333, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5134/10000, Loss: 0.013916661031544209, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5135/10000, Loss: 0.013902511447668076, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5136/10000, Loss: 1.2755252782881144e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5137/10000, Loss: 0.013964825309813023, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5138/10000, Loss: 0.013903756625950336, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5139/10000, Loss: 4.064912900503259e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5140/10000, Loss: 1.1682433296300587e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5141/10000, Loss: 0.013889921829104424, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5142/10000, Loss: 7.805099812685512e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5143/10000, Loss: 0.027762047946453094, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5144/10000, Loss: 4.587068360706326e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5145/10000, Loss: 3.0826852253085235e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5146/10000, Loss: 0.013899344019591808, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5147/10000, Loss: 0.013858838006854057, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5148/10000, Loss: 7.959274080349132e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5149/10000, Loss: 8.058484581852099e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5150/10000, Loss: 0.013885779306292534, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5151/10000, Loss: 2.262562020405312e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5152/10000, Loss: 0.013873838819563389, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5153/10000, Loss: 0.013883009552955627, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5154/10000, Loss: 3.229869980714284e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5155/10000, Loss: 0.013917848467826843, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5156/10000, Loss: 0.027758607640862465, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5157/10000, Loss: 1.471031509936438e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5158/10000, Loss: 0.02775854989886284, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5159/10000, Loss: 6.079637273614935e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5160/10000, Loss: 0.04165326803922653, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5161/10000, Loss: 0.01388630736619234, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5162/10000, Loss: 7.896245369920507e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5163/10000, Loss: 7.822975021554157e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5164/10000, Loss: 3.943351202906342e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5165/10000, Loss: 6.461119141931704e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5166/10000, Loss: 3.5046734865318285e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5167/10000, Loss: 0.013888114131987095, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5168/10000, Loss: 0.013889570720493793, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5169/10000, Loss: 0.027783891186118126, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5170/10000, Loss: 0.01388213038444519, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5171/10000, Loss: 1.664145656832261e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5172/10000, Loss: 5.471420990943443e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5173/10000, Loss: 5.269039888844418e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5174/10000, Loss: 0.013960016891360283, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5175/10000, Loss: 7.769861986162141e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5176/10000, Loss: 0.013970963656902313, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5177/10000, Loss: 1.3375162097872817e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5178/10000, Loss: 7.874628499848768e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5179/10000, Loss: 2.721411146922037e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5180/10000, Loss: 0.02775724045932293, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5181/10000, Loss: 0.013874645344913006, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5182/10000, Loss: 4.186380010651192e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5183/10000, Loss: 4.1530006456014235e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5184/10000, Loss: 1.537780576654768e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5185/10000, Loss: 5.080421942693647e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5186/10000, Loss: 2.8311071218922734e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5187/10000, Loss: 0.014016016386449337, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5188/10000, Loss: 2.7513090117281536e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5189/10000, Loss: 0.013907650485634804, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5190/10000, Loss: 7.731618825346231e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5191/10000, Loss: 0.013879215344786644, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5192/10000, Loss: 2.8628433938138187e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5193/10000, Loss: 0.027763737365603447, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5194/10000, Loss: 6.055808512428484e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5195/10000, Loss: 0.013904642313718796, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5196/10000, Loss: 7.691272185184062e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5197/10000, Loss: 0.013892099261283875, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5198/10000, Loss: 1.3613561122838291e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5199/10000, Loss: 0.013900281861424446, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5200/10000, Loss: 0.013895319774746895, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 5200: 0.32396800270080583\n",
            "Epoch 5201/10000, Loss: 1.5163249145189184e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5202/10000, Loss: 0.01388968899846077, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5203/10000, Loss: 1.7142100432465668e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5204/10000, Loss: 0.02775626629590988, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5205/10000, Loss: 0.013885295018553734, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5206/10000, Loss: 0.013904173858463764, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5207/10000, Loss: 2.9320035537239164e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5208/10000, Loss: 0.027802281081676483, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5209/10000, Loss: 0.0138712078332901, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5210/10000, Loss: 4.024287136417115e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5211/10000, Loss: 2.8667065635090694e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5212/10000, Loss: 1.707031401565473e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5213/10000, Loss: 0.013950345106422901, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5214/10000, Loss: 0.027782142162322998, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5215/10000, Loss: 1.1157857215948752e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5216/10000, Loss: 2.043224867520621e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5217/10000, Loss: 0.013903950341045856, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5218/10000, Loss: 2.8514216410258086e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5219/10000, Loss: 2.717242568905931e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5220/10000, Loss: 4.060157607455039e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5221/10000, Loss: 0.027757350355386734, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5222/10000, Loss: 0.013880143873393536, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5223/10000, Loss: 4.4822618860962393e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5224/10000, Loss: 0.013906599953770638, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5225/10000, Loss: 9.295057679992169e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5226/10000, Loss: 0.013892673887312412, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5227/10000, Loss: 0.013895024545490742, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5228/10000, Loss: 0.013902796432375908, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5229/10000, Loss: 1.3804307172904373e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5230/10000, Loss: 0.013878454454243183, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5231/10000, Loss: 0.01387121994048357, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5232/10000, Loss: 0.013889850117266178, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5233/10000, Loss: 0.013863313011825085, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5234/10000, Loss: 4.210250608593924e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5235/10000, Loss: 0.013889309018850327, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5236/10000, Loss: 0.013876362703740597, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5237/10000, Loss: 7.431957055814564e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5238/10000, Loss: 6.389537929862854e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5239/10000, Loss: 0.013889428228139877, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5240/10000, Loss: 0.013961068354547024, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5241/10000, Loss: 1.039500148181105e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5242/10000, Loss: 2.2673052626487333e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5243/10000, Loss: 3.170891659465269e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5244/10000, Loss: 2.412739831925137e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5245/10000, Loss: 0.013898881152272224, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5246/10000, Loss: 0.027819352224469185, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5247/10000, Loss: 2.8463207854656503e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5248/10000, Loss: 7.869672845117748e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5249/10000, Loss: 0.01388369407504797, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5250/10000, Loss: 1.9239898847445147e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5251/10000, Loss: 0.013893558643758297, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5252/10000, Loss: 1.006113734547398e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5253/10000, Loss: 0.013896250165998936, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5254/10000, Loss: 0.013872789219021797, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5255/10000, Loss: 6.508793717330263e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5256/10000, Loss: 4.115007413929561e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5257/10000, Loss: 2.8180577373859705e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5258/10000, Loss: 0.013878194615244865, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5259/10000, Loss: 2.6058742150780745e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5260/10000, Loss: 1.7761935851012822e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5261/10000, Loss: 1.635517264730879e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5262/10000, Loss: 0.013893184252083302, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5263/10000, Loss: 0.013946318067610264, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5264/10000, Loss: 7.921980795799755e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5265/10000, Loss: 9.751228162713232e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5266/10000, Loss: 0.013912482187151909, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5267/10000, Loss: 3.418731921556173e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5268/10000, Loss: 2.1171360913285753e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5269/10000, Loss: 0.01389916893094778, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5270/10000, Loss: 1.4757850976820919e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5271/10000, Loss: 0.013966607861220837, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5272/10000, Loss: 0.013875509612262249, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5273/10000, Loss: 2.0503632640611613e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5274/10000, Loss: 3.0040681053833396e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5275/10000, Loss: 7.233897486003116e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5276/10000, Loss: 0.0138936135917902, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5277/10000, Loss: 0.02777358889579773, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5278/10000, Loss: 7.147411088226363e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5279/10000, Loss: 1.3303459809321794e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5280/10000, Loss: 0.01390047837048769, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5281/10000, Loss: 6.324649348243838e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5282/10000, Loss: 0.027755476534366608, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5283/10000, Loss: 0.013894181698560715, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5284/10000, Loss: 0.027785519137978554, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5285/10000, Loss: 2.3435936782334466e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5286/10000, Loss: 0.013863501138985157, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5287/10000, Loss: 0.02778659202158451, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5288/10000, Loss: 0.0001925414544530213, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5289/10000, Loss: 4.451268614502624e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5290/10000, Loss: 4.749123763758689e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5291/10000, Loss: 1.0310515790479258e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5292/10000, Loss: 0.013948013074696064, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5293/10000, Loss: 0.01388400886207819, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5294/10000, Loss: 0.013882068917155266, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5295/10000, Loss: 9.775060334504815e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5296/10000, Loss: 2.9015145628363825e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5297/10000, Loss: 2.599569234007504e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5298/10000, Loss: 2.52719974014326e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5299/10000, Loss: 0.013906854204833508, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5300/10000, Loss: 0.013894030824303627, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 5300: 0.32492700264453905\n",
            "Epoch 5301/10000, Loss: 1.0429412213852629e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5302/10000, Loss: 7.212410855572671e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5303/10000, Loss: 0.013896482065320015, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5304/10000, Loss: 0.02775820717215538, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5305/10000, Loss: 7.853231363696977e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5306/10000, Loss: 0.01390349492430687, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5307/10000, Loss: 4.682394774135901e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5308/10000, Loss: 0.013908574357628822, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5309/10000, Loss: 0.027797533199191093, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5310/10000, Loss: 1.7118181858677417e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5311/10000, Loss: 7.165694114519283e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5312/10000, Loss: 0.013949242420494556, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5313/10000, Loss: 7.976351298566442e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5314/10000, Loss: 3.5070834201178513e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5315/10000, Loss: 4.563212314678822e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5316/10000, Loss: 0.013964418321847916, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5317/10000, Loss: 0.013895343989133835, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5318/10000, Loss: 7.105244731064886e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5319/10000, Loss: 7.104035466909409e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5320/10000, Loss: 7.049701525829732e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5321/10000, Loss: 2.2983319922786904e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5322/10000, Loss: 6.172488156153122e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5323/10000, Loss: 0.027823304757475853, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5324/10000, Loss: 3.3544090456416598e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5325/10000, Loss: 9.059860417437449e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5326/10000, Loss: 7.28782542864792e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5327/10000, Loss: 3.4045413030980853e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5328/10000, Loss: 0.041713688522577286, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5329/10000, Loss: 2.7937718186876737e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5330/10000, Loss: 2.233928398709395e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5331/10000, Loss: 0.013892976567149162, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5332/10000, Loss: 0.01387544721364975, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5333/10000, Loss: 0.013881217688322067, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5334/10000, Loss: 2.3149852950155037e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5335/10000, Loss: 1.3685054227607907e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5336/10000, Loss: 5.745877160734381e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5337/10000, Loss: 7.037167051748838e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5338/10000, Loss: 1.358970848741592e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5339/10000, Loss: 0.013896848075091839, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5340/10000, Loss: 7.66370867495425e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5341/10000, Loss: 0.027754172682762146, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5342/10000, Loss: 5.5669097491772845e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5343/10000, Loss: 0.013885077089071274, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5344/10000, Loss: 0.01389940083026886, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5345/10000, Loss: 2.6514175260672346e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5346/10000, Loss: 0.01389152742922306, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5347/10000, Loss: 2.9215374524937943e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5348/10000, Loss: 6.987161214055959e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5349/10000, Loss: 0.013888223096728325, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5350/10000, Loss: 0.013880658894777298, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5351/10000, Loss: 0.013889207504689693, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5352/10000, Loss: 2.8216423743288033e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5353/10000, Loss: 7.328122137550963e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5354/10000, Loss: 7.430634013871895e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5355/10000, Loss: 9.918093155647512e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5356/10000, Loss: 7.2804491537681315e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5357/10000, Loss: 3.094607336606714e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5358/10000, Loss: 4.937440280627925e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5359/10000, Loss: 0.02775396965444088, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5360/10000, Loss: 0.013887705281376839, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5361/10000, Loss: 2.8418769488780526e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5362/10000, Loss: 0.013857868500053883, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5363/10000, Loss: 2.2029619231034303e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5364/10000, Loss: 2.936303280876018e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5365/10000, Loss: 2.97301903628977e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5366/10000, Loss: 6.74834955134429e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5367/10000, Loss: 0.013878082856535912, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5368/10000, Loss: 0.027752893045544624, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5369/10000, Loss: 0.013957480899989605, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5370/10000, Loss: 4.381955477583688e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5371/10000, Loss: 1.7595151575733325e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5372/10000, Loss: 2.6177920062764315e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5373/10000, Loss: 7.666718374821357e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5374/10000, Loss: 3.0111646083241794e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5375/10000, Loss: 8.916773026612645e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5376/10000, Loss: 1.8000114323513117e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5377/10000, Loss: 0.013885503634810448, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5378/10000, Loss: 0.013890613801777363, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5379/10000, Loss: 0.013952959328889847, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5380/10000, Loss: 0.02775336056947708, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5381/10000, Loss: 0.013877585530281067, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5382/10000, Loss: 0.01387509424239397, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5383/10000, Loss: 2.8368936909828335e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5384/10000, Loss: 6.294221748248674e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5385/10000, Loss: 8.511465807714558e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5386/10000, Loss: 0.013885158114135265, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5387/10000, Loss: 2.3173743102233857e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5388/10000, Loss: 6.787526945117861e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5389/10000, Loss: 2.648774852787028e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5390/10000, Loss: 0.027819277718663216, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5391/10000, Loss: 0.027766210958361626, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5392/10000, Loss: 0.013943472877144814, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5393/10000, Loss: 0.027820458635687828, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5394/10000, Loss: 0.01391146145761013, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5395/10000, Loss: 0.013874160125851631, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5396/10000, Loss: 0.027809910476207733, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5397/10000, Loss: 6.43727958049567e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5398/10000, Loss: 4.322434961068211e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5399/10000, Loss: 2.8133365503890673e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5400/10000, Loss: 2.4675750864844304e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 5400: 0.32588600258827227\n",
            "Epoch 5401/10000, Loss: 2.8326010578894056e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5402/10000, Loss: 0.013908294960856438, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5403/10000, Loss: 0.02775884047150612, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5404/10000, Loss: 0.01391648966819048, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5405/10000, Loss: 0.013903498649597168, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5406/10000, Loss: 0.013948837295174599, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5407/10000, Loss: 0.013888377696275711, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5408/10000, Loss: 4.5726696953352075e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5409/10000, Loss: 0.013904697261750698, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5410/10000, Loss: 2.300700316482107e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5411/10000, Loss: 0.013882702216506004, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5412/10000, Loss: 0.01388982031494379, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5413/10000, Loss: 0.027753202244639397, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5414/10000, Loss: 0.013915407471358776, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5415/10000, Loss: 3.204262611689046e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5416/10000, Loss: 0.02775319293141365, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5417/10000, Loss: 0.027776185423135757, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5418/10000, Loss: 0.013960747048258781, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5419/10000, Loss: 5.867230811418267e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5420/10000, Loss: 0.027753381058573723, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5421/10000, Loss: 0.013898031786084175, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5422/10000, Loss: 2.920821680163499e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5423/10000, Loss: 0.013891596347093582, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5424/10000, Loss: 0.027753621339797974, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5425/10000, Loss: 0.013886979781091213, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5426/10000, Loss: 0.013900532387197018, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5427/10000, Loss: 0.02776397205889225, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5428/10000, Loss: 6.587938696611673e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5429/10000, Loss: 0.02775178663432598, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5430/10000, Loss: 1.2945999969815603e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5431/10000, Loss: 0.013875404372811317, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5432/10000, Loss: 2.3650602543057175e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5433/10000, Loss: 0.013965262100100517, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5434/10000, Loss: 1.8000347381530446e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5435/10000, Loss: 2.2005508526490303e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5436/10000, Loss: 0.013877741061151028, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5437/10000, Loss: 0.013892446644604206, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5438/10000, Loss: 1.0871822269109543e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5439/10000, Loss: 7.79313086241018e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5440/10000, Loss: 0.027806855738162994, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5441/10000, Loss: 0.013867182657122612, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5442/10000, Loss: 2.2911538053449476e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5443/10000, Loss: 0.013876744545996189, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5444/10000, Loss: 0.01395320612937212, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5445/10000, Loss: 2.0122067780903308e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5446/10000, Loss: 0.013911964371800423, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5447/10000, Loss: 0.01397342886775732, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5448/10000, Loss: 0.027766255661845207, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5449/10000, Loss: 0.01390241552144289, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5450/10000, Loss: 3.0922449241188588e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5451/10000, Loss: 6.794887212890899e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5452/10000, Loss: 0.013894673436880112, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5453/10000, Loss: 0.013954119756817818, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5454/10000, Loss: 0.0138936135917902, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5455/10000, Loss: 6.937947887308837e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5456/10000, Loss: 7.411676961055491e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5457/10000, Loss: 0.01395140029489994, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5458/10000, Loss: 0.027751414105296135, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5459/10000, Loss: 1.8620102082422818e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5460/10000, Loss: 2.8753156584571116e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5461/10000, Loss: 5.412092605183716e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5462/10000, Loss: 2.479551426404214e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5463/10000, Loss: 1.8310358882445144e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5464/10000, Loss: 2.7155288080393802e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5465/10000, Loss: 0.013881504535675049, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5466/10000, Loss: 0.02775265835225582, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5467/10000, Loss: 0.0138936135917902, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5468/10000, Loss: 1.7213678802363575e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5469/10000, Loss: 2.865727992684697e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5470/10000, Loss: 0.013901054859161377, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5471/10000, Loss: 4.146013907302404e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5472/10000, Loss: 8.034627398956218e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5473/10000, Loss: 0.013876503333449364, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5474/10000, Loss: 0.013890867121517658, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5475/10000, Loss: 6.198127266543452e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5476/10000, Loss: 1.974086671907571e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5477/10000, Loss: 4.0744762372924015e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5478/10000, Loss: 0.027755333110690117, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5479/10000, Loss: 5.583509846474044e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5480/10000, Loss: 0.0138776283711195, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5481/10000, Loss: 0.013884102925658226, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5482/10000, Loss: 3.2696192647563294e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5483/10000, Loss: 5.428581516753184e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5484/10000, Loss: 0.02779262885451317, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5485/10000, Loss: 3.392627377252211e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5486/10000, Loss: 0.01388920471072197, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5487/10000, Loss: 2.9745278880000114e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5488/10000, Loss: 1.7452035763199092e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5489/10000, Loss: 1.2874523918071645e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5490/10000, Loss: 1.5473184475922608e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5491/10000, Loss: 3.7908446870460466e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5492/10000, Loss: 4.813454324903432e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5493/10000, Loss: 0.013902490958571434, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5494/10000, Loss: 1.1610776482484653e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5495/10000, Loss: 1.652231162552198e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5496/10000, Loss: 8.49405478220433e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5497/10000, Loss: 0.013894299045205116, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5498/10000, Loss: 2.582131310191471e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5499/10000, Loss: 7.67152141634142e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5500/10000, Loss: 0.013919681310653687, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 5500: 0.3268450025320055\n",
            "Epoch 5501/10000, Loss: 1.940679567269399e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5502/10000, Loss: 4.415323019202333e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5503/10000, Loss: 5.364390176509914e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5504/10000, Loss: 0.027773549780249596, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5505/10000, Loss: 0.013901695609092712, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5506/10000, Loss: 7.963133157318225e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5507/10000, Loss: 0.013885370455682278, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5508/10000, Loss: 0.01394862961024046, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5509/10000, Loss: 0.013898343779146671, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5510/10000, Loss: 0.013867966830730438, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5511/10000, Loss: 0.013888273388147354, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5512/10000, Loss: 2.764774217212107e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5513/10000, Loss: 0.027775458991527557, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5514/10000, Loss: 0.013934757560491562, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5515/10000, Loss: 0.027751261368393898, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5516/10000, Loss: 0.013890859670937061, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5517/10000, Loss: 1.4281147286965279e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5518/10000, Loss: 9.065001358976588e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5519/10000, Loss: 1.0681040976123768e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5520/10000, Loss: 0.013956828974187374, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5521/10000, Loss: 0.013899354264140129, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5522/10000, Loss: 6.277591455727816e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5523/10000, Loss: 9.383315045852214e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5524/10000, Loss: 2.0932857296429574e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5525/10000, Loss: 0.01387453731149435, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5526/10000, Loss: 1.0967162324959645e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5527/10000, Loss: 4.4225662350072525e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5528/10000, Loss: 1.5973826066328911e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5529/10000, Loss: 0.013878108002245426, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5530/10000, Loss: 0.013861230574548244, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5531/10000, Loss: 0.013948391191661358, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5532/10000, Loss: 1.1539337947397144e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5533/10000, Loss: 2.4771270545898005e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5534/10000, Loss: 6.667785328318132e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5535/10000, Loss: 6.556470566465578e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5536/10000, Loss: 0.013882705941796303, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5537/10000, Loss: 7.352054126386065e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5538/10000, Loss: 0.027812737971544266, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5539/10000, Loss: 0.013889312744140625, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5540/10000, Loss: 0.013900388032197952, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5541/10000, Loss: 6.438917807827238e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5542/10000, Loss: 0.027794096618890762, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5543/10000, Loss: 2.19103480958438e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5544/10000, Loss: 0.013897547498345375, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5545/10000, Loss: 3.380683438081178e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5546/10000, Loss: 2.8442736947908998e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5547/10000, Loss: 1.7666468465904472e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5548/10000, Loss: 0.013883305713534355, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5549/10000, Loss: 7.74856744101271e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5550/10000, Loss: 1.9788716087987268e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5551/10000, Loss: 0.013885154388844967, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5552/10000, Loss: 0.027811190113425255, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5553/10000, Loss: 0.04172751307487488, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5554/10000, Loss: 0.027751591056585312, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5555/10000, Loss: 0.013954266905784607, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5556/10000, Loss: 1.8453409893481876e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5557/10000, Loss: 0.027750417590141296, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5558/10000, Loss: 9.111494364333339e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5559/10000, Loss: 0.013886947184801102, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5560/10000, Loss: 0.013884153217077255, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5561/10000, Loss: 6.9324310061347205e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5562/10000, Loss: 2.338848162253271e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5563/10000, Loss: 2.8466770345403347e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5564/10000, Loss: 6.461115731326572e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5565/10000, Loss: 2.6478044674149714e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5566/10000, Loss: 6.81368401274085e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5567/10000, Loss: 0.0277703907340765, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5568/10000, Loss: 4.200756848149467e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5569/10000, Loss: 0.013904117979109287, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5570/10000, Loss: 0.013950379565358162, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5571/10000, Loss: 2.3174013676907634e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5572/10000, Loss: 2.5486399408691796e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5573/10000, Loss: 1.62838080086658e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5574/10000, Loss: 1.6784388208179735e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5575/10000, Loss: 3.6000378713652026e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5576/10000, Loss: 0.01390031073242426, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5577/10000, Loss: 0.02775503136217594, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5578/10000, Loss: 0.013876118697226048, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5579/10000, Loss: 0.013887395150959492, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5580/10000, Loss: 2.5887055016937666e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5581/10000, Loss: 2.3150000743044075e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5582/10000, Loss: 0.013902481645345688, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5583/10000, Loss: 0.013902030885219574, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5584/10000, Loss: 3.0080123906373046e-05, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5585/10000, Loss: 0.013889445923268795, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5586/10000, Loss: 2.002687324420549e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5587/10000, Loss: 0.013869239017367363, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5588/10000, Loss: 0.013940940611064434, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5589/10000, Loss: 0.01388673298060894, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5590/10000, Loss: 2.7131445676786825e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5591/10000, Loss: 5.797550784336636e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5592/10000, Loss: 1.4090423974266741e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5593/10000, Loss: 0.013867084868252277, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5594/10000, Loss: 0.01391396950930357, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5595/10000, Loss: 0.013893346302211285, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5596/10000, Loss: 3.2877032936085016e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5597/10000, Loss: 0.013892251066863537, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5598/10000, Loss: 1.888221277113189e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5599/10000, Loss: 0.027760371565818787, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5600/10000, Loss: 1.060952854459174e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 5600: 0.3278040024757387\n",
            "Epoch 5601/10000, Loss: 2.4961907456599874e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5602/10000, Loss: 0.013920605182647705, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5603/10000, Loss: 0.027812322601675987, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5604/10000, Loss: 0.013883349485695362, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5605/10000, Loss: 1.6116638335006428e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5606/10000, Loss: 0.027749724686145782, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5607/10000, Loss: 1.094334379558859e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5608/10000, Loss: 0.013881604187190533, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5609/10000, Loss: 1.4876856084811152e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5610/10000, Loss: 3.225734417355852e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5611/10000, Loss: 0.013882407918572426, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5612/10000, Loss: 2.3936922843859065e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5613/10000, Loss: 0.013891634531319141, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5614/10000, Loss: 1.3064981203569914e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5615/10000, Loss: 0.013885371387004852, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5616/10000, Loss: 2.3102395516616525e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5617/10000, Loss: 0.027752280235290527, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5618/10000, Loss: 0.013894827105104923, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5619/10000, Loss: 0.013885676860809326, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5620/10000, Loss: 0.02777264267206192, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5621/10000, Loss: 6.461061161644466e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5622/10000, Loss: 2.4055900667008245e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5623/10000, Loss: 5.857309588463977e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5624/10000, Loss: 0.013878794386982918, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5625/10000, Loss: 9.632036608309136e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5626/10000, Loss: 4.029187039122917e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5627/10000, Loss: 0.027749642729759216, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5628/10000, Loss: 0.013965340331196785, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5629/10000, Loss: 2.1219229040525533e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5630/10000, Loss: 0.027772659435868263, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5631/10000, Loss: 3.027912498509977e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5632/10000, Loss: 1.4185800409904914e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5633/10000, Loss: 0.013882498256862164, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5634/10000, Loss: 0.013926809653639793, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5635/10000, Loss: 2.279250111314468e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5636/10000, Loss: 4.4345767946651904e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5637/10000, Loss: 2.4485284484399017e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5638/10000, Loss: 0.013893770053982735, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5639/10000, Loss: 2.5370893126819283e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5640/10000, Loss: 0.013883447274565697, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5641/10000, Loss: 0.013894017785787582, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5642/10000, Loss: 0.013886002823710442, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5643/10000, Loss: 0.013893824070692062, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5644/10000, Loss: 0.013889586552977562, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5645/10000, Loss: 1.609289029147476e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5646/10000, Loss: 0.013887022621929646, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5647/10000, Loss: 1.0501381439098623e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5648/10000, Loss: 0.013946300372481346, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5649/10000, Loss: 0.027798647060990334, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5650/10000, Loss: 2.1361727249313844e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5651/10000, Loss: 0.013891800306737423, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5652/10000, Loss: 0.013895660638809204, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5653/10000, Loss: 2.8251943149371073e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5654/10000, Loss: 0.013874613679945469, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5655/10000, Loss: 4.756258476845687e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5656/10000, Loss: 3.6763133266504155e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5657/10000, Loss: 1.699872882454656e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5658/10000, Loss: 0.013936296105384827, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5659/10000, Loss: 0.013885516673326492, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5660/10000, Loss: 3.399778506718576e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5661/10000, Loss: 3.4474437597964425e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5662/10000, Loss: 0.013892324641346931, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5663/10000, Loss: 4.5061023001835565e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5664/10000, Loss: 2.4437324555037776e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5665/10000, Loss: 0.013901010155677795, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5666/10000, Loss: 0.01397599559277296, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5667/10000, Loss: 1.9478452486509923e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5668/10000, Loss: 2.624854005262023e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5669/10000, Loss: 0.013867656700313091, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5670/10000, Loss: 0.01390086580067873, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5671/10000, Loss: 1.2922178029839415e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5672/10000, Loss: 2.472361074978835e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5673/10000, Loss: 0.013898340985178947, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5674/10000, Loss: 0.013895015232264996, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5675/10000, Loss: 0.0138862868770957, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5676/10000, Loss: 0.013896253891289234, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5677/10000, Loss: 0.013956118375062943, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5678/10000, Loss: 0.013939598575234413, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5679/10000, Loss: 0.013871160335838795, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5680/10000, Loss: 0.013881079852581024, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5681/10000, Loss: 5.602817623184819e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5682/10000, Loss: 2.2792569325247314e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5683/10000, Loss: 0.01390872336924076, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5684/10000, Loss: 1.1730116966646165e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5685/10000, Loss: 1.2683773320532055e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5686/10000, Loss: 2.7942112410528352e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5687/10000, Loss: 0.013890894129872322, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5688/10000, Loss: 8.94062452516664e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5689/10000, Loss: 0.013882114551961422, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5690/10000, Loss: 1.1944583775402862e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5691/10000, Loss: 8.630694310340914e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5692/10000, Loss: 0.013885818421840668, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5693/10000, Loss: 2.095672016366734e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5694/10000, Loss: 4.081647603015881e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5695/10000, Loss: 0.013935137540102005, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5696/10000, Loss: 0.013865799643099308, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5697/10000, Loss: 0.027754897251725197, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5698/10000, Loss: 0.01388632133603096, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5699/10000, Loss: 7.104841301952547e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5700/10000, Loss: 0.013879128731787205, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 5700: 0.32876300241947193\n",
            "Epoch 5701/10000, Loss: 0.027806542813777924, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5702/10000, Loss: 2.3972663257154636e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5703/10000, Loss: 5.530997441383079e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5704/10000, Loss: 0.027748126536607742, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5705/10000, Loss: 0.02785196155309677, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5706/10000, Loss: 8.368459702978726e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5707/10000, Loss: 6.179910997161642e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5708/10000, Loss: 0.013885729014873505, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5709/10000, Loss: 1.6736788666094071e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5710/10000, Loss: 0.01387307234108448, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5711/10000, Loss: 5.0089647629647516e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5712/10000, Loss: 3.271027253504144e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5713/10000, Loss: 2.3457891074940562e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5714/10000, Loss: 1.3279817494549206e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5715/10000, Loss: 5.555133384405053e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5716/10000, Loss: 0.013875195756554604, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5717/10000, Loss: 1.0061199873234727e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5718/10000, Loss: 2.299304833286442e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5719/10000, Loss: 2.665390638867393e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5720/10000, Loss: 0.013940037228167057, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5721/10000, Loss: 5.5830596465966664e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5722/10000, Loss: 2.2532985894940794e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5723/10000, Loss: 1.7404539676135755e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5724/10000, Loss: 2.2337531845550984e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5725/10000, Loss: 0.013967856764793396, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5726/10000, Loss: 0.013879437930881977, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5727/10000, Loss: 0.04164111614227295, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5728/10000, Loss: 0.013872782699763775, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5729/10000, Loss: 3.790844118611858e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5730/10000, Loss: 1.163473712040286e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5731/10000, Loss: 0.013871997594833374, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5732/10000, Loss: 6.145110091893002e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5733/10000, Loss: 8.296931355289416e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5734/10000, Loss: 1.3923386177339125e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5735/10000, Loss: 4.157833245699294e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5736/10000, Loss: 3.054095031984616e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5737/10000, Loss: 8.940609177443548e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5738/10000, Loss: 0.013885035179555416, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5739/10000, Loss: 4.7445232098652923e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5740/10000, Loss: 0.01395194511860609, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5741/10000, Loss: 5.078289291304827e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5742/10000, Loss: 6.355545792757766e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5743/10000, Loss: 6.794900286877237e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5744/10000, Loss: 7.67871824791655e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5745/10000, Loss: 0.027746865525841713, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5746/10000, Loss: 0.013876978307962418, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5747/10000, Loss: 7.4904037319356576e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5748/10000, Loss: 1.9836068076983793e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5749/10000, Loss: 2.0503525774984155e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5750/10000, Loss: 2.980227407078928e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5751/10000, Loss: 3.5427603961579734e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5752/10000, Loss: 0.01386822946369648, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5753/10000, Loss: 2.2452528355643153e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5754/10000, Loss: 0.02774771861732006, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5755/10000, Loss: 2.158468123525381e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5756/10000, Loss: 0.013937444426119328, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5757/10000, Loss: 0.04162754863500595, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5758/10000, Loss: 0.027818137779831886, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5759/10000, Loss: 7.915463129393174e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5760/10000, Loss: 0.013913976959884167, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5761/10000, Loss: 2.7464598133519758e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5762/10000, Loss: 0.04163934662938118, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5763/10000, Loss: 0.013867642730474472, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5764/10000, Loss: 2.6606337542034453e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5765/10000, Loss: 0.013854927383363247, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5766/10000, Loss: 2.0241386664565653e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5767/10000, Loss: 4.865931714448379e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5768/10000, Loss: 0.027768244966864586, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5769/10000, Loss: 1.5568572280244553e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5770/10000, Loss: 8.591797268309165e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5771/10000, Loss: 0.013877883553504944, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5772/10000, Loss: 0.027749978005886078, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5773/10000, Loss: 7.440336503350409e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5774/10000, Loss: 0.013890224508941174, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5775/10000, Loss: 0.01390262320637703, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5776/10000, Loss: 1.0108877859238419e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5777/10000, Loss: 9.369808253723022e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5778/10000, Loss: 3.6787268982152455e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5779/10000, Loss: 0.013944308273494244, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5780/10000, Loss: 1.5091625300556188e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5781/10000, Loss: 0.02774677611887455, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5782/10000, Loss: 2.0217676137690432e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5783/10000, Loss: 5.197512678023486e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5784/10000, Loss: 0.013879823498427868, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5785/10000, Loss: 7.554866897407919e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5786/10000, Loss: 0.013879054225981236, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5787/10000, Loss: 0.013892552815377712, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5788/10000, Loss: 0.013879028148949146, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5789/10000, Loss: 8.91680372205883e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5790/10000, Loss: 0.027747368440032005, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5791/10000, Loss: 4.379566689749481e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5792/10000, Loss: 0.013884501531720161, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5793/10000, Loss: 1.1944684956688434e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5794/10000, Loss: 6.510531875392189e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5795/10000, Loss: 0.013885154388844967, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5796/10000, Loss: 0.013872046023607254, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5797/10000, Loss: 1.3899619943913422e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5798/10000, Loss: 1.4900875839884975e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5799/10000, Loss: 0.013880185782909393, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5800/10000, Loss: 1.0561842600509408e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 5800: 0.32972200236320515\n",
            "Epoch 5801/10000, Loss: 2.3063712433213368e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5802/10000, Loss: 1.7523509541206295e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5803/10000, Loss: 0.013893009163439274, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5804/10000, Loss: 0.013863584958016872, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5805/10000, Loss: 8.749897801862971e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5806/10000, Loss: 4.446344973985106e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5807/10000, Loss: 0.013873242773115635, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5808/10000, Loss: 5.6903818403952755e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5809/10000, Loss: 2.6559400794212706e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5810/10000, Loss: 5.134285311214626e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5811/10000, Loss: 0.013869739137589931, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5812/10000, Loss: 1.4853206948828301e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5813/10000, Loss: 0.013902544975280762, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5814/10000, Loss: 1.8620161199578433e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5815/10000, Loss: 1.7475790627941024e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5816/10000, Loss: 9.371455234941095e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5817/10000, Loss: 0.013891132548451424, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5818/10000, Loss: 0.027745971456170082, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5819/10000, Loss: 0.013906553387641907, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5820/10000, Loss: 0.013882319442927837, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5821/10000, Loss: 0.027730342000722885, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5822/10000, Loss: 3.16851696879894e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5823/10000, Loss: 2.343613914490561e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5824/10000, Loss: 3.1756617318023928e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5825/10000, Loss: 0.02777724899351597, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5826/10000, Loss: 2.129037284248625e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5827/10000, Loss: 0.01389816589653492, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5828/10000, Loss: 0.013954450376331806, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5829/10000, Loss: 0.02775930054485798, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5830/10000, Loss: 0.02774810791015625, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5831/10000, Loss: 2.1826805095770396e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5832/10000, Loss: 0.013889564201235771, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5833/10000, Loss: 2.067060449917335e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5834/10000, Loss: 5.48297703062417e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5835/10000, Loss: 8.058486855588853e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5836/10000, Loss: 0.013895907439291477, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5837/10000, Loss: 8.153876933647553e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5838/10000, Loss: 0.013892749324440956, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5839/10000, Loss: 7.247849680425134e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5840/10000, Loss: 2.4890448457881575e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5841/10000, Loss: 0.027748826891183853, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5842/10000, Loss: 1.3375031358009437e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5843/10000, Loss: 1.8977907529915683e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5844/10000, Loss: 1.8095684026775416e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5845/10000, Loss: 0.013890095986425877, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5846/10000, Loss: 1.4781942070385412e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5847/10000, Loss: 1.8763379330266616e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5848/10000, Loss: 0.02774903178215027, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5849/10000, Loss: 0.027797086164355278, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5850/10000, Loss: 1.3756501857642434e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5851/10000, Loss: 1.392353965457005e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5852/10000, Loss: 3.981580221079639e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5853/10000, Loss: 1.335143338110356e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5854/10000, Loss: 1.2016204209430725e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5855/10000, Loss: 3.89804790756898e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5856/10000, Loss: 2.4080247840174707e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5857/10000, Loss: 0.02778538689017296, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5858/10000, Loss: 2.1766963982372545e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5859/10000, Loss: 0.01388789713382721, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5860/10000, Loss: 2.0849774955422617e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5861/10000, Loss: 1.975546547328122e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5862/10000, Loss: 2.4103424038912635e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5863/10000, Loss: 0.013899685814976692, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5864/10000, Loss: 4.172316039330326e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5865/10000, Loss: 1.019158571580192e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5866/10000, Loss: 6.890269901305146e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5867/10000, Loss: 7.600104254379403e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5868/10000, Loss: 0.013887014240026474, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5869/10000, Loss: 2.07421408049413e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5870/10000, Loss: 0.02776988409459591, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5871/10000, Loss: 0.013883340172469616, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5872/10000, Loss: 2.0628238416975364e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5873/10000, Loss: 0.01389617845416069, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5874/10000, Loss: 2.0551321995299077e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5875/10000, Loss: 0.01391402818262577, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5876/10000, Loss: 1.2588380968736601e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5877/10000, Loss: 0.013905994594097137, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5878/10000, Loss: 0.013871369883418083, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5879/10000, Loss: 1.6593628515693126e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5880/10000, Loss: 1.3279820905154338e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5881/10000, Loss: 0.013886196538805962, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5882/10000, Loss: 5.388236559156212e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5883/10000, Loss: 0.027745969593524933, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5884/10000, Loss: 2.789494999433373e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5885/10000, Loss: 6.079655463508971e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5886/10000, Loss: 5.4667648328177165e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5887/10000, Loss: 1.173009877675213e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5888/10000, Loss: 2.1862636003788793e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5889/10000, Loss: 9.274374974665989e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5890/10000, Loss: 0.01388522144407034, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5891/10000, Loss: 0.01388083677738905, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5892/10000, Loss: 1.3947185379947769e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5893/10000, Loss: 2.846659754141001e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5894/10000, Loss: 1.2564415783344884e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5895/10000, Loss: 0.013871682807803154, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5896/10000, Loss: 3.8050666262279265e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5897/10000, Loss: 2.9562822874140693e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5898/10000, Loss: 0.05549599975347519, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5899/10000, Loss: 3.1160132039076416e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5900/10000, Loss: 5.390080332290381e-05, Train Accuracy: 0.9900000095367432\n",
            "Test Accuracy at epoch 5900: 0.33068100230693837\n",
            "Epoch 5901/10000, Loss: 0.013903087005019188, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5902/10000, Loss: 3.5213754472351866e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5903/10000, Loss: 0.013877099379897118, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5904/10000, Loss: 0.02779017575085163, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5905/10000, Loss: 2.1624239252560074e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5906/10000, Loss: 0.013883761130273342, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5907/10000, Loss: 0.02780800126492977, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5908/10000, Loss: 0.01390845887362957, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5909/10000, Loss: 1.015656380332075e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5910/10000, Loss: 3.2186443377213436e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5911/10000, Loss: 8.678372864778794e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5912/10000, Loss: 0.02774479240179062, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5913/10000, Loss: 0.013887002132833004, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5914/10000, Loss: 9.488989576311724e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5915/10000, Loss: 0.01392444595694542, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5916/10000, Loss: 0.013911942020058632, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5917/10000, Loss: 2.1361695416999282e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5918/10000, Loss: 0.01389944739639759, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5919/10000, Loss: 4.4822544964517874e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5920/10000, Loss: 1.950841397047043e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5921/10000, Loss: 0.013880209997296333, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5922/10000, Loss: 2.1680336431018077e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5923/10000, Loss: 0.013892403803765774, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5924/10000, Loss: 1.5949934777381714e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5925/10000, Loss: 0.013933084905147552, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5926/10000, Loss: 4.793103289557621e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5927/10000, Loss: 1.4757821418243111e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5928/10000, Loss: 0.013935694471001625, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5929/10000, Loss: 2.8061069770046743e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5930/10000, Loss: 6.771036282771092e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5931/10000, Loss: 1.714198560875957e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5932/10000, Loss: 0.0138810770586133, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5933/10000, Loss: 0.04163071885704994, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5934/10000, Loss: 0.013866988942027092, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5935/10000, Loss: 1.9973578673671e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5936/10000, Loss: 5.769712174696906e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5937/10000, Loss: 0.013904070481657982, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5938/10000, Loss: 0.013872583396732807, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5939/10000, Loss: 8.869104135555972e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5940/10000, Loss: 9.760164175531827e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5941/10000, Loss: 0.027744868770241737, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5942/10000, Loss: 0.027746126055717468, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5943/10000, Loss: 3.433221706927725e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5944/10000, Loss: 0.013889480382204056, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5945/10000, Loss: 2.041712104983162e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5946/10000, Loss: 1.1038682714570314e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5947/10000, Loss: 6.002798727422487e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5948/10000, Loss: 0.027768922969698906, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5949/10000, Loss: 0.013889186084270477, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5950/10000, Loss: 4.100791386463243e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5951/10000, Loss: 2.2005694972904166e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5952/10000, Loss: 1.1944655398110626e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5953/10000, Loss: 1.9003038687515073e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5954/10000, Loss: 4.913269731332548e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5955/10000, Loss: 0.013866722583770752, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5956/10000, Loss: 0.013920534402132034, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5957/10000, Loss: 0.013896036893129349, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5958/10000, Loss: 2.3170508939074352e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5959/10000, Loss: 5.1476104999892414e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5960/10000, Loss: 0.027745699509978294, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5961/10000, Loss: 0.013898470439016819, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5962/10000, Loss: 1.2278335361770587e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5963/10000, Loss: 1.6069280945885112e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5964/10000, Loss: 0.013877315446734428, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5965/10000, Loss: 0.01388337928801775, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5966/10000, Loss: 8.773716331234027e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5967/10000, Loss: 0.027744822204113007, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5968/10000, Loss: 0.013897698372602463, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5969/10000, Loss: 1.7881258145280299e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5970/10000, Loss: 5.309022981236922e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5971/10000, Loss: 0.013932191766798496, Train Accuracy: 0.9879999756813049\n",
            "Epoch 5972/10000, Loss: 6.811090861447155e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5973/10000, Loss: 0.013898410834372044, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5974/10000, Loss: 0.013913074508309364, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5975/10000, Loss: 0.027782045304775238, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5976/10000, Loss: 0.013898573815822601, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5977/10000, Loss: 2.2172575881995726e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5978/10000, Loss: 0.013898809440433979, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5979/10000, Loss: 8.940667157730786e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5980/10000, Loss: 0.01393007393926382, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5981/10000, Loss: 7.557785011158558e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5982/10000, Loss: 0.013892007991671562, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5983/10000, Loss: 1.0347301895308192e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5984/10000, Loss: 1.6021556348277954e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5985/10000, Loss: 0.013876666314899921, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5986/10000, Loss: 2.7751152629207354e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5987/10000, Loss: 0.013883233070373535, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5988/10000, Loss: 0.013873603194952011, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5989/10000, Loss: 0.027744852006435394, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5990/10000, Loss: 5.0350656238151714e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5991/10000, Loss: 3.8623764453404874e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5992/10000, Loss: 1.0752456773843733e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5993/10000, Loss: 0.041628625243902206, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5994/10000, Loss: 0.01389253605157137, Train Accuracy: 0.9900000095367432\n",
            "Epoch 5995/10000, Loss: 0.027850091457366943, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5996/10000, Loss: 1.931161705215345e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5997/10000, Loss: 0.013883348554372787, Train Accuracy: 0.9919999837875366\n",
            "Epoch 5998/10000, Loss: 5.817393571305729e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 5999/10000, Loss: 0.013890366069972515, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6000/10000, Loss: 0.02783108688890934, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 6000: 0.3316400022506716\n",
            "Epoch 6001/10000, Loss: 0.013871967792510986, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6002/10000, Loss: 1.16345654532779e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6003/10000, Loss: 4.960059231962077e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6004/10000, Loss: 0.013884174637496471, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6005/10000, Loss: 1.7514023056719452e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6006/10000, Loss: 1.4590972341466113e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6007/10000, Loss: 0.01388154923915863, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6008/10000, Loss: 0.013887017965316772, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6009/10000, Loss: 2.1147416191524826e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6010/10000, Loss: 1.3136736924934667e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6011/10000, Loss: 0.01388300396502018, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6012/10000, Loss: 6.270363996918604e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6013/10000, Loss: 4.44999968749471e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6014/10000, Loss: 0.013901459984481335, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6015/10000, Loss: 1.7714177147354349e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6016/10000, Loss: 3.456950253166724e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6017/10000, Loss: 0.013866262510418892, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6018/10000, Loss: 0.027745580300688744, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6019/10000, Loss: 1.175383317786327e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6020/10000, Loss: 1.3589847469575034e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6021/10000, Loss: 0.01393486000597477, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6022/10000, Loss: 2.013437551795505e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6023/10000, Loss: 2.7369555937184487e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6024/10000, Loss: 2.078980287478771e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6025/10000, Loss: 0.013887125998735428, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6026/10000, Loss: 0.013924969360232353, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6027/10000, Loss: 2.3603031422680942e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6028/10000, Loss: 0.027804020792245865, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6029/10000, Loss: 1.8332095351070166e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6030/10000, Loss: 1.826533116400242e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6031/10000, Loss: 0.02774619683623314, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6032/10000, Loss: 1.8334146716370014e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6033/10000, Loss: 2.77033132078941e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6034/10000, Loss: 0.01387842744588852, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6035/10000, Loss: 8.821454002827522e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6036/10000, Loss: 5.364403818930441e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6037/10000, Loss: 4.660910053644329e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6038/10000, Loss: 4.124636348024069e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6039/10000, Loss: 3.9552301132061984e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6040/10000, Loss: 0.013919717632234097, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6041/10000, Loss: 0.013888703659176826, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6042/10000, Loss: 0.027783801779150963, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6043/10000, Loss: 1.8501003751225653e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6044/10000, Loss: 4.449000334716402e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6045/10000, Loss: 5.800219241791638e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6046/10000, Loss: 0.013895303010940552, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6047/10000, Loss: 0.0138925826177001, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6048/10000, Loss: 0.02777252160012722, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6049/10000, Loss: 0.013858337886631489, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6050/10000, Loss: 0.01386980339884758, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6051/10000, Loss: 9.417370847586426e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6052/10000, Loss: 1.4304888509286684e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6053/10000, Loss: 0.02775227092206478, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6054/10000, Loss: 1.740454536047764e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6055/10000, Loss: 0.01386936753988266, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6056/10000, Loss: 0.013902920298278332, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6057/10000, Loss: 3.004068673817528e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6058/10000, Loss: 0.0139067517593503, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6059/10000, Loss: 2.908703606863128e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6060/10000, Loss: 4.5072829379932955e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6061/10000, Loss: 4.373532647150569e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6062/10000, Loss: 6.675653025922657e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6063/10000, Loss: 1.897781089610362e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6064/10000, Loss: 9.70355472418305e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6065/10000, Loss: 6.008114041833323e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6066/10000, Loss: 1.0466490039107157e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6067/10000, Loss: 7.295577120203234e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6068/10000, Loss: 0.013906343840062618, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6069/10000, Loss: 9.05984336441179e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6070/10000, Loss: 2.527232823013037e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6071/10000, Loss: 0.013898056000471115, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6072/10000, Loss: 2.2683027054881677e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6073/10000, Loss: 0.013904832303524017, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6074/10000, Loss: 0.027762383222579956, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6075/10000, Loss: 0.013883358798921108, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6076/10000, Loss: 2.7727201086236164e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6077/10000, Loss: 1.4018756928635412e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6078/10000, Loss: 0.013883039355278015, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6079/10000, Loss: 1.0800175687109004e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6080/10000, Loss: 1.194471906273975e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6081/10000, Loss: 1.8544909835327417e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6082/10000, Loss: 2.1939522412139922e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6083/10000, Loss: 7.653167131138616e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6084/10000, Loss: 0.013885107822716236, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6085/10000, Loss: 3.826500687864609e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6086/10000, Loss: 4.0531085687689483e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6087/10000, Loss: 0.01389642059803009, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6088/10000, Loss: 0.013869477435946465, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6089/10000, Loss: 2.0892961401841603e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6090/10000, Loss: 0.02774490974843502, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6091/10000, Loss: 1.2278474059712607e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6092/10000, Loss: 0.041622839868068695, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6093/10000, Loss: 0.013888842426240444, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6094/10000, Loss: 4.2101939470740035e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6095/10000, Loss: 4.6105756155157e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6096/10000, Loss: 2.9229611300252145e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6097/10000, Loss: 8.058503340180323e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6098/10000, Loss: 2.1171049411350396e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6099/10000, Loss: 5.049265382695012e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6100/10000, Loss: 5.531292117666453e-07, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 6100: 0.3325990021944048\n",
            "Epoch 6101/10000, Loss: 6.914119694556575e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6102/10000, Loss: 1.6856062075021327e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6103/10000, Loss: 4.272968362784013e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6104/10000, Loss: 3.0994357302915887e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6105/10000, Loss: 7.295558930309198e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6106/10000, Loss: 1.971676510947873e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6107/10000, Loss: 7.104833343873906e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6108/10000, Loss: 0.01388593390583992, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6109/10000, Loss: 0.013884978368878365, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6110/10000, Loss: 0.013880104757845402, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6111/10000, Loss: 5.936586262578203e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6112/10000, Loss: 2.3507288915425306e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6113/10000, Loss: 1.8739473262030515e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6114/10000, Loss: 0.013903840444982052, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6115/10000, Loss: 1.594887362443842e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6116/10000, Loss: 0.013873659074306488, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6117/10000, Loss: 0.01388748362660408, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6118/10000, Loss: 0.013890405185520649, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6119/10000, Loss: 4.331654963607434e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6120/10000, Loss: 1.5210686115096905e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6121/10000, Loss: 5.220953880780144e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6122/10000, Loss: 0.013934160582721233, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6123/10000, Loss: 6.818718816248293e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6124/10000, Loss: 0.013872576877474785, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6125/10000, Loss: 0.013875600881874561, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6126/10000, Loss: 9.417460660188226e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6127/10000, Loss: 2.522407385185943e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6128/10000, Loss: 2.0026825495733647e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6129/10000, Loss: 0.027782125398516655, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6130/10000, Loss: 2.2077194898884045e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6131/10000, Loss: 1.5765435819048434e-05, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6132/10000, Loss: 0.013887624256312847, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6133/10000, Loss: 0.013873756863176823, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6134/10000, Loss: 8.010820238268934e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6135/10000, Loss: 0.013930710032582283, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6136/10000, Loss: 0.027758101001381874, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6137/10000, Loss: 1.900129291243502e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6138/10000, Loss: 0.013887922279536724, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6139/10000, Loss: 1.2493034091676236e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6140/10000, Loss: 2.1051998828625074e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6141/10000, Loss: 0.01389179565012455, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6142/10000, Loss: 4.725050530396402e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6143/10000, Loss: 0.027743540704250336, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6144/10000, Loss: 0.01389499381184578, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6145/10000, Loss: 1.2493034091676236e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6146/10000, Loss: 2.069399670290295e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6147/10000, Loss: 0.013874507509171963, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6148/10000, Loss: 0.02777993306517601, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6149/10000, Loss: 0.01388578861951828, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6150/10000, Loss: 2.365038426432875e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6151/10000, Loss: 0.04161473363637924, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6152/10000, Loss: 0.013935715891420841, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6153/10000, Loss: 4.5748647607979365e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6154/10000, Loss: 0.013890866190195084, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6155/10000, Loss: 0.013895096257328987, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6156/10000, Loss: 5.921871434111381e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6157/10000, Loss: 8.678354674884758e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6158/10000, Loss: 5.1995220928802155e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6159/10000, Loss: 8.344516118086176e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6160/10000, Loss: 0.0277436301112175, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6161/10000, Loss: 0.013887051492929459, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6162/10000, Loss: 0.02774263545870781, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6163/10000, Loss: 0.02774295024573803, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6164/10000, Loss: 5.412061341303342e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6165/10000, Loss: 0.013882355764508247, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6166/10000, Loss: 0.013886376284062862, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6167/10000, Loss: 1.0323466312911478e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6168/10000, Loss: 0.027742037549614906, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6169/10000, Loss: 9.179073003906524e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6170/10000, Loss: 0.027768271043896675, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6171/10000, Loss: 0.013870111666619778, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6172/10000, Loss: 0.01388147845864296, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6173/10000, Loss: 3.0994374355941545e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6174/10000, Loss: 0.013858823105692863, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6175/10000, Loss: 1.0299633004251518e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6176/10000, Loss: 0.013873711228370667, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6177/10000, Loss: 0.027765223756432533, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6178/10000, Loss: 0.01388488058000803, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6179/10000, Loss: 1.0847951443793136e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6180/10000, Loss: 0.027781734243035316, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6181/10000, Loss: 0.01387045718729496, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6182/10000, Loss: 2.1219229040525533e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6183/10000, Loss: 7.367092393906205e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6184/10000, Loss: 0.013897879980504513, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6185/10000, Loss: 0.013923381455242634, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6186/10000, Loss: 0.027743587270379066, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6187/10000, Loss: 1.6898065950954333e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6188/10000, Loss: 1.9450346371741034e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6189/10000, Loss: 8.034664915612666e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6190/10000, Loss: 1.2898250361104147e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6191/10000, Loss: 2.595797377580311e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6192/10000, Loss: 0.013883249834179878, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6193/10000, Loss: 0.013907268643379211, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6194/10000, Loss: 0.013863770291209221, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6195/10000, Loss: 0.013881501741707325, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6196/10000, Loss: 1.2040056844853098e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6197/10000, Loss: 0.013876814395189285, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6198/10000, Loss: 5.364373123484256e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6199/10000, Loss: 0.013867327943444252, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6200/10000, Loss: 0.02779511921107769, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 6200: 0.333558002138138\n",
            "Epoch 6201/10000, Loss: 2.26017300519743e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6202/10000, Loss: 1.242154098690662e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6203/10000, Loss: 0.013876759447157383, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6204/10000, Loss: 1.080022229871247e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6205/10000, Loss: 2.8037447918904945e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6206/10000, Loss: 0.013874541968107224, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6207/10000, Loss: 0.013880057260394096, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6208/10000, Loss: 1.6688678670107038e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6209/10000, Loss: 0.013882446102797985, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6210/10000, Loss: 4.794261258211918e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6211/10000, Loss: 0.013880421407520771, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6212/10000, Loss: 8.678402423356602e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6213/10000, Loss: 6.15116732660681e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6214/10000, Loss: 1.2326164551268448e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6215/10000, Loss: 4.176070433459245e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6216/10000, Loss: 0.013901970349252224, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6217/10000, Loss: 2.7418056447459094e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6218/10000, Loss: 0.02778235450387001, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6219/10000, Loss: 0.01390822883695364, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6220/10000, Loss: 9.941982170857955e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6221/10000, Loss: 1.296983782594907e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6222/10000, Loss: 0.013886984437704086, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6223/10000, Loss: 0.013874618336558342, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6224/10000, Loss: 4.6968324340923573e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6225/10000, Loss: 0.013924900442361832, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6226/10000, Loss: 2.5510098566883244e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6227/10000, Loss: 0.013920032419264317, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6228/10000, Loss: 0.013891072943806648, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6229/10000, Loss: 6.389572035914171e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6230/10000, Loss: 4.7206467002069985e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6231/10000, Loss: 1.5179925867414568e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6232/10000, Loss: 0.013876077719032764, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6233/10000, Loss: 1.0585719110167702e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6234/10000, Loss: 4.12195777244051e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6235/10000, Loss: 3.791419294429943e-05, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6236/10000, Loss: 0.027781682088971138, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6237/10000, Loss: 1.8501071963328286e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6238/10000, Loss: 1.082414087250072e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6239/10000, Loss: 0.027762839570641518, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6240/10000, Loss: 1.0466526418895228e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6241/10000, Loss: 6.548977580678184e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6242/10000, Loss: 0.013880101963877678, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6243/10000, Loss: 1.0371130656494643e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6244/10000, Loss: 1.1753879789466737e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6245/10000, Loss: 1.068101141754596e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6246/10000, Loss: 3.770950934267603e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6247/10000, Loss: 4.5776110368933587e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6248/10000, Loss: 7.462446660611022e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6249/10000, Loss: 0.027754856273531914, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6250/10000, Loss: 6.222699084901251e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6251/10000, Loss: 3.9338999613391934e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6252/10000, Loss: 1.463169428461697e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6253/10000, Loss: 2.3483614768338157e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6254/10000, Loss: 0.013872824609279633, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6255/10000, Loss: 1.0204195177720976e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6256/10000, Loss: 1.7680878954706714e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6257/10000, Loss: 2.9205480132077355e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6258/10000, Loss: 0.013867232948541641, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6259/10000, Loss: 0.013920934870839119, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6260/10000, Loss: 0.027778662741184235, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6261/10000, Loss: 2.884860634821962e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6262/10000, Loss: 0.04173889011144638, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6263/10000, Loss: 4.43457082610621e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6264/10000, Loss: 9.536740464000104e-08, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6265/10000, Loss: 0.013876249082386494, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6266/10000, Loss: 0.013879002071917057, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6267/10000, Loss: 1.3398962437349837e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6268/10000, Loss: 0.013878085650503635, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6269/10000, Loss: 2.622597321533249e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6270/10000, Loss: 0.02774079702794552, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6271/10000, Loss: 0.01389517355710268, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6272/10000, Loss: 1.0919467285930295e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6273/10000, Loss: 0.013887680135667324, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6274/10000, Loss: 9.608137361283298e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6275/10000, Loss: 0.013874937780201435, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6276/10000, Loss: 2.0718239284178708e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6277/10000, Loss: 0.013875365257263184, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6278/10000, Loss: 3.623947293363017e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6279/10000, Loss: 1.7881374958506058e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6280/10000, Loss: 1.0371149983257055e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6281/10000, Loss: 0.013883961364626884, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6282/10000, Loss: 0.013877269811928272, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6283/10000, Loss: 9.107467917601753e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6284/10000, Loss: 0.041623856872320175, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6285/10000, Loss: 0.027782000601291656, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6286/10000, Loss: 5.292866944728303e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6287/10000, Loss: 0.013889695517718792, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6288/10000, Loss: 2.4604128157079685e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6289/10000, Loss: 5.0984312110813335e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6290/10000, Loss: 0.01388772577047348, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6291/10000, Loss: 7.700811011090991e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6292/10000, Loss: 7.462466555807623e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6293/10000, Loss: 1.1491700888655032e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6294/10000, Loss: 4.935239985570661e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6295/10000, Loss: 7.31940360765293e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6296/10000, Loss: 0.013877393677830696, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6297/10000, Loss: 8.845219667819038e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6298/10000, Loss: 1.3065218809060752e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6299/10000, Loss: 1.7642963712205528e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6300/10000, Loss: 0.02774178422987461, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 6300: 0.33451700208187124\n",
            "Epoch 6301/10000, Loss: 2.0980816373139533e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6302/10000, Loss: 5.04803319927305e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6303/10000, Loss: 3.599352567107417e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6304/10000, Loss: 1.9788720351243683e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6305/10000, Loss: 6.389603299794544e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6306/10000, Loss: 2.088482460749219e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6307/10000, Loss: 0.013923109509050846, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6308/10000, Loss: 0.013892018236219883, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6309/10000, Loss: 0.027751976624131203, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6310/10000, Loss: 0.01392322313040495, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6311/10000, Loss: 1.6782742022769526e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6312/10000, Loss: 0.013879215344786644, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6313/10000, Loss: 6.424687853723299e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6314/10000, Loss: 5.108972800371703e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6315/10000, Loss: 0.013898028060793877, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6316/10000, Loss: 0.01386368740350008, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6317/10000, Loss: 0.01388052199035883, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6318/10000, Loss: 6.010216111462796e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6319/10000, Loss: 5.235455319052562e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6320/10000, Loss: 0.041629135608673096, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6321/10000, Loss: 1.2197263458801899e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6322/10000, Loss: 0.013886790722608566, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6323/10000, Loss: 4.434474703884916e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6324/10000, Loss: 0.013862285763025284, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6325/10000, Loss: 0.013874504715204239, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6326/10000, Loss: 1.2159281368440134e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6327/10000, Loss: 4.417823674884858e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6328/10000, Loss: 1.2762833648594096e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6329/10000, Loss: 3.93034060834907e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6330/10000, Loss: 0.013890832662582397, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6331/10000, Loss: 8.559193247492658e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6332/10000, Loss: 0.013897049240767956, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6333/10000, Loss: 2.5639439627411775e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6334/10000, Loss: 0.027876142412424088, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6335/10000, Loss: 1.053801270245458e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6336/10000, Loss: 0.027741895988583565, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6337/10000, Loss: 0.013895411975681782, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6338/10000, Loss: 1.2803004665329354e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6339/10000, Loss: 1.1014871006409521e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6340/10000, Loss: 9.191882782033645e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6341/10000, Loss: 2.6297113890905166e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6342/10000, Loss: 5.3508454584516585e-05, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6343/10000, Loss: 0.027742872014641762, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6344/10000, Loss: 2.4938140086305793e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6345/10000, Loss: 0.013893093913793564, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6346/10000, Loss: 0.01390060130506754, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6347/10000, Loss: 0.013867812231183052, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6348/10000, Loss: 1.1515533060446614e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6349/10000, Loss: 9.512855854154623e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6350/10000, Loss: 1.0085055919262231e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6351/10000, Loss: 0.013884184882044792, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6352/10000, Loss: 1.770414564816747e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6353/10000, Loss: 9.131396723205398e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6354/10000, Loss: 0.013892196118831635, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6355/10000, Loss: 0.013872123323380947, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6356/10000, Loss: 1.120562615142262e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6357/10000, Loss: 3.807712346315384e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6358/10000, Loss: 1.0585722520772833e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6359/10000, Loss: 3.178062570441398e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6360/10000, Loss: 1.8668064285520813e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6361/10000, Loss: 0.013892731629312038, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6362/10000, Loss: 0.013860133476555347, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6363/10000, Loss: 3.0850856092001777e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6364/10000, Loss: 0.0138669703155756, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6365/10000, Loss: 0.013900544494390488, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6366/10000, Loss: 0.013901001773774624, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6367/10000, Loss: 3.708588701556437e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6368/10000, Loss: 1.2183122635178734e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6369/10000, Loss: 0.013865442015230656, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6370/10000, Loss: 2.5582112357369624e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6371/10000, Loss: 0.013922974467277527, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6372/10000, Loss: 3.9069644117262214e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6373/10000, Loss: 2.210111915701418e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6374/10000, Loss: 0.027740873396396637, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6375/10000, Loss: 2.60110618910403e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6376/10000, Loss: 1.0490329032109003e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6377/10000, Loss: 1.9740780317079043e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6378/10000, Loss: 2.8776426006515976e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6379/10000, Loss: 0.013879073783755302, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6380/10000, Loss: 6.389598752321035e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6381/10000, Loss: 0.01387955155223608, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6382/10000, Loss: 0.027740422636270523, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6383/10000, Loss: 2.1934494043307495e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6384/10000, Loss: 0.013901072554290295, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6385/10000, Loss: 2.7870382837136276e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6386/10000, Loss: 0.013885877095162868, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6387/10000, Loss: 0.013885640539228916, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6388/10000, Loss: 0.02778949961066246, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6389/10000, Loss: 1.0633419833538937e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6390/10000, Loss: 2.367482238696539e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6391/10000, Loss: 0.027778398245573044, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6392/10000, Loss: 0.027740182355046272, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6393/10000, Loss: 6.815550477767829e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6394/10000, Loss: 2.6201876153209014e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6395/10000, Loss: 0.013876535929739475, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6396/10000, Loss: 0.027741579338908195, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6397/10000, Loss: 3.83746883017011e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6398/10000, Loss: 6.291065801633522e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6399/10000, Loss: 9.536705078971863e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6400/10000, Loss: 2.317405233043246e-06, Train Accuracy: 0.9900000095367432\n",
            "Test Accuracy at epoch 6400: 0.33547600202560446\n",
            "Epoch 6401/10000, Loss: 6.150417902972549e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6402/10000, Loss: 0.013930833898484707, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6403/10000, Loss: 3.55243230387714e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6404/10000, Loss: 0.013870244845747948, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6405/10000, Loss: 1.4376481658473494e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6406/10000, Loss: 0.013898753561079502, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6407/10000, Loss: 0.013867992907762527, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6408/10000, Loss: 0.013860425911843777, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6409/10000, Loss: 0.013871122151613235, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6410/10000, Loss: 0.013883247971534729, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6411/10000, Loss: 1.779215017450042e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6412/10000, Loss: 0.027790989726781845, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6413/10000, Loss: 1.716602696433256e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6414/10000, Loss: 0.013885000720620155, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6415/10000, Loss: 6.699534083054459e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6416/10000, Loss: 1.3613521332445089e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6417/10000, Loss: 5.897777555219363e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6418/10000, Loss: 1.5687739960412728e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6419/10000, Loss: 3.6327455745777115e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6420/10000, Loss: 3.139903355986462e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6421/10000, Loss: 1.65714282047702e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6422/10000, Loss: 0.013887731358408928, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6423/10000, Loss: 0.013916144147515297, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6424/10000, Loss: 6.448552085203119e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6425/10000, Loss: 1.6927475599004538e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6426/10000, Loss: 1.00612112419185e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6427/10000, Loss: 0.013922333717346191, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6428/10000, Loss: 0.013860742561519146, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6429/10000, Loss: 1.4304980595625238e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6430/10000, Loss: 6.059958195692161e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6431/10000, Loss: 2.6583068120089592e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6432/10000, Loss: 6.608318926737411e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6433/10000, Loss: 0.027739834040403366, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6434/10000, Loss: 0.0277755968272686, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6435/10000, Loss: 0.013883434236049652, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6436/10000, Loss: 1.0228103519693832e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6437/10000, Loss: 1.2802993296645582e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6438/10000, Loss: 1.3112950227878173e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6439/10000, Loss: 0.013885797932744026, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6440/10000, Loss: 3.546509105945006e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6441/10000, Loss: 0.01390285138040781, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6442/10000, Loss: 7.60551984058111e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6443/10000, Loss: 0.0416090190410614, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6444/10000, Loss: 1.9550299157344853e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6445/10000, Loss: 0.013895120471715927, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6446/10000, Loss: 0.013882334344089031, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6447/10000, Loss: 0.013872266747057438, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6448/10000, Loss: 3.716900209838059e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6449/10000, Loss: 0.01390603743493557, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6450/10000, Loss: 1.5520860188189545e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6451/10000, Loss: 1.6230313121923245e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6452/10000, Loss: 1.1396260788387735e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6453/10000, Loss: 1.8095862515110639e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6454/10000, Loss: 1.0847983276107698e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6455/10000, Loss: 1.6859694369486533e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6456/10000, Loss: 0.013878228142857552, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6457/10000, Loss: 0.027772124856710434, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6458/10000, Loss: 1.9287929262645775e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6459/10000, Loss: 0.013902591541409492, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6460/10000, Loss: 1.0776446970339748e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6461/10000, Loss: 0.013880289159715176, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6462/10000, Loss: 1.5759313782837125e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6463/10000, Loss: 3.4810127544915304e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6464/10000, Loss: 2.0122272417211207e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6465/10000, Loss: 2.229169467682368e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6466/10000, Loss: 5.483599352373858e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6467/10000, Loss: 0.01386463176459074, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6468/10000, Loss: 2.717968925480818e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6469/10000, Loss: 0.02780199982225895, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6470/10000, Loss: 0.013885349035263062, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6471/10000, Loss: 0.013871472328901291, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6472/10000, Loss: 0.04161923751235008, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6473/10000, Loss: 0.013908373191952705, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6474/10000, Loss: 2.214869255112717e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6475/10000, Loss: 1.9287660961708752e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6476/10000, Loss: 0.013880042359232903, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6477/10000, Loss: 0.027805145829916, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6478/10000, Loss: 0.013887278735637665, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6479/10000, Loss: 0.013895850628614426, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6480/10000, Loss: 5.053762288298458e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6481/10000, Loss: 3.5287343052914366e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6482/10000, Loss: 1.0108908554684604e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6483/10000, Loss: 0.013871829025447369, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6484/10000, Loss: 1.9239932953496464e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6485/10000, Loss: 2.4342266442545224e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6486/10000, Loss: 6.604167310797493e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6487/10000, Loss: 0.013888739980757236, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6488/10000, Loss: 4.834661922359373e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6489/10000, Loss: 0.027837369590997696, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6490/10000, Loss: 0.013874199241399765, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6491/10000, Loss: 0.013886997476220131, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6492/10000, Loss: 3.563098653103225e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6493/10000, Loss: 0.013898964039981365, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6494/10000, Loss: 0.013870538212358952, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6495/10000, Loss: 5.047824015491642e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6496/10000, Loss: 2.0122308796999278e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6497/10000, Loss: 0.01388293132185936, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6498/10000, Loss: 8.773755553193041e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6499/10000, Loss: 1.1729997595466557e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6500/10000, Loss: 7.915461992524797e-07, Train Accuracy: 0.9900000095367432\n",
            "Test Accuracy at epoch 6500: 0.3364350019693377\n",
            "Epoch 6501/10000, Loss: 0.013898291625082493, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6502/10000, Loss: 7.414755032186804e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6503/10000, Loss: 6.389595910150092e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6504/10000, Loss: 0.013870385475456715, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6505/10000, Loss: 0.027803953737020493, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6506/10000, Loss: 0.013907725922763348, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6507/10000, Loss: 0.013864168897271156, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6508/10000, Loss: 6.151181537461525e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6509/10000, Loss: 0.01389223150908947, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6510/10000, Loss: 1.5830609072509105e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6511/10000, Loss: 1.4042478824194404e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6512/10000, Loss: 0.013875739648938179, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6513/10000, Loss: 3.5490666050463915e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6514/10000, Loss: 0.013931878842413425, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6515/10000, Loss: 0.02775568887591362, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6516/10000, Loss: 0.027739785611629486, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6517/10000, Loss: 5.216178033151664e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6518/10000, Loss: 3.45513726642821e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6519/10000, Loss: 3.983910119131906e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6520/10000, Loss: 0.013893380761146545, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6521/10000, Loss: 7.820041787454102e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6522/10000, Loss: 0.013866533525288105, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6523/10000, Loss: 0.01387773733586073, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6524/10000, Loss: 0.027775775641202927, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6525/10000, Loss: 1.0752467005659128e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6526/10000, Loss: 2.102829739669687e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6527/10000, Loss: 0.013885707594454288, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6528/10000, Loss: 1.2135359384046751e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6529/10000, Loss: 0.013879620470106602, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6530/10000, Loss: 8.344647284275197e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6531/10000, Loss: 0.02774115651845932, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6532/10000, Loss: 0.013873066753149033, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6533/10000, Loss: 0.013879137113690376, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6534/10000, Loss: 2.6464439883966406e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6535/10000, Loss: 0.013849607668817043, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6536/10000, Loss: 5.850384241057327e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6537/10000, Loss: 1.962168198588188e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6538/10000, Loss: 1.4734146134287585e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6539/10000, Loss: 0.013874618336558342, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6540/10000, Loss: 1.0466479807291762e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6541/10000, Loss: 4.4008293116348796e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6542/10000, Loss: 1.7404158825229388e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6543/10000, Loss: 0.013882502913475037, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6544/10000, Loss: 0.02773931995034218, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6545/10000, Loss: 1.2874595256562316e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6546/10000, Loss: 1.4281162066254183e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6547/10000, Loss: 0.013918920420110226, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6548/10000, Loss: 0.013887704350054264, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6549/10000, Loss: 0.013894899748265743, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6550/10000, Loss: 0.013871469534933567, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6551/10000, Loss: 4.959086936651147e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6552/10000, Loss: 2.503352334315423e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6553/10000, Loss: 0.01389854121953249, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6554/10000, Loss: 0.013901877216994762, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6555/10000, Loss: 1.349432636743586e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6556/10000, Loss: 0.01388747151941061, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6557/10000, Loss: 0.01387289259582758, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6558/10000, Loss: 0.013922815211117268, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6559/10000, Loss: 3.2901675695029553e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6560/10000, Loss: 0.013928613625466824, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6561/10000, Loss: 1.7917544028023258e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6562/10000, Loss: 0.013878721743822098, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6563/10000, Loss: 0.013869975693523884, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6564/10000, Loss: 5.292994683259167e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6565/10000, Loss: 7.176362828431593e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6566/10000, Loss: 1.273136831514421e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6567/10000, Loss: 0.02774111181497574, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6568/10000, Loss: 0.013884931802749634, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6569/10000, Loss: 0.013886666856706142, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6570/10000, Loss: 4.3630512891468243e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6571/10000, Loss: 0.013909042812883854, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6572/10000, Loss: 0.01387898437678814, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6573/10000, Loss: 2.4079847662505927e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6574/10000, Loss: 1.0228037581327953e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6575/10000, Loss: 0.013906581327319145, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6576/10000, Loss: 3.528586489665031e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6577/10000, Loss: 4.291529478450684e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6578/10000, Loss: 0.013890450820326805, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6579/10000, Loss: 1.7142093611255405e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6580/10000, Loss: 3.548957465682179e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6581/10000, Loss: 2.0146085262240376e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6582/10000, Loss: 1.1920920428565296e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6583/10000, Loss: 5.057695307186805e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6584/10000, Loss: 0.041614677757024765, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6585/10000, Loss: 2.0694255908892956e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6586/10000, Loss: 0.013889292255043983, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6587/10000, Loss: 0.013891072012484074, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6588/10000, Loss: 0.013875863514840603, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6589/10000, Loss: 0.013915149495005608, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6590/10000, Loss: 1.3708655615118914e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6591/10000, Loss: 0.013904386200010777, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6592/10000, Loss: 4.768039616465103e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6593/10000, Loss: 8.010778174138977e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6594/10000, Loss: 0.013893439434468746, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6595/10000, Loss: 0.027815692126750946, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6596/10000, Loss: 8.869084240359371e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6597/10000, Loss: 8.368448334294953e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6598/10000, Loss: 5.857578798895702e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6599/10000, Loss: 0.027739491313695908, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6600/10000, Loss: 1.6045445363488398e-06, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 6600: 0.3373940019130709\n",
            "Epoch 6601/10000, Loss: 1.770506969478447e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6602/10000, Loss: 2.601105279609328e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6603/10000, Loss: 2.1385790205386e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6604/10000, Loss: 3.0517543336827657e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6605/10000, Loss: 1.7762295101420023e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6606/10000, Loss: 3.419293716433458e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6607/10000, Loss: 3.194805344719498e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6608/10000, Loss: 0.013869291171431541, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6609/10000, Loss: 4.434272341313772e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6610/10000, Loss: 0.013880675658583641, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6611/10000, Loss: 3.3988057111855596e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6612/10000, Loss: 0.0138936098664999, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6613/10000, Loss: 0.01386477891355753, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6614/10000, Loss: 2.2339470433507813e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6615/10000, Loss: 3.348501559230499e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6616/10000, Loss: 0.027780681848526, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6617/10000, Loss: 0.013875458389520645, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6618/10000, Loss: 1.5997625268937554e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6619/10000, Loss: 3.6001131320517743e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6620/10000, Loss: 3.9100541471270844e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6621/10000, Loss: 0.027740592136979103, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6622/10000, Loss: 5.035807771491818e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6623/10000, Loss: 9.727401675263536e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6624/10000, Loss: 5.841231995873386e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6625/10000, Loss: 1.7805014067562297e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6626/10000, Loss: 0.013890395872294903, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6627/10000, Loss: 0.027739793062210083, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6628/10000, Loss: 1.7427971670258557e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6629/10000, Loss: 1.547311853755673e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6630/10000, Loss: 0.013879969716072083, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6631/10000, Loss: 3.5044640753767453e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6632/10000, Loss: 0.01390625350177288, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6633/10000, Loss: 0.027745118364691734, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6634/10000, Loss: 0.013890592381358147, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6635/10000, Loss: 3.051751775728917e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6636/10000, Loss: 0.013878011144697666, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6637/10000, Loss: 0.01388875488191843, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6638/10000, Loss: 9.131389901995135e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6639/10000, Loss: 0.013884130865335464, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6640/10000, Loss: 6.008125978951284e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6641/10000, Loss: 0.013869120739400387, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6642/10000, Loss: 3.3592823456274346e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6643/10000, Loss: 3.230497441109037e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6644/10000, Loss: 4.89443891638075e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6645/10000, Loss: 0.013888318091630936, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6646/10000, Loss: 0.013876852579414845, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6647/10000, Loss: 0.013880271464586258, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6648/10000, Loss: 0.013892932794988155, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6649/10000, Loss: 1.883505262867402e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6650/10000, Loss: 0.013882040977478027, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6651/10000, Loss: 0.013866366818547249, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6652/10000, Loss: 0.013879483565688133, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6653/10000, Loss: 4.868196811003145e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6654/10000, Loss: 1.0943356301140739e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6655/10000, Loss: 0.013885521329939365, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6656/10000, Loss: 0.027747591957449913, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6657/10000, Loss: 0.013872959651052952, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6658/10000, Loss: 0.04160993546247482, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6659/10000, Loss: 0.013873593881726265, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6660/10000, Loss: 1.74997228441498e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6661/10000, Loss: 0.013870353810489178, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6662/10000, Loss: 3.0636122119176434e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6663/10000, Loss: 4.405695108289365e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6664/10000, Loss: 8.988300805867766e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6665/10000, Loss: 8.845191814543796e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6666/10000, Loss: 3.967007614846807e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6667/10000, Loss: 0.013868636451661587, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6668/10000, Loss: 2.5605613700463437e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6669/10000, Loss: 0.027738260105252266, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6670/10000, Loss: 3.905021912942175e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6671/10000, Loss: 4.3868917032341415e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6672/10000, Loss: 1.8822709535015747e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6673/10000, Loss: 5.745866360484797e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6674/10000, Loss: 0.027738848701119423, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6675/10000, Loss: 1.9120709112030454e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6676/10000, Loss: 9.775011449164595e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6677/10000, Loss: 0.013883301988244057, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6678/10000, Loss: 1.2922138239446213e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6679/10000, Loss: 0.013899787329137325, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6680/10000, Loss: 2.7489049898576923e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6681/10000, Loss: 0.013887684792280197, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6682/10000, Loss: 0.013885163702070713, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6683/10000, Loss: 1.5973840845617815e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6684/10000, Loss: 1.8078766515827738e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6685/10000, Loss: 1.2159273410361493e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6686/10000, Loss: 0.0138925239443779, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6687/10000, Loss: 0.027821587398648262, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6688/10000, Loss: 0.013889841735363007, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6689/10000, Loss: 3.3133404940599576e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6690/10000, Loss: 0.01393401250243187, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6691/10000, Loss: 1.3732761772189406e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6692/10000, Loss: 0.013879001140594482, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6693/10000, Loss: 0.013908756896853447, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6694/10000, Loss: 0.013894283212721348, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6695/10000, Loss: 0.013896814547479153, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6696/10000, Loss: 4.7683533921372145e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6697/10000, Loss: 0.013883830048143864, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6698/10000, Loss: 1.3828068858856568e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6699/10000, Loss: 1.8191127537647844e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6700/10000, Loss: 8.416129162469588e-07, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 6700: 0.3383530018568041\n",
            "Epoch 6701/10000, Loss: 0.013884532265365124, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6702/10000, Loss: 3.2985786674544215e-05, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6703/10000, Loss: 2.7894918730453355e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6704/10000, Loss: 0.027737975120544434, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6705/10000, Loss: 0.013902084901928902, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6706/10000, Loss: 1.311301218720473e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6707/10000, Loss: 1.890355270006694e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6708/10000, Loss: 0.013888491317629814, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6709/10000, Loss: 2.410361730653676e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6710/10000, Loss: 1.9079952835454606e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6711/10000, Loss: 3.409382429708785e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6712/10000, Loss: 0.013896934688091278, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6713/10000, Loss: 2.5677175017335685e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6714/10000, Loss: 1.2135408269386971e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6715/10000, Loss: 0.01388072595000267, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6716/10000, Loss: 4.7013327275635675e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6717/10000, Loss: 0.013867503963410854, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6718/10000, Loss: 6.890266490700014e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6719/10000, Loss: 1.0394978744443506e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6720/10000, Loss: 3.528174784150906e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6721/10000, Loss: 2.5796368845476536e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6722/10000, Loss: 0.01388196088373661, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6723/10000, Loss: 0.027816161513328552, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6724/10000, Loss: 0.013865971006453037, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6725/10000, Loss: 4.2915252151942695e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6726/10000, Loss: 0.01391547080129385, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6727/10000, Loss: 0.01388773787766695, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6728/10000, Loss: 1.0037254014605423e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6729/10000, Loss: 0.013867778703570366, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6730/10000, Loss: 1.80002848537697e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6731/10000, Loss: 0.02778378129005432, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6732/10000, Loss: 6.89026023792394e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6733/10000, Loss: 0.013879849575459957, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6734/10000, Loss: 1.8211952919955365e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6735/10000, Loss: 3.1471208217226376e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6736/10000, Loss: 8.153871817739855e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6737/10000, Loss: 7.772394496896595e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6738/10000, Loss: 3.750063115148805e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6739/10000, Loss: 4.792192953573249e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6740/10000, Loss: 0.027792440727353096, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6741/10000, Loss: 2.5486378945061006e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6742/10000, Loss: 0.013892997056245804, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6743/10000, Loss: 0.013874041847884655, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6744/10000, Loss: 2.484266133251367e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6745/10000, Loss: 3.1806288461666554e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6746/10000, Loss: 4.81602967283834e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6747/10000, Loss: 0.027738220989704132, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6748/10000, Loss: 5.086937380838208e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6749/10000, Loss: 0.013883620500564575, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6750/10000, Loss: 1.494867888141016e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6751/10000, Loss: 0.013878567144274712, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6752/10000, Loss: 1.9389586668694392e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6753/10000, Loss: 3.1815892725717276e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6754/10000, Loss: 0.01388534251600504, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6755/10000, Loss: 6.866417834316962e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6756/10000, Loss: 4.792204322257021e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6757/10000, Loss: 3.8144385143823456e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6758/10000, Loss: 0.013883373700082302, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6759/10000, Loss: 0.013870819471776485, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6760/10000, Loss: 0.04161348566412926, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6761/10000, Loss: 3.337057933094911e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6762/10000, Loss: 0.01387692429125309, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6763/10000, Loss: 0.013874828815460205, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6764/10000, Loss: 0.013860074803233147, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6765/10000, Loss: 0.013876661658287048, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6766/10000, Loss: 8.29691771286889e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6767/10000, Loss: 0.013880479149520397, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6768/10000, Loss: 0.02774050086736679, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6769/10000, Loss: 1.9754268578253686e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6770/10000, Loss: 2.4318223950103857e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6771/10000, Loss: 1.4018854699315852e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6772/10000, Loss: 1.947295641002711e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6773/10000, Loss: 8.725990028324304e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6774/10000, Loss: 2.3078557660483057e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6775/10000, Loss: 7.653192710677104e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6776/10000, Loss: 1.2588416211656295e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6777/10000, Loss: 5.006788583727939e-08, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6778/10000, Loss: 0.027801185846328735, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6779/10000, Loss: 0.013855061493813992, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6780/10000, Loss: 0.013892017304897308, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6781/10000, Loss: 0.013888384215533733, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6782/10000, Loss: 0.013876141980290413, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6783/10000, Loss: 2.6607046947901836e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6784/10000, Loss: 0.013882813975214958, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6785/10000, Loss: 1.8912594896391965e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6786/10000, Loss: 0.013880092650651932, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6787/10000, Loss: 0.013871793635189533, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6788/10000, Loss: 0.013887746259570122, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6789/10000, Loss: 0.02773747220635414, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6790/10000, Loss: 0.013891737908124924, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6791/10000, Loss: 2.319766053915373e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6792/10000, Loss: 0.01392148807644844, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6793/10000, Loss: 0.013862228021025658, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6794/10000, Loss: 5.1439514209050685e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6795/10000, Loss: 6.461111183853063e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6796/10000, Loss: 3.1823637982597575e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6797/10000, Loss: 2.76565288004349e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6798/10000, Loss: 1.3494402537617134e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6799/10000, Loss: 4.6968168021521706e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6800/10000, Loss: 7.128684273993713e-07, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 6800: 0.33931200180053733\n",
            "Epoch 6801/10000, Loss: 1.7070574358513113e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6802/10000, Loss: 1.4447989542532014e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6803/10000, Loss: 0.013889390043914318, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6804/10000, Loss: 1.9911438357667066e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6805/10000, Loss: 0.01387923676520586, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6806/10000, Loss: 4.570191777020227e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6807/10000, Loss: 0.013879065401852131, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6808/10000, Loss: 1.7261065750062698e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6809/10000, Loss: 0.013877968303859234, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6810/10000, Loss: 1.3971139196655713e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6811/10000, Loss: 1.0251930007143528e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6812/10000, Loss: 0.013882101513445377, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6813/10000, Loss: 5.936599336564541e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6814/10000, Loss: 4.291516404464346e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6815/10000, Loss: 0.027796560898423195, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6816/10000, Loss: 5.382127346820198e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6817/10000, Loss: 0.013891124166548252, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6818/10000, Loss: 3.1881092581897974e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6819/10000, Loss: 7.510134309995919e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6820/10000, Loss: 0.013893650844693184, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6821/10000, Loss: 1.9210488972021267e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6822/10000, Loss: 3.862375876906299e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6823/10000, Loss: 1.7237472320630332e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6824/10000, Loss: 0.013917224481701851, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6825/10000, Loss: 8.58297653394402e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6826/10000, Loss: 3.314478090032935e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6827/10000, Loss: 2.3201293515739962e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6828/10000, Loss: 0.027757816016674042, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6829/10000, Loss: 0.013897842727601528, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6830/10000, Loss: 0.013868423178792, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6831/10000, Loss: 3.2587100577075034e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6832/10000, Loss: 4.946903118252521e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6833/10000, Loss: 0.0138619439676404, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6834/10000, Loss: 0.013884071260690689, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6835/10000, Loss: 0.04161538556218147, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6836/10000, Loss: 4.7445226414311037e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6837/10000, Loss: 2.1647949779435294e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6838/10000, Loss: 0.01387383695691824, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6839/10000, Loss: 0.013886774890124798, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6840/10000, Loss: 0.027813095599412918, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6841/10000, Loss: 0.013894553296267986, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6842/10000, Loss: 0.02779279462993145, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6843/10000, Loss: 2.9420032205962343e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6844/10000, Loss: 0.013889615423977375, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6845/10000, Loss: 1.380427988806332e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6846/10000, Loss: 6.62800573536515e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6847/10000, Loss: 0.013923757709562778, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6848/10000, Loss: 0.013902201317250729, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6849/10000, Loss: 3.29017183275937e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6850/10000, Loss: 1.528241227788385e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6851/10000, Loss: 4.069705482834252e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6852/10000, Loss: 2.031893927778583e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6853/10000, Loss: 0.013892527669668198, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6854/10000, Loss: 1.270757593374583e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6855/10000, Loss: 0.02773931995034218, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6856/10000, Loss: 0.013869622722268105, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6857/10000, Loss: 0.02774583362042904, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6858/10000, Loss: 1.1205509053979767e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6859/10000, Loss: 2.098062395816669e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6860/10000, Loss: 0.01390083972364664, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6861/10000, Loss: 2.224987474619411e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6862/10000, Loss: 2.1000832930440083e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6863/10000, Loss: 9.274361900679651e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6864/10000, Loss: 0.013890745118260384, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6865/10000, Loss: 0.013880903832614422, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6866/10000, Loss: 7.510093951168528e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6867/10000, Loss: 0.013888359069824219, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6868/10000, Loss: 0.013913041912019253, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6869/10000, Loss: 3.314004572985141e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6870/10000, Loss: 1.7261086213693488e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6871/10000, Loss: 0.013899226672947407, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6872/10000, Loss: 0.01388830877840519, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6873/10000, Loss: 7.820092946531076e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6874/10000, Loss: 5.483600489242235e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6875/10000, Loss: 2.0503537143667927e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6876/10000, Loss: 1.1825487717942451e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6877/10000, Loss: 1.7857144030131167e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6878/10000, Loss: 1.6593744476267602e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6879/10000, Loss: 0.013871257193386555, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6880/10000, Loss: 0.027737628668546677, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6881/10000, Loss: 0.013876893557608128, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6882/10000, Loss: 3.7693178001063643e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6883/10000, Loss: 0.027801288291811943, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6884/10000, Loss: 0.027807649224996567, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6885/10000, Loss: 1.0323358310415642e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6886/10000, Loss: 0.01386663131415844, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6887/10000, Loss: 4.982931613994879e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6888/10000, Loss: 7.36709012016945e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6889/10000, Loss: 9.751212246555951e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6890/10000, Loss: 0.013918140903115273, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6891/10000, Loss: 9.369708777740016e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6892/10000, Loss: 1.6235869679803727e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6893/10000, Loss: 0.013877514749765396, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6894/10000, Loss: 0.013915824703872204, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6895/10000, Loss: 0.013865032233297825, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6896/10000, Loss: 9.155216389444831e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6897/10000, Loss: 3.826355168712325e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6898/10000, Loss: 1.2755227771776845e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6899/10000, Loss: 5.128083557792706e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6900/10000, Loss: 0.013890394009649754, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 6900: 0.34027100174427055\n",
            "Epoch 6901/10000, Loss: 2.9325408945624076e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6902/10000, Loss: 3.0994362987257773e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6903/10000, Loss: 1.8977841591549804e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6904/10000, Loss: 9.393623372488946e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6905/10000, Loss: 0.027794599533081055, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6906/10000, Loss: 1.454352798191394e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6907/10000, Loss: 2.086139602397452e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6908/10000, Loss: 0.013869882561266422, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6909/10000, Loss: 2.0063802367076278e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6910/10000, Loss: 1.2969799172424246e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6911/10000, Loss: 0.027740446850657463, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6912/10000, Loss: 7.629285505572625e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6913/10000, Loss: 3.142210698570125e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6914/10000, Loss: 0.013876311480998993, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6915/10000, Loss: 6.961789154047437e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6916/10000, Loss: 0.013882424682378769, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6917/10000, Loss: 0.013868710957467556, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6918/10000, Loss: 0.013857750222086906, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6919/10000, Loss: 0.01387085672467947, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6920/10000, Loss: 0.027737366035580635, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6921/10000, Loss: 0.013871584087610245, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6922/10000, Loss: 1.051414301400655e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6923/10000, Loss: 0.013878168538212776, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6924/10000, Loss: 0.027737081050872803, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6925/10000, Loss: 4.255498424754478e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6926/10000, Loss: 1.8778770026983693e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6927/10000, Loss: 0.02773687243461609, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6928/10000, Loss: 4.48225137006375e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6929/10000, Loss: 2.1337943962862482e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6930/10000, Loss: 3.671640342872706e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6931/10000, Loss: 2.2434630864154315e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6932/10000, Loss: 2.694126521873841e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6933/10000, Loss: 3.17585509037599e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6934/10000, Loss: 0.013899254612624645, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6935/10000, Loss: 1.951538615685422e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6936/10000, Loss: 0.013896393589675426, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6937/10000, Loss: 4.148469372466934e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6938/10000, Loss: 0.027737446129322052, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6939/10000, Loss: 4.546370291791391e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6940/10000, Loss: 0.01386146992444992, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6941/10000, Loss: 4.274564616935095e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6942/10000, Loss: 0.013860419392585754, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6943/10000, Loss: 1.9019538740394637e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6944/10000, Loss: 0.013854044489562511, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6945/10000, Loss: 0.027792708948254585, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6946/10000, Loss: 2.4628272967675002e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6947/10000, Loss: 0.013865070417523384, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6948/10000, Loss: 0.013883113861083984, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6949/10000, Loss: 1.223075400957896e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6950/10000, Loss: 7.629389386920593e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6951/10000, Loss: 0.013900204561650753, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6952/10000, Loss: 2.3602847250003833e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6953/10000, Loss: 1.7285144622292137e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6954/10000, Loss: 3.153697616653517e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6955/10000, Loss: 3.5855505302606616e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6956/10000, Loss: 0.013887861743569374, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6957/10000, Loss: 0.02773841843008995, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6958/10000, Loss: 1.959651490324177e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6959/10000, Loss: 2.5391188955836697e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6960/10000, Loss: 8.344564434992208e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6961/10000, Loss: 0.02782389149069786, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6962/10000, Loss: 0.027852633967995644, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6963/10000, Loss: 2.138570152965258e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6964/10000, Loss: 0.041600216180086136, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6965/10000, Loss: 3.40435394718952e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6966/10000, Loss: 0.013860401697456837, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6967/10000, Loss: 0.013883059844374657, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6968/10000, Loss: 3.0058947231736965e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6969/10000, Loss: 4.1484773305455747e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6970/10000, Loss: 4.625295559890219e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6971/10000, Loss: 0.013863291591405869, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6972/10000, Loss: 2.0085284631932154e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6973/10000, Loss: 0.013881426304578781, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6974/10000, Loss: 0.013874313794076443, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6975/10000, Loss: 3.719321455264435e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6976/10000, Loss: 0.013882088474929333, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6977/10000, Loss: 0.013879484497010708, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6978/10000, Loss: 0.01389063335955143, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6979/10000, Loss: 5.555113489208452e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6980/10000, Loss: 0.0138770816847682, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6981/10000, Loss: 0.0138902198523283, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6982/10000, Loss: 0.01389912236481905, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6983/10000, Loss: 2.462808652126114e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6984/10000, Loss: 6.151168463475187e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6985/10000, Loss: 2.2339252154779388e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6986/10000, Loss: 1.8215024510936928e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6987/10000, Loss: 0.013860302977263927, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6988/10000, Loss: 2.598754633709177e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6989/10000, Loss: 0.027737312018871307, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6990/10000, Loss: 0.013877342455089092, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6991/10000, Loss: 5.245181000645971e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 6992/10000, Loss: 6.937934813322499e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6993/10000, Loss: 0.013877274468541145, Train Accuracy: 0.9879999756813049\n",
            "Epoch 6994/10000, Loss: 0.013901735655963421, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6995/10000, Loss: 0.02779620885848999, Train Accuracy: 0.9900000095367432\n",
            "Epoch 6996/10000, Loss: 0.013906080275774002, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6997/10000, Loss: 0.027772633358836174, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6998/10000, Loss: 0.027736544609069824, Train Accuracy: 0.9940000176429749\n",
            "Epoch 6999/10000, Loss: 0.01387773733586073, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7000/10000, Loss: 3.3948185773624573e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 7000: 0.34123000168800377\n",
            "Epoch 7001/10000, Loss: 0.013898811303079128, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7002/10000, Loss: 1.2159166544734035e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7003/10000, Loss: 1.3375116623137728e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7004/10000, Loss: 5.793543209620111e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7005/10000, Loss: 1.466236653868691e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7006/10000, Loss: 1.6593738791925716e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7007/10000, Loss: 1.175386614704621e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7008/10000, Loss: 1.7642952343521756e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7009/10000, Loss: 2.5414851734240074e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7010/10000, Loss: 4.935239985570661e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7011/10000, Loss: 1.4614889778385987e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7012/10000, Loss: 0.013880190439522266, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7013/10000, Loss: 0.01387617364525795, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7014/10000, Loss: 4.1007834283846023e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7015/10000, Loss: 0.013890608213841915, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7016/10000, Loss: 0.0138584328815341, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7017/10000, Loss: 2.9987897505634464e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7018/10000, Loss: 3.110125180683099e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7019/10000, Loss: 0.013883923180401325, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7020/10000, Loss: 0.013876048848032951, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7021/10000, Loss: 3.218647464109381e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7022/10000, Loss: 0.013897454366087914, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7023/10000, Loss: 1.2230681250002817e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7024/10000, Loss: 5.819481884827837e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7025/10000, Loss: 2.0622671854653163e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7026/10000, Loss: 6.365735885083268e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7027/10000, Loss: 0.013871957547962666, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7028/10000, Loss: 0.013884280808269978, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7029/10000, Loss: 5.812338713440113e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7030/10000, Loss: 0.013872501440346241, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7031/10000, Loss: 0.013878552243113518, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7032/10000, Loss: 6.604165605494927e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7033/10000, Loss: 0.027737723663449287, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7034/10000, Loss: 0.027738060802221298, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7035/10000, Loss: 8.320751589963038e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7036/10000, Loss: 0.01387525163590908, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7037/10000, Loss: 0.02773718535900116, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7038/10000, Loss: 9.441321822123427e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7039/10000, Loss: 0.013868795707821846, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7040/10000, Loss: 5.523847448785091e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7041/10000, Loss: 0.013882298953831196, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7042/10000, Loss: 0.013893302530050278, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7043/10000, Loss: 0.027737297117710114, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7044/10000, Loss: 4.482260465010768e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7045/10000, Loss: 0.01388588733971119, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7046/10000, Loss: 3.104431016254239e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7047/10000, Loss: 2.193447983245278e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7048/10000, Loss: 1.4161679473545519e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7049/10000, Loss: 0.013883143663406372, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7050/10000, Loss: 9.679740742285503e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7051/10000, Loss: 9.274422154703643e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7052/10000, Loss: 0.013923779129981995, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7053/10000, Loss: 0.027738021686673164, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7054/10000, Loss: 0.027737125754356384, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7055/10000, Loss: 2.988585583807435e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7056/10000, Loss: 0.01387781836092472, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7057/10000, Loss: 7.462472240149509e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7058/10000, Loss: 0.013911280781030655, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7059/10000, Loss: 0.01387821789830923, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7060/10000, Loss: 0.013893315568566322, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7061/10000, Loss: 0.013895820826292038, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7062/10000, Loss: 5.316708779901091e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7063/10000, Loss: 4.348471520643216e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7064/10000, Loss: 0.013876831158995628, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7065/10000, Loss: 0.027789371088147163, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7066/10000, Loss: 0.027807433158159256, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7067/10000, Loss: 0.013892106711864471, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7068/10000, Loss: 4.1961615693253407e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7069/10000, Loss: 4.298410203773528e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7070/10000, Loss: 1.7881383485018887e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7071/10000, Loss: 2.2840217752673198e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7072/10000, Loss: 0.013892443850636482, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7073/10000, Loss: 0.02773713320493698, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7074/10000, Loss: 2.1743264824181097e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7075/10000, Loss: 1.8474105672794394e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7076/10000, Loss: 0.027800854295492172, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7077/10000, Loss: 0.01386605016887188, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7078/10000, Loss: 0.013878797180950642, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7079/10000, Loss: 0.013883545063436031, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7080/10000, Loss: 9.989637419494102e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7081/10000, Loss: 0.013864951208233833, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7082/10000, Loss: 3.2534637284697965e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7083/10000, Loss: 0.013882418163120747, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7084/10000, Loss: 1.1825395631603897e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7085/10000, Loss: 3.921714323951164e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7086/10000, Loss: 0.013877034187316895, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7087/10000, Loss: 0.013883249834179878, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7088/10000, Loss: 1.4972315511840861e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7089/10000, Loss: 2.9404534870991483e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7090/10000, Loss: 0.01391095481812954, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7091/10000, Loss: 0.013879205100238323, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7092/10000, Loss: 2.1934478411367309e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7093/10000, Loss: 1.0037317679234548e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7094/10000, Loss: 3.600116826874e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7095/10000, Loss: 5.626646952805459e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7096/10000, Loss: 0.013902570120990276, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7097/10000, Loss: 0.01388393621891737, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7098/10000, Loss: 0.027774125337600708, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7099/10000, Loss: 1.8693659512791783e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7100/10000, Loss: 1.9890470866812393e-05, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 7100: 0.342189001631737\n",
            "Epoch 7101/10000, Loss: 2.1886366994294804e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7102/10000, Loss: 2.9154381991247647e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7103/10000, Loss: 0.013894205912947655, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7104/10000, Loss: 0.013913096860051155, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7105/10000, Loss: 0.027790652588009834, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7106/10000, Loss: 0.02773788385093212, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7107/10000, Loss: 0.013906857930123806, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7108/10000, Loss: 2.100443225572235e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7109/10000, Loss: 7.128671200007375e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7110/10000, Loss: 2.9323724447749555e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7111/10000, Loss: 0.027737537398934364, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7112/10000, Loss: 1.8028542399406433e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7113/10000, Loss: 2.0980369299650192e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7114/10000, Loss: 1.549719428339813e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7115/10000, Loss: 0.013891056180000305, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7116/10000, Loss: 1.2040012506986386e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7117/10000, Loss: 2.9679031285922974e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7118/10000, Loss: 0.013882245868444443, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7119/10000, Loss: 0.013857755810022354, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7120/10000, Loss: 0.013875246047973633, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7121/10000, Loss: 0.01390528492629528, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7122/10000, Loss: 0.013894367031753063, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7123/10000, Loss: 2.8930558983120136e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7124/10000, Loss: 0.027736835181713104, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7125/10000, Loss: 0.013893399387598038, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7126/10000, Loss: 1.8572633280200535e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7127/10000, Loss: 0.013892640359699726, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7128/10000, Loss: 1.4471626172962715e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7129/10000, Loss: 0.01388510037213564, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7130/10000, Loss: 0.013897557742893696, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7131/10000, Loss: 3.463947905402165e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7132/10000, Loss: 2.996534931298811e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7133/10000, Loss: 4.553754138214572e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7134/10000, Loss: 0.013895303010940552, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7135/10000, Loss: 2.7274575131741585e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7136/10000, Loss: 1.3756574617218575e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7137/10000, Loss: 0.013907428830862045, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7138/10000, Loss: 1.1586978416744387e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7139/10000, Loss: 7.343248284996662e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7140/10000, Loss: 0.02773667685687542, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7141/10000, Loss: 2.2768520011595683e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7142/10000, Loss: 1.5878458725637756e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7143/10000, Loss: 1.1110200830444228e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7144/10000, Loss: 0.013887301087379456, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7145/10000, Loss: 0.0138621861115098, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7146/10000, Loss: 0.027771655470132828, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7147/10000, Loss: 0.013877506367862225, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7148/10000, Loss: 0.013870427384972572, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7149/10000, Loss: 0.013893925584852695, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7150/10000, Loss: 0.02778543159365654, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7151/10000, Loss: 4.959090915690467e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7152/10000, Loss: 2.0503973985341872e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7153/10000, Loss: 0.01390544418245554, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7154/10000, Loss: 0.0138744181022048, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7155/10000, Loss: 0.013903041370213032, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7156/10000, Loss: 4.088602054252988e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7157/10000, Loss: 1.7576010577613488e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7158/10000, Loss: 5.578970672104333e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7159/10000, Loss: 0.01386861689388752, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7160/10000, Loss: 0.013901494443416595, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7161/10000, Loss: 0.013877720572054386, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7162/10000, Loss: 0.027765611186623573, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7163/10000, Loss: 2.450894044159213e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7164/10000, Loss: 0.013911581598222256, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7165/10000, Loss: 1.1205665373381635e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7166/10000, Loss: 3.494946440696367e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7167/10000, Loss: 1.0752532944025006e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7168/10000, Loss: 0.027737071737647057, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7169/10000, Loss: 1.0108813057740917e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7170/10000, Loss: 0.01385531947016716, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7171/10000, Loss: 0.01390704233199358, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7172/10000, Loss: 1.2302235745664802e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7173/10000, Loss: 0.013887017965316772, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7174/10000, Loss: 0.013888223096728325, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7175/10000, Loss: 0.027741119265556335, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7176/10000, Loss: 2.9090959287714213e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7177/10000, Loss: 0.013858388178050518, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7178/10000, Loss: 0.013868672773241997, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7179/10000, Loss: 2.8726208256557584e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7180/10000, Loss: 0.013917732983827591, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7181/10000, Loss: 0.013918831944465637, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7182/10000, Loss: 0.013878525234758854, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7183/10000, Loss: 0.027735907584428787, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7184/10000, Loss: 2.0360664620966418e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7185/10000, Loss: 5.054432108408946e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7186/10000, Loss: 2.880982901842799e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7187/10000, Loss: 0.013881871476769447, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7188/10000, Loss: 0.013908830471336842, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7189/10000, Loss: 6.58031922284863e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7190/10000, Loss: 0.013871018774807453, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7191/10000, Loss: 9.465145467402181e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7192/10000, Loss: 0.013862662017345428, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7193/10000, Loss: 8.726039482098713e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7194/10000, Loss: 0.013907169923186302, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7195/10000, Loss: 1.6901627532206476e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7196/10000, Loss: 3.38553292067445e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7197/10000, Loss: 1.1753921853596694e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7198/10000, Loss: 0.027767177671194077, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7199/10000, Loss: 6.67571669055178e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7200/10000, Loss: 0.01387800183147192, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 7200: 0.3431480015754702\n",
            "Epoch 7201/10000, Loss: 6.747158067810233e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7202/10000, Loss: 0.013919715769588947, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7203/10000, Loss: 5.459759222503635e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7204/10000, Loss: 8.63063064571179e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7205/10000, Loss: 2.8392769308993593e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7206/10000, Loss: 1.1539309525687713e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7207/10000, Loss: 0.04161044955253601, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7208/10000, Loss: 0.027736077085137367, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7209/10000, Loss: 0.013880597427487373, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7210/10000, Loss: 1.547309352645243e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7211/10000, Loss: 3.2138163078343496e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7212/10000, Loss: 5.19751097272092e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7213/10000, Loss: 9.846620514508686e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7214/10000, Loss: 0.013899778947234154, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7215/10000, Loss: 0.027812838554382324, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7216/10000, Loss: 0.027744131162762642, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7217/10000, Loss: 0.013860548846423626, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7218/10000, Loss: 4.715616341854911e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7219/10000, Loss: 0.013886824250221252, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7220/10000, Loss: 0.027736438438296318, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7221/10000, Loss: 1.442392886019661e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7222/10000, Loss: 1.7481248505646363e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7223/10000, Loss: 0.013901500031352043, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7224/10000, Loss: 0.013933554291725159, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7225/10000, Loss: 0.013874697498977184, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7226/10000, Loss: 3.647785149496485e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7227/10000, Loss: 3.140426633763127e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7228/10000, Loss: 3.067950456170365e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7229/10000, Loss: 2.5987594653997803e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7230/10000, Loss: 0.013917539268732071, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7231/10000, Loss: 0.013886792585253716, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7232/10000, Loss: 0.013870500959455967, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7233/10000, Loss: 3.5020977975364076e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7234/10000, Loss: 3.1948019341143663e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7235/10000, Loss: 0.013875533826649189, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7236/10000, Loss: 0.01388839352875948, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7237/10000, Loss: 3.623938198415999e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7238/10000, Loss: 0.013883935287594795, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7239/10000, Loss: 2.968254875668208e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7240/10000, Loss: 2.8302734790486284e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7241/10000, Loss: 3.169744377373718e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7242/10000, Loss: 5.626656616186665e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7243/10000, Loss: 4.4345640048959467e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7244/10000, Loss: 1.1610882211243734e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7245/10000, Loss: 0.013858523219823837, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7246/10000, Loss: 0.013880289159715176, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7247/10000, Loss: 2.415127710264642e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7248/10000, Loss: 1.382826582130292e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7249/10000, Loss: 1.9073470980401908e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7250/10000, Loss: 2.8357613700791262e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7251/10000, Loss: 7.77235982241109e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7252/10000, Loss: 0.013889878988265991, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7253/10000, Loss: 0.013866924680769444, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7254/10000, Loss: 4.7683579396107234e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7255/10000, Loss: 0.013868584297597408, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7256/10000, Loss: 0.027781261131167412, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7257/10000, Loss: 0.027764203026890755, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7258/10000, Loss: 2.8071570341126062e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7259/10000, Loss: 0.013904952444136143, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7260/10000, Loss: 0.027735764160752296, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7261/10000, Loss: 0.027795609086751938, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7262/10000, Loss: 0.02773985080420971, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7263/10000, Loss: 0.013895981013774872, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7264/10000, Loss: 4.720657216239488e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7265/10000, Loss: 2.539109800636652e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7266/10000, Loss: 4.1961550323321717e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7267/10000, Loss: 5.173672548153263e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7268/10000, Loss: 0.013895031996071339, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7269/10000, Loss: 1.652203764024307e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7270/10000, Loss: 7.438571287821105e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7271/10000, Loss: 0.027736352756619453, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7272/10000, Loss: 0.013880491256713867, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7273/10000, Loss: 0.013905980624258518, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7274/10000, Loss: 0.02776299975812435, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7275/10000, Loss: 0.027756568044424057, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7276/10000, Loss: 0.013903924264013767, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7277/10000, Loss: 0.013883234933018684, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7278/10000, Loss: 9.655816484155366e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7279/10000, Loss: 0.013887140899896622, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7280/10000, Loss: 1.0847909379663179e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7281/10000, Loss: 0.027793537825345993, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7282/10000, Loss: 1.8500880969440914e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7283/10000, Loss: 0.013871734030544758, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7284/10000, Loss: 0.01386494841426611, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7285/10000, Loss: 0.013910610228776932, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7286/10000, Loss: 1.2159340201378654e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7287/10000, Loss: 0.013879428617656231, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7288/10000, Loss: 0.027810832485556602, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7289/10000, Loss: 1.7642952343521756e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7290/10000, Loss: 0.013878684490919113, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7291/10000, Loss: 1.0013576456913142e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7292/10000, Loss: 6.008124273648718e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7293/10000, Loss: 0.013865845277905464, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7294/10000, Loss: 8.344644442104254e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7295/10000, Loss: 9.012069313030224e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7296/10000, Loss: 4.0530974843022705e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7297/10000, Loss: 0.013874287717044353, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7298/10000, Loss: 0.01393029186874628, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7299/10000, Loss: 7.772312073939247e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7300/10000, Loss: 0.01393040269613266, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 7300: 0.3441070015192034\n",
            "Epoch 7301/10000, Loss: 4.506097184275859e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7302/10000, Loss: 8.39229528537544e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7303/10000, Loss: 0.013881080783903599, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7304/10000, Loss: 0.02775242179632187, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7305/10000, Loss: 0.013875549659132957, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7306/10000, Loss: 3.0618455639341846e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7307/10000, Loss: 0.013898219913244247, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7308/10000, Loss: 3.027910508990317e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7309/10000, Loss: 1.3756431371803046e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7310/10000, Loss: 0.013889177702367306, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7311/10000, Loss: 1.9311882226702437e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7312/10000, Loss: 0.02773739956319332, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7313/10000, Loss: 1.4447830380959203e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7314/10000, Loss: 0.01390556525439024, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7315/10000, Loss: 5.841186521138297e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7316/10000, Loss: 0.013904119841754436, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7317/10000, Loss: 0.013864859938621521, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7318/10000, Loss: 1.5439056369359605e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7319/10000, Loss: 2.0217416931700427e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7320/10000, Loss: 0.013862846419215202, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7321/10000, Loss: 0.013887708075344563, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7322/10000, Loss: 3.552167299858411e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7323/10000, Loss: 3.559321612556232e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7324/10000, Loss: 4.577353593049338e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7325/10000, Loss: 1.5255558537319303e-05, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7326/10000, Loss: 0.013863799162209034, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7327/10000, Loss: 0.027736777439713478, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7328/10000, Loss: 0.013901427388191223, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7329/10000, Loss: 1.640001210034825e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7330/10000, Loss: 9.727335736897658e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7331/10000, Loss: 0.013864979147911072, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7332/10000, Loss: 1.07287269202061e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7333/10000, Loss: 1.9120750494039385e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7334/10000, Loss: 2.000297399717965e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7335/10000, Loss: 0.013866796158254147, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7336/10000, Loss: 2.2840035853732843e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7337/10000, Loss: 0.02773597463965416, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7338/10000, Loss: 9.84663074632408e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7339/10000, Loss: 1.5735294027763302e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7340/10000, Loss: 2.59394232671184e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7341/10000, Loss: 9.918120440488565e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7342/10000, Loss: 3.3140096888928383e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7343/10000, Loss: 0.01388759259134531, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7344/10000, Loss: 0.013874080032110214, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7345/10000, Loss: 0.013901515863835812, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7346/10000, Loss: 0.02773871086537838, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7347/10000, Loss: 0.041673097759485245, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7348/10000, Loss: 1.716612274549334e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7349/10000, Loss: 5.423723450803664e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7350/10000, Loss: 0.013892266899347305, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7351/10000, Loss: 2.861012831090193e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7352/10000, Loss: 1.084795371752989e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7353/10000, Loss: 1.4829287238171673e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7354/10000, Loss: 0.013869845308363438, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7355/10000, Loss: 0.027794692665338516, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7356/10000, Loss: 1.3112721717334352e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7357/10000, Loss: 3.036401903955266e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7358/10000, Loss: 2.486659695932758e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7359/10000, Loss: 0.013880036771297455, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7360/10000, Loss: 0.013892672955989838, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7361/10000, Loss: 0.04162359982728958, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7362/10000, Loss: 0.013888577930629253, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7363/10000, Loss: 1.5415709640365094e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7364/10000, Loss: 1.533463000669144e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7365/10000, Loss: 0.01387965027242899, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7366/10000, Loss: 0.013889417052268982, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7367/10000, Loss: 3.4973454603459686e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7368/10000, Loss: 0.013869022950530052, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7369/10000, Loss: 0.02775096334517002, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7370/10000, Loss: 0.013860209845006466, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7371/10000, Loss: 3.2424824780719064e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7372/10000, Loss: 4.3392057591518096e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7373/10000, Loss: 0.013874795287847519, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7374/10000, Loss: 2.8657370876317145e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7375/10000, Loss: 0.0138736916705966, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7376/10000, Loss: 1.2921977941005025e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7377/10000, Loss: 1.5480201909667812e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7378/10000, Loss: 0.013864421285688877, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7379/10000, Loss: 5.984283575344307e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7380/10000, Loss: 3.5762684547080426e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7381/10000, Loss: 1.5353840581155964e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7382/10000, Loss: 2.3245386273629265e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7383/10000, Loss: 1.5782992477397784e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7384/10000, Loss: 2.7560921807889827e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7385/10000, Loss: 1.6641281490592519e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7386/10000, Loss: 0.013903715647757053, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7387/10000, Loss: 0.013895653188228607, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7388/10000, Loss: 0.013909503817558289, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7389/10000, Loss: 1.4421743799175601e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7390/10000, Loss: 0.013884933665394783, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7391/10000, Loss: 0.013856349512934685, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7392/10000, Loss: 0.013897010125219822, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7393/10000, Loss: 0.013898752629756927, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7394/10000, Loss: 2.8149914214736782e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7395/10000, Loss: 0.013896388933062553, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7396/10000, Loss: 1.5089356566022616e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7397/10000, Loss: 1.9478434296615887e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7398/10000, Loss: 9.202827300214267e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7399/10000, Loss: 0.041636861860752106, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7400/10000, Loss: 1.52584686929913e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 7400: 0.34506600146293664\n",
            "Epoch 7401/10000, Loss: 1.5401694781758124e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7402/10000, Loss: 0.013876733370125294, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7403/10000, Loss: 0.027818305417895317, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7404/10000, Loss: 0.013889172114431858, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7405/10000, Loss: 0.04159639775753021, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7406/10000, Loss: 0.013858562335371971, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7407/10000, Loss: 6.24654092007404e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7408/10000, Loss: 5.221347691986011e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7409/10000, Loss: 1.4486352483800147e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7410/10000, Loss: 0.013878272846341133, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7411/10000, Loss: 2.0265555633613985e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7412/10000, Loss: 1.0466449111845577e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7413/10000, Loss: 1.380431285724626e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7414/10000, Loss: 1.2802918263332685e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7415/10000, Loss: 1.382799041493854e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7416/10000, Loss: 0.013871555216610432, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7417/10000, Loss: 0.01389144267886877, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7418/10000, Loss: 9.059844501280168e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7419/10000, Loss: 2.7103718821308576e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7420/10000, Loss: 1.83339977866126e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7421/10000, Loss: 4.339197801073169e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7422/10000, Loss: 6.031975203768525e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7423/10000, Loss: 0.013887312263250351, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7424/10000, Loss: 3.337849818763061e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7425/10000, Loss: 1.327977088294574e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7426/10000, Loss: 0.027738358825445175, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7427/10000, Loss: 0.013873618096113205, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7428/10000, Loss: 1.0013429800892482e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7429/10000, Loss: 2.884850687223661e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7430/10000, Loss: 3.433213180414896e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7431/10000, Loss: 0.02779413014650345, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7432/10000, Loss: 5.578955892815429e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7433/10000, Loss: 3.6261033073969884e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7434/10000, Loss: 0.013884702697396278, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7435/10000, Loss: 0.027735279873013496, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7436/10000, Loss: 3.409366797768598e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7437/10000, Loss: 0.02778720296919346, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7438/10000, Loss: 2.6267176508554257e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7439/10000, Loss: 0.013903170824050903, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7440/10000, Loss: 1.2039853345413576e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7441/10000, Loss: 0.013887752778828144, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7442/10000, Loss: 0.01387601438909769, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7443/10000, Loss: 1.1682505629551088e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7444/10000, Loss: 2.5914443540386856e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7445/10000, Loss: 0.01388990692794323, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7446/10000, Loss: 5.674306180480926e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7447/10000, Loss: 2.1362013740144903e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7448/10000, Loss: 5.531272222469852e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7449/10000, Loss: 7.057146831357386e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7450/10000, Loss: 4.4107218855060637e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7451/10000, Loss: 7.295571435861348e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7452/10000, Loss: 0.027735993266105652, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7453/10000, Loss: 1.9073470980401908e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7454/10000, Loss: 7.486269737455586e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7455/10000, Loss: 2.882431090256432e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7456/10000, Loss: 2.646442567311169e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7457/10000, Loss: 0.04161638766527176, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7458/10000, Loss: 0.02777608297765255, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7459/10000, Loss: 3.170961235809955e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7460/10000, Loss: 0.013870653696358204, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7461/10000, Loss: 2.143343635907513e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7462/10000, Loss: 1.7928754232343636e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7463/10000, Loss: 0.02773815020918846, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7464/10000, Loss: 5.507429250428686e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7465/10000, Loss: 0.02773720771074295, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7466/10000, Loss: 0.013878224417567253, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7467/10000, Loss: 2.5910027034115046e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7468/10000, Loss: 0.013864581473171711, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7469/10000, Loss: 2.9564896976808086e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7470/10000, Loss: 1.1396314221201465e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7471/10000, Loss: 3.791277777054347e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7472/10000, Loss: 1.1515356845848146e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7473/10000, Loss: 0.02773510478436947, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7474/10000, Loss: 8.416055834459257e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7475/10000, Loss: 2.0002935343654826e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7476/10000, Loss: 0.013880982995033264, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7477/10000, Loss: 6.222705337677326e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7478/10000, Loss: 0.02779747173190117, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7479/10000, Loss: 0.013893704861402512, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7480/10000, Loss: 3.361696201409359e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7481/10000, Loss: 0.01389695331454277, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7482/10000, Loss: 1.2159059679106576e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7483/10000, Loss: 2.5376286430400796e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7484/10000, Loss: 0.013882718048989773, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7485/10000, Loss: 0.01388076413422823, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7486/10000, Loss: 0.013879399746656418, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7487/10000, Loss: 0.027759604156017303, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7488/10000, Loss: 0.013873724266886711, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7489/10000, Loss: 0.027735067531466484, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7490/10000, Loss: 2.5211851607309654e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7491/10000, Loss: 0.013880996033549309, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7492/10000, Loss: 0.0416286326944828, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7493/10000, Loss: 0.02776988223195076, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7494/10000, Loss: 9.512818337498175e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7495/10000, Loss: 0.013895388692617416, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7496/10000, Loss: 0.013899234123528004, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7497/10000, Loss: 0.027738558128476143, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7498/10000, Loss: 7.891543418736546e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7499/10000, Loss: 3.983740498370025e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7500/10000, Loss: 0.027767548337578773, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 7500: 0.34602500140666986\n",
            "Epoch 7501/10000, Loss: 5.125978645992291e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7502/10000, Loss: 0.02774757891893387, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7503/10000, Loss: 0.013884072192013264, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7504/10000, Loss: 0.027736464515328407, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7505/10000, Loss: 0.013887468725442886, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7506/10000, Loss: 1.2720511222141795e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7507/10000, Loss: 0.013890866190195084, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7508/10000, Loss: 0.0277701523154974, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7509/10000, Loss: 0.013894414529204369, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7510/10000, Loss: 4.5654678615392186e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7511/10000, Loss: 5.960463411724959e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7512/10000, Loss: 2.932542884082068e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7513/10000, Loss: 2.4294317881867755e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7514/10000, Loss: 0.013875969685614109, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7515/10000, Loss: 0.013869840651750565, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7516/10000, Loss: 0.013864075765013695, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7517/10000, Loss: 7.152555525635762e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7518/10000, Loss: 1.406668701520175e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7519/10000, Loss: 5.722043994182968e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7520/10000, Loss: 1.3661116327057243e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7521/10000, Loss: 0.013891544193029404, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7522/10000, Loss: 0.013874460943043232, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7523/10000, Loss: 1.0490326758372248e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7524/10000, Loss: 0.04159485548734665, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7525/10000, Loss: 0.013873710297048092, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7526/10000, Loss: 1.1348446378178778e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7527/10000, Loss: 0.013874213211238384, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7528/10000, Loss: 1.4543522297572054e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7529/10000, Loss: 3.886217427861993e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7530/10000, Loss: 0.013894688338041306, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7531/10000, Loss: 3.044395270990208e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7532/10000, Loss: 0.013880318962037563, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7533/10000, Loss: 1.2778978089045268e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7534/10000, Loss: 1.1491659961393452e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7535/10000, Loss: 0.013875678181648254, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7536/10000, Loss: 0.01386820524930954, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7537/10000, Loss: 0.01389255840331316, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7538/10000, Loss: 0.027818143367767334, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7539/10000, Loss: 0.013876736164093018, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7540/10000, Loss: 0.013908377848565578, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7541/10000, Loss: 0.013883966952562332, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7542/10000, Loss: 4.959086368216958e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7543/10000, Loss: 3.263742200942943e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7544/10000, Loss: 0.027825139462947845, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7545/10000, Loss: 5.316713895808789e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7546/10000, Loss: 8.773724289312668e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7547/10000, Loss: 7.20013588306756e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7548/10000, Loss: 0.0277696680277586, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7549/10000, Loss: 0.013890190050005913, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7550/10000, Loss: 0.02773827314376831, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7551/10000, Loss: 5.006765491089027e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7552/10000, Loss: 7.796245427016402e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7553/10000, Loss: 1.9073470980401908e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7554/10000, Loss: 2.9802248491250793e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7555/10000, Loss: 0.013865415938198566, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7556/10000, Loss: 3.6952785649191355e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7557/10000, Loss: 0.013863558880984783, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7558/10000, Loss: 0.02778209187090397, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7559/10000, Loss: 0.02773507498204708, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7560/10000, Loss: 3.480905093056208e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7561/10000, Loss: 3.635088796727359e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7562/10000, Loss: 9.918109071804793e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7563/10000, Loss: 3.385528373200941e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7564/10000, Loss: 1.349101512460038e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7565/10000, Loss: 6.389558961927833e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7566/10000, Loss: 0.02773475833237171, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7567/10000, Loss: 0.02773517742753029, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7568/10000, Loss: 0.013891599141061306, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7569/10000, Loss: 1.4328710449262871e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7570/10000, Loss: 1.0490412449826181e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7571/10000, Loss: 0.013873850926756859, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7572/10000, Loss: 0.041611555963754654, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7573/10000, Loss: 1.2159340201378654e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7574/10000, Loss: 5.507456535269739e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7575/10000, Loss: 7.533939765380637e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7576/10000, Loss: 6.48492118671129e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7577/10000, Loss: 1.2351507393759675e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7578/10000, Loss: 0.01391022652387619, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7579/10000, Loss: 1.43048578138405e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7580/10000, Loss: 0.027734823524951935, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7581/10000, Loss: 0.013867375440895557, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7582/10000, Loss: 0.013906492851674557, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7583/10000, Loss: 1.811979757349036e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7584/10000, Loss: 3.359120455570519e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7585/10000, Loss: 4.2078654587385245e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7586/10000, Loss: 1.2656715625780635e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7587/10000, Loss: 2.59875150732114e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7588/10000, Loss: 2.117130406986689e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7589/10000, Loss: 1.257090571016306e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7590/10000, Loss: 0.04162347689270973, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7591/10000, Loss: 0.013892468065023422, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7592/10000, Loss: 3.3855332048915443e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7593/10000, Loss: 0.01385559607297182, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7594/10000, Loss: 0.013904129154980183, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7595/10000, Loss: 6.747194447598304e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7596/10000, Loss: 0.013855744153261185, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7597/10000, Loss: 7.343249990299228e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7598/10000, Loss: 0.013878158293664455, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7599/10000, Loss: 0.013892763294279575, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7600/10000, Loss: 0.013886045664548874, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 7600: 0.3469840013504031\n",
            "Epoch 7601/10000, Loss: 4.029256785997859e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7602/10000, Loss: 4.5299398720999307e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7603/10000, Loss: 0.013853788375854492, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7604/10000, Loss: 6.008123136780341e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7605/10000, Loss: 0.041636332869529724, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7606/10000, Loss: 0.02771424874663353, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7607/10000, Loss: 0.013878275640308857, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7608/10000, Loss: 3.704815753735602e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7609/10000, Loss: 1.0859551366593223e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7610/10000, Loss: 1.0668833965610247e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7611/10000, Loss: 0.013875052332878113, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7612/10000, Loss: 0.013880208134651184, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7613/10000, Loss: 1.1193425052624661e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7614/10000, Loss: 0.01385723426938057, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7615/10000, Loss: 2.3077667719917372e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7616/10000, Loss: 0.013900190591812134, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7617/10000, Loss: 8.821483277188236e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7618/10000, Loss: 0.013867728412151337, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7619/10000, Loss: 2.3125450752559118e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7620/10000, Loss: 0.013862254098057747, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7621/10000, Loss: 6.294198442446941e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7622/10000, Loss: 0.01389235444366932, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7623/10000, Loss: 3.7930274174868828e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7624/10000, Loss: 2.367155502724927e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7625/10000, Loss: 5.149827302375343e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7626/10000, Loss: 0.02776900865137577, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7627/10000, Loss: 0.013864477165043354, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7628/10000, Loss: 0.013877682387828827, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7629/10000, Loss: 0.013890966773033142, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7630/10000, Loss: 7.772391654725652e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7631/10000, Loss: 0.041609156876802444, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7632/10000, Loss: 1.292210640713165e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7633/10000, Loss: 0.01386194210499525, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7634/10000, Loss: 0.013892767019569874, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7635/10000, Loss: 1.5568485878247884e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7636/10000, Loss: 0.013889552094042301, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7637/10000, Loss: 0.0416158065199852, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7638/10000, Loss: 3.0634892027592286e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7639/10000, Loss: 0.01386635284870863, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7640/10000, Loss: 9.713357030705083e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7641/10000, Loss: 1.0118675163539592e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7642/10000, Loss: 0.027737202122807503, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7643/10000, Loss: 0.013888892717659473, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7644/10000, Loss: 4.873068974120542e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7645/10000, Loss: 0.027787167578935623, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7646/10000, Loss: 4.000461558462121e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7647/10000, Loss: 0.027764389291405678, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7648/10000, Loss: 2.549328019085806e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7649/10000, Loss: 1.2874595256562316e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7650/10000, Loss: 0.01388190034776926, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7651/10000, Loss: 0.027735034003853798, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7652/10000, Loss: 0.041633300483226776, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7653/10000, Loss: 0.01390051655471325, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7654/10000, Loss: 1.0681070534701576e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7655/10000, Loss: 0.01388829667121172, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7656/10000, Loss: 0.013853611424565315, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7657/10000, Loss: 1.0704753776735743e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7658/10000, Loss: 1.597403667119579e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7659/10000, Loss: 1.740453541287934e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7660/10000, Loss: 0.013884349726140499, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7661/10000, Loss: 0.013894298113882542, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7662/10000, Loss: 3.1517110983259045e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7663/10000, Loss: 0.013880003243684769, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7664/10000, Loss: 1.2257393791514914e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7665/10000, Loss: 5.221355650064652e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7666/10000, Loss: 0.01388054434210062, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7667/10000, Loss: 3.862370476781507e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7668/10000, Loss: 0.041610222309827805, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7669/10000, Loss: 0.013885438442230225, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7670/10000, Loss: 0.013889923691749573, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7671/10000, Loss: 1.0013575746370407e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7672/10000, Loss: 5.507443461283401e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7673/10000, Loss: 5.507430955731252e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7674/10000, Loss: 9.083677241505939e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7675/10000, Loss: 1.072883222263954e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7676/10000, Loss: 1.6140729712788016e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7677/10000, Loss: 9.05990376054433e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7678/10000, Loss: 2.2859556338516995e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7679/10000, Loss: 0.013853311538696289, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7680/10000, Loss: 0.02773628570139408, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7681/10000, Loss: 0.013869261369109154, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7682/10000, Loss: 0.013900136575102806, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7683/10000, Loss: 4.196159011371492e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7684/10000, Loss: 2.999134721903829e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7685/10000, Loss: 5.698161089640053e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7686/10000, Loss: 2.268805110361427e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7687/10000, Loss: 1.8358215925218246e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7688/10000, Loss: 0.013874323107302189, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7689/10000, Loss: 1.0776362842079834e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7690/10000, Loss: 0.013875225558876991, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7691/10000, Loss: 1.008502408694767e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7692/10000, Loss: 1.0681075082175084e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7693/10000, Loss: 1.0967179377985303e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7694/10000, Loss: 0.013906197622418404, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7695/10000, Loss: 4.7683579396107234e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7696/10000, Loss: 5.269035341370909e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7697/10000, Loss: 5.936565798947413e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7698/10000, Loss: 2.285038135596551e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7699/10000, Loss: 0.013877324759960175, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7700/10000, Loss: 8.345435162482318e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 7700: 0.3479430012941363\n",
            "Epoch 7701/10000, Loss: 0.013862967491149902, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7702/10000, Loss: 8.674457603774499e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7703/10000, Loss: 2.980217743697722e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7704/10000, Loss: 6.914137173907875e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7705/10000, Loss: 0.013867995701730251, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7706/10000, Loss: 0.01388366986066103, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7707/10000, Loss: 0.02773541398346424, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7708/10000, Loss: 1.3113015029375674e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7709/10000, Loss: 1.223066419697716e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7710/10000, Loss: 1.5735611214040546e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7711/10000, Loss: 9.059853596227185e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7712/10000, Loss: 0.013873951509594917, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7713/10000, Loss: 8.058505613917077e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7714/10000, Loss: 3.5762647598858166e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7715/10000, Loss: 0.01389744970947504, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7716/10000, Loss: 0.01387594174593687, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7717/10000, Loss: 0.013891601003706455, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7718/10000, Loss: 0.01387608703225851, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7719/10000, Loss: 0.027735302224755287, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7720/10000, Loss: 1.2993621112400433e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7721/10000, Loss: 5.006789294270675e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7722/10000, Loss: 0.013895312324166298, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7723/10000, Loss: 5.555115194511018e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7724/10000, Loss: 7.759103027638048e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7725/10000, Loss: 0.013893788680434227, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7726/10000, Loss: 1.0180280014537857e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7727/10000, Loss: 0.013853857293725014, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7728/10000, Loss: 2.431863492802222e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7729/10000, Loss: 0.013873704709112644, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7730/10000, Loss: 7.867766953495448e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7731/10000, Loss: 5.936597631261975e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7732/10000, Loss: 1.454351945540111e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7733/10000, Loss: 0.01388100441545248, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7734/10000, Loss: 1.1682506340093823e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7735/10000, Loss: 0.013896009884774685, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7736/10000, Loss: 0.013882971368730068, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7737/10000, Loss: 0.013898521661758423, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7738/10000, Loss: 2.6558327590464614e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7739/10000, Loss: 3.623952977704903e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7740/10000, Loss: 6.794891760364408e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7741/10000, Loss: 1.9073470980401908e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7742/10000, Loss: 0.013872768729925156, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7743/10000, Loss: 5.698179847968277e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7744/10000, Loss: 0.0138652753084898, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7745/10000, Loss: 1.8596634276946133e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7746/10000, Loss: 2.0980816373139533e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7747/10000, Loss: 3.6239489986655826e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7748/10000, Loss: 2.717959262099612e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7749/10000, Loss: 0.013885910622775555, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7750/10000, Loss: 0.01387462392449379, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7751/10000, Loss: 0.013875090517103672, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7752/10000, Loss: 3.457064963185985e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7753/10000, Loss: 1.6689293147464923e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7754/10000, Loss: 8.940647262534185e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7755/10000, Loss: 1.1634726888587466e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7756/10000, Loss: 0.013903949409723282, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7757/10000, Loss: 1.1992276540695457e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7758/10000, Loss: 0.013877345249056816, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7759/10000, Loss: 0.01388537883758545, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7760/10000, Loss: 7.709237252129242e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7761/10000, Loss: 0.013890106230974197, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7762/10000, Loss: 0.013891004025936127, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7763/10000, Loss: 0.013879737816751003, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7764/10000, Loss: 7.5018310781160835e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7765/10000, Loss: 0.013874085620045662, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7766/10000, Loss: 1.0108884680448682e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7767/10000, Loss: 6.818710289735463e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7768/10000, Loss: 0.027754349634051323, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7769/10000, Loss: 0.013860725797712803, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7770/10000, Loss: 0.013876382261514664, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7771/10000, Loss: 3.874149115290493e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7772/10000, Loss: 3.8146689007589885e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7773/10000, Loss: 3.6716329532282543e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7774/10000, Loss: 1.192078798339935e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7775/10000, Loss: 1.311301076611926e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7776/10000, Loss: 0.01386866346001625, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7777/10000, Loss: 0.013877443969249725, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7778/10000, Loss: 0.013890845701098442, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7779/10000, Loss: 0.01388176903128624, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7780/10000, Loss: 0.04159730672836304, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7781/10000, Loss: 0.013860415667295456, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7782/10000, Loss: 0.02773425541818142, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7783/10000, Loss: 1.4114272062215605e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7784/10000, Loss: 0.013886796310544014, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7785/10000, Loss: 0.013849284499883652, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7786/10000, Loss: 0.013867292553186417, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7787/10000, Loss: 0.013877347111701965, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7788/10000, Loss: 0.01389848068356514, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7789/10000, Loss: 3.957736964821379e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7790/10000, Loss: 0.013893501833081245, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7791/10000, Loss: 0.013888701796531677, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7792/10000, Loss: 2.8942711196577875e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7793/10000, Loss: 6.675718111637252e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7794/10000, Loss: 0.01389494352042675, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7795/10000, Loss: 8.964481708062522e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7796/10000, Loss: 6.9846164478803985e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7797/10000, Loss: 3.096926093348884e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7798/10000, Loss: 0.013892028480768204, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7799/10000, Loss: 0.013874191790819168, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7800/10000, Loss: 0.013890600763261318, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 7800: 0.3489020012378695\n",
            "Epoch 7801/10000, Loss: 1.2254569128344883e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7802/10000, Loss: 5.412071004684549e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7803/10000, Loss: 9.369687177240849e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7804/10000, Loss: 2.0117757230764255e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7805/10000, Loss: 3.3140133837150643e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7806/10000, Loss: 0.013893554918467999, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7807/10000, Loss: 0.04160628095269203, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7808/10000, Loss: 0.013892041519284248, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7809/10000, Loss: 1.2397761395277485e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7810/10000, Loss: 0.013879399746656418, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7811/10000, Loss: 4.267675137725746e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7812/10000, Loss: 5.912760343562695e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7813/10000, Loss: 1.9538498236215673e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7814/10000, Loss: 1.0633395959303016e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7815/10000, Loss: 0.027780242264270782, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7816/10000, Loss: 0.013889705762267113, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7817/10000, Loss: 2.8299073164816946e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7818/10000, Loss: 0.013886476866900921, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7819/10000, Loss: 0.013877779245376587, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7820/10000, Loss: 6.782050149922725e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7821/10000, Loss: 2.2411309430481197e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7822/10000, Loss: 6.360064162436174e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7823/10000, Loss: 0.013902448117733002, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7824/10000, Loss: 6.747188763256418e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7825/10000, Loss: 2.9300379082997097e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7826/10000, Loss: 1.0251994098098294e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7827/10000, Loss: 0.027811111882328987, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7828/10000, Loss: 1.9541219444363378e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7829/10000, Loss: 0.013862278312444687, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7830/10000, Loss: 0.027733923867344856, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7831/10000, Loss: 0.01388371642678976, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7832/10000, Loss: 6.1988254174139e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7833/10000, Loss: 0.01387624442577362, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7834/10000, Loss: 4.3153514184268715e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7835/10000, Loss: 1.4018900174050941e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7836/10000, Loss: 0.013880283571779728, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7837/10000, Loss: 6.63430137137766e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7838/10000, Loss: 6.686755114060361e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7839/10000, Loss: 3.1279241738957353e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7840/10000, Loss: 0.02773446775972843, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7841/10000, Loss: 0.013879310339689255, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7842/10000, Loss: 6.131254394858843e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7843/10000, Loss: 0.013873846270143986, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7844/10000, Loss: 0.013880870305001736, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7845/10000, Loss: 2.684482069525984e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7846/10000, Loss: 6.294210379564902e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7847/10000, Loss: 0.013878956437110901, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7848/10000, Loss: 3.242482193854812e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7849/10000, Loss: 0.013872116804122925, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7850/10000, Loss: 0.01387609913945198, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7851/10000, Loss: 0.013894052244722843, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7852/10000, Loss: 0.027733473107218742, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7853/10000, Loss: 2.28881646080481e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7854/10000, Loss: 8.344646573732462e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7855/10000, Loss: 4.768354813222686e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7856/10000, Loss: 0.027812279760837555, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7857/10000, Loss: 0.027770591899752617, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7858/10000, Loss: 0.013886324129998684, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7859/10000, Loss: 3.932389518013224e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7860/10000, Loss: 4.329448074713582e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7861/10000, Loss: 0.013885856606066227, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7862/10000, Loss: 0.01388351246714592, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7863/10000, Loss: 0.013891304843127728, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7864/10000, Loss: 0.01385323517024517, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7865/10000, Loss: 2.0704634152934887e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7866/10000, Loss: 3.809513873420656e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7867/10000, Loss: 0.013887764886021614, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7868/10000, Loss: 0.013881339691579342, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7869/10000, Loss: 3.278170652265544e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7870/10000, Loss: 5.113879979035119e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7871/10000, Loss: 5.810025413666153e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7872/10000, Loss: 0.01389212254434824, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7873/10000, Loss: 0.013849620707333088, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7874/10000, Loss: 3.0135429369693156e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7875/10000, Loss: 9.030241017171647e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7876/10000, Loss: 0.027749422937631607, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7877/10000, Loss: 0.013866760767996311, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7878/10000, Loss: 0.013887213543057442, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7879/10000, Loss: 0.02773447148501873, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7880/10000, Loss: 0.013898450881242752, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7881/10000, Loss: 0.013874337077140808, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7882/10000, Loss: 8.43181896925671e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7883/10000, Loss: 8.0627687566448e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7884/10000, Loss: 1.8167125972468057e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7885/10000, Loss: 1.6283649983961368e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7886/10000, Loss: 8.940651241573505e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7887/10000, Loss: 1.8095707901011338e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7888/10000, Loss: 1.997892468352802e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7889/10000, Loss: 3.516520791890798e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7890/10000, Loss: 0.013867263682186604, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7891/10000, Loss: 1.235365380125586e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7892/10000, Loss: 0.013880987651646137, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7893/10000, Loss: 1.6188113249882008e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7894/10000, Loss: 3.5118066534778336e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7895/10000, Loss: 0.013885114341974258, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7896/10000, Loss: 0.013850228860974312, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7897/10000, Loss: 2.5033228666870855e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7898/10000, Loss: 3.266324313244695e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7899/10000, Loss: 3.020571057277266e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7900/10000, Loss: 1.628370227990672e-06, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 7900: 0.34986100118160274\n",
            "Epoch 7901/10000, Loss: 2.2434589936892735e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7902/10000, Loss: 0.013892878778278828, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7903/10000, Loss: 0.013885997235774994, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7904/10000, Loss: 2.90616867459903e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7905/10000, Loss: 0.027741743251681328, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7906/10000, Loss: 4.36765958511387e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7907/10000, Loss: 6.968660727579845e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7908/10000, Loss: 3.406912128411932e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7909/10000, Loss: 0.013880070298910141, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7910/10000, Loss: 0.013889352791011333, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7911/10000, Loss: 4.839881739826524e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7912/10000, Loss: 0.013892684131860733, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7913/10000, Loss: 4.298558906157268e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7914/10000, Loss: 1.5949785847624298e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7915/10000, Loss: 3.910059547251876e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7916/10000, Loss: 2.6654149678506656e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7917/10000, Loss: 0.01388332899659872, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7918/10000, Loss: 0.013888370245695114, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7919/10000, Loss: 3.7549259559455095e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7920/10000, Loss: 2.0026920992677333e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7921/10000, Loss: 0.027754507958889008, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7922/10000, Loss: 0.013879368081688881, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7923/10000, Loss: 0.013866569846868515, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7924/10000, Loss: 0.02773446775972843, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7925/10000, Loss: 2.131646397174336e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7926/10000, Loss: 0.01388187613338232, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7927/10000, Loss: 6.031967814124073e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7928/10000, Loss: 0.013879368081688881, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7929/10000, Loss: 3.2971690870908787e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7930/10000, Loss: 1.6379080989281647e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7931/10000, Loss: 0.013882114551961422, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7932/10000, Loss: 0.013889624737203121, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7933/10000, Loss: 1.101485963772575e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7934/10000, Loss: 3.3140136679321586e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7935/10000, Loss: 1.6402955225203186e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7936/10000, Loss: 1.2612276805157308e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7937/10000, Loss: 0.013881556689739227, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7938/10000, Loss: 7.823897249181755e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7939/10000, Loss: 1.1873025869135745e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7940/10000, Loss: 6.651824264736206e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7941/10000, Loss: 0.01389368250966072, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7942/10000, Loss: 0.013891413807868958, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7943/10000, Loss: 2.9896134492446436e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7944/10000, Loss: 7.263630322995596e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7945/10000, Loss: 0.013885501772165298, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7946/10000, Loss: 0.027735522016882896, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7947/10000, Loss: 0.0416293665766716, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7948/10000, Loss: 0.013893844559788704, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7949/10000, Loss: 7.653206921531819e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7950/10000, Loss: 6.736729119438678e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7951/10000, Loss: 1.568771835991356e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7952/10000, Loss: 7.34324487439153e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7953/10000, Loss: 1.8763192883852753e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7954/10000, Loss: 3.504680307742092e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7955/10000, Loss: 0.01387154683470726, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7956/10000, Loss: 0.01388273760676384, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7957/10000, Loss: 0.013879514299333096, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7958/10000, Loss: 0.013869163580238819, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7959/10000, Loss: 3.075593042467517e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7960/10000, Loss: 0.013883787207305431, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7961/10000, Loss: 0.027736494317650795, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7962/10000, Loss: 1.6450867690309678e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7963/10000, Loss: 1.3685047406397643e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7964/10000, Loss: 1.087182795345143e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7965/10000, Loss: 3.3855363312795816e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7966/10000, Loss: 0.013877205550670624, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7967/10000, Loss: 0.013893404975533485, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7968/10000, Loss: 3.07555546896765e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7969/10000, Loss: 0.01387193612754345, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7970/10000, Loss: 0.0138749610632658, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7971/10000, Loss: 0.013896665535867214, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7972/10000, Loss: 7.39474762667669e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7973/10000, Loss: 0.013865005224943161, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7974/10000, Loss: 7.399517016892787e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7975/10000, Loss: 0.013889387249946594, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7976/10000, Loss: 0.013875255361199379, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7977/10000, Loss: 0.02773437462747097, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7978/10000, Loss: 1.2016224673061515e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7979/10000, Loss: 1.9924456864828244e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7980/10000, Loss: 6.27036968126049e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7981/10000, Loss: 2.0820933059439994e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7982/10000, Loss: 2.9014038318564417e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7983/10000, Loss: 9.155226052826038e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7984/10000, Loss: 0.02775607816874981, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7985/10000, Loss: 0.027794575318694115, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7986/10000, Loss: 0.02773429825901985, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7987/10000, Loss: 0.02773555926978588, Train Accuracy: 0.9879999756813049\n",
            "Epoch 7988/10000, Loss: 0.013887658715248108, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7989/10000, Loss: 0.027787594124674797, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7990/10000, Loss: 0.013873412273824215, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7991/10000, Loss: 0.013879675418138504, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7992/10000, Loss: 4.365278982731979e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7993/10000, Loss: 0.01388669852167368, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7994/10000, Loss: 1.3327467058843467e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 7995/10000, Loss: 0.02773318439722061, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7996/10000, Loss: 8.296917144434701e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7997/10000, Loss: 1.1062564908570494e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 7998/10000, Loss: 0.013895773328840733, Train Accuracy: 0.9919999837875366\n",
            "Epoch 7999/10000, Loss: 7.104837891347415e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8000/10000, Loss: 7.10626272848458e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 8000: 0.35082000112533596\n",
            "Epoch 8001/10000, Loss: 0.013902653940021992, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8002/10000, Loss: 0.013868040405213833, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8003/10000, Loss: 6.839232810307294e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8004/10000, Loss: 6.341916787278024e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8005/10000, Loss: 2.975316192532773e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8006/10000, Loss: 1.144398197538976e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8007/10000, Loss: 1.254070298273291e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8008/10000, Loss: 7.820059977348137e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8009/10000, Loss: 8.153877502081741e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8010/10000, Loss: 0.013882030732929707, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8011/10000, Loss: 0.013883374631404877, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8012/10000, Loss: 0.013862867839634418, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8013/10000, Loss: 0.01385597512125969, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8014/10000, Loss: 0.02773604542016983, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8015/10000, Loss: 0.01387808658182621, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8016/10000, Loss: 0.01387154683470726, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8017/10000, Loss: 2.2037173039279878e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8018/10000, Loss: 0.013882811181247234, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8019/10000, Loss: 7.295580530808365e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8020/10000, Loss: 2.3841812435421161e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8021/10000, Loss: 1.9634109776234254e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8022/10000, Loss: 2.4080236471490934e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8023/10000, Loss: 0.01387489028275013, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8024/10000, Loss: 6.05580623869173e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8025/10000, Loss: 0.013882502913475037, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8026/10000, Loss: 0.013876711018383503, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8027/10000, Loss: 7.64505603001453e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8028/10000, Loss: 1.2779008784491452e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8029/10000, Loss: 8.892982350516832e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8030/10000, Loss: 0.01387751754373312, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8031/10000, Loss: 3.051748933557974e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8032/10000, Loss: 0.013860664330422878, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8033/10000, Loss: 0.013876219280064106, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8034/10000, Loss: 0.027759253978729248, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8035/10000, Loss: 1.9350576621945947e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8036/10000, Loss: 0.013877823948860168, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8037/10000, Loss: 6.691401267744368e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8038/10000, Loss: 0.02773432247340679, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8039/10000, Loss: 0.013889329507946968, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8040/10000, Loss: 1.9820319721475244e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8041/10000, Loss: 1.9736857211682945e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8042/10000, Loss: 0.01384323462843895, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8043/10000, Loss: 0.027788294479250908, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8044/10000, Loss: 3.268572072556708e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8045/10000, Loss: 1.3899569921704824e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8046/10000, Loss: 5.030616989643022e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8047/10000, Loss: 2.0147012037341483e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8048/10000, Loss: 3.9265878513106145e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8049/10000, Loss: 0.013889329507946968, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8050/10000, Loss: 1.804803673621791e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8051/10000, Loss: 0.013886249624192715, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8052/10000, Loss: 0.013892008922994137, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8053/10000, Loss: 5.722033051824837e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8054/10000, Loss: 0.013883767649531364, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8055/10000, Loss: 4.5061034370519337e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8056/10000, Loss: 0.0416116900742054, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8057/10000, Loss: 0.013894498348236084, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8058/10000, Loss: 0.013858570717275143, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8059/10000, Loss: 0.02781883254647255, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8060/10000, Loss: 0.013885540887713432, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8061/10000, Loss: 1.046652982950036e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8062/10000, Loss: 0.013868219219148159, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8063/10000, Loss: 0.013864288106560707, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8064/10000, Loss: 0.027768725529313087, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8065/10000, Loss: 0.013881977647542953, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8066/10000, Loss: 5.292863534123171e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8067/10000, Loss: 7.0203959694481455e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8068/10000, Loss: 0.013875014148652554, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8069/10000, Loss: 7.033330575723085e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8070/10000, Loss: 6.937963803466118e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8071/10000, Loss: 0.02776125818490982, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8072/10000, Loss: 7.1896688496053685e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8073/10000, Loss: 1.4328828683574102e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8074/10000, Loss: 2.1325002308003604e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8075/10000, Loss: 4.625300391580822e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8076/10000, Loss: 0.013898632489144802, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8077/10000, Loss: 2.560473376433947e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8078/10000, Loss: 1.5163341231527738e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8079/10000, Loss: 2.646442283094075e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8080/10000, Loss: 2.8610202207346447e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8081/10000, Loss: 0.013872502371668816, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8082/10000, Loss: 0.013870525173842907, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8083/10000, Loss: 0.013879121281206608, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8084/10000, Loss: 3.5856674003298394e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8085/10000, Loss: 1.022810806716734e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8086/10000, Loss: 0.04161684587597847, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8087/10000, Loss: 0.013863534666597843, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8088/10000, Loss: 9.72741645455244e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8089/10000, Loss: 0.013891255483031273, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8090/10000, Loss: 0.01389429159462452, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8091/10000, Loss: 1.8898230337072164e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8092/10000, Loss: 0.027766181156039238, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8093/10000, Loss: 1.4805682440055534e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8094/10000, Loss: 0.013909289613366127, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8095/10000, Loss: 0.013895518146455288, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8096/10000, Loss: 6.822490831837058e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8097/10000, Loss: 9.89418708741141e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8098/10000, Loss: 0.013884750194847584, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8099/10000, Loss: 4.5299398720999307e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8100/10000, Loss: 6.793876764277229e-06, Train Accuracy: 0.9900000095367432\n",
            "Test Accuracy at epoch 8100: 0.3517790010690692\n",
            "Epoch 8101/10000, Loss: 0.02778974547982216, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8102/10000, Loss: 9.131392175731889e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8103/10000, Loss: 6.36575123280636e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8104/10000, Loss: 0.013883648440241814, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8105/10000, Loss: 0.027733270078897476, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8106/10000, Loss: 0.013882254250347614, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8107/10000, Loss: 7.724724468971544e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8108/10000, Loss: 0.01386741828173399, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8109/10000, Loss: 4.3868934085367073e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8110/10000, Loss: 8.487657510158897e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8111/10000, Loss: 0.01385729294270277, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8112/10000, Loss: 3.767003988741635e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8113/10000, Loss: 0.027783848345279694, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8114/10000, Loss: 2.1270559955155477e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8115/10000, Loss: 0.01388983428478241, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8116/10000, Loss: 0.01385759562253952, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8117/10000, Loss: 0.027753883972764015, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8118/10000, Loss: 0.013877077959477901, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8119/10000, Loss: 0.013865454122424126, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8120/10000, Loss: 3.504748065097374e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8121/10000, Loss: 1.8283388271811418e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8122/10000, Loss: 2.9467141757777426e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8123/10000, Loss: 0.0138880405575037, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8124/10000, Loss: 1.870062988018617e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8125/10000, Loss: 0.013880407437682152, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8126/10000, Loss: 5.221353944762086e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8127/10000, Loss: 6.808161288063275e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8128/10000, Loss: 6.937945613572083e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8129/10000, Loss: 6.893989848322235e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8130/10000, Loss: 0.013887186534702778, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8131/10000, Loss: 0.01387451495975256, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8132/10000, Loss: 0.013888180255889893, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8133/10000, Loss: 7.232539246615488e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8134/10000, Loss: 0.013878711499273777, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8135/10000, Loss: 0.013881875202059746, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8136/10000, Loss: 5.459757517201069e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8137/10000, Loss: 0.02773333713412285, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8138/10000, Loss: 8.130036235343141e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8139/10000, Loss: 0.02773543819785118, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8140/10000, Loss: 1.199235725835024e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8141/10000, Loss: 0.027733448892831802, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8142/10000, Loss: 0.013887720182538033, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8143/10000, Loss: 0.013894069008529186, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8144/10000, Loss: 8.177693189281854e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8145/10000, Loss: 0.013869797810912132, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8146/10000, Loss: 3.39969597007439e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8147/10000, Loss: 0.013873683288693428, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8148/10000, Loss: 2.131377550540492e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8149/10000, Loss: 1.8310328186998959e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8150/10000, Loss: 0.013871448114514351, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8151/10000, Loss: 1.7854479665402323e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8152/10000, Loss: 2.9325434525162564e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8153/10000, Loss: 2.3603396925864217e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8154/10000, Loss: 5.030614715906268e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8155/10000, Loss: 0.013881293125450611, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8156/10000, Loss: 0.01390385627746582, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8157/10000, Loss: 6.437286401705933e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8158/10000, Loss: 0.02773280069231987, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8159/10000, Loss: 4.672978093367419e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8160/10000, Loss: 0.013866424560546875, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8161/10000, Loss: 0.02777896262705326, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8162/10000, Loss: 2.0741670596180484e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8163/10000, Loss: 1.9008492017746903e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8164/10000, Loss: 0.013896171003580093, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8165/10000, Loss: 0.013892925344407558, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8166/10000, Loss: 1.783312291081529e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8167/10000, Loss: 2.408025068234565e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8168/10000, Loss: 1.883503273347742e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8169/10000, Loss: 0.013871369883418083, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8170/10000, Loss: 0.013889428228139877, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8171/10000, Loss: 0.027817189693450928, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8172/10000, Loss: 0.013876460492610931, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8173/10000, Loss: 1.7404542518306698e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8174/10000, Loss: 7.1371391641150694e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8175/10000, Loss: 1.0371046528234729e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8176/10000, Loss: 0.013892065733671188, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8177/10000, Loss: 0.027750467881560326, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8178/10000, Loss: 3.564208327588858e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8179/10000, Loss: 0.02777693420648575, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8180/10000, Loss: 0.027754921466112137, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8181/10000, Loss: 2.5272342440985085e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8182/10000, Loss: 1.4591031458621728e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8183/10000, Loss: 9.059748435902293e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8184/10000, Loss: 0.0277404822409153, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8185/10000, Loss: 0.013867801986634731, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8186/10000, Loss: 3.0279090879048454e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8187/10000, Loss: 7.271730169122748e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8188/10000, Loss: 7.462466555807623e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8189/10000, Loss: 1.7821357687353157e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8190/10000, Loss: 1.1896922842424829e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8191/10000, Loss: 1.8429327610647306e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8192/10000, Loss: 6.389593067979149e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8193/10000, Loss: 0.013888624496757984, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8194/10000, Loss: 7.1800359364715405e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8195/10000, Loss: 0.013885815627872944, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8196/10000, Loss: 1.776419230736792e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8197/10000, Loss: 0.013869103044271469, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8198/10000, Loss: 4.2676757061599346e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8199/10000, Loss: 5.102145337332331e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8200/10000, Loss: 1.78977134055458e-05, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 8200: 0.3527380010128024\n",
            "Epoch 8201/10000, Loss: 4.3868899979315756e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8202/10000, Loss: 9.632058208808303e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8203/10000, Loss: 3.278114718341385e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8204/10000, Loss: 0.027785586193203926, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8205/10000, Loss: 0.0277366004884243, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8206/10000, Loss: 7.065585123200435e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8207/10000, Loss: 0.013862754218280315, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8208/10000, Loss: 0.013873021118342876, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8209/10000, Loss: 4.172311491856817e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8210/10000, Loss: 1.7499636669526808e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8211/10000, Loss: 2.8133359819548787e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8212/10000, Loss: 1.4519524711431586e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8213/10000, Loss: 0.01388542726635933, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8214/10000, Loss: 5.030623242419097e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8215/10000, Loss: 0.013887994922697544, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8216/10000, Loss: 0.027734898030757904, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8217/10000, Loss: 0.02776903286576271, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8218/10000, Loss: 2.6510849693295313e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8219/10000, Loss: 0.013882345519959927, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8220/10000, Loss: 0.013884823769330978, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8221/10000, Loss: 0.013894912786781788, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8222/10000, Loss: 3.0230169159040088e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8223/10000, Loss: 7.153787919378374e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8224/10000, Loss: 0.013884630054235458, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8225/10000, Loss: 0.013893872499465942, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8226/10000, Loss: 8.869111525200424e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8227/10000, Loss: 7.759356776659843e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8228/10000, Loss: 1.7547414472574019e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8229/10000, Loss: 1.751643867464736e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8230/10000, Loss: 1.0895680588873802e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8231/10000, Loss: 4.529940440534119e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8232/10000, Loss: 0.013889939524233341, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8233/10000, Loss: 0.013866322115063667, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8234/10000, Loss: 0.01386756356805563, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8235/10000, Loss: 4.1246312321163714e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8236/10000, Loss: 5.030618694945588e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8237/10000, Loss: 0.027732841670513153, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8238/10000, Loss: 1.7206557458848692e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8239/10000, Loss: 3.314011962629593e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8240/10000, Loss: 2.8799684059777064e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8241/10000, Loss: 3.8862131646055786e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8242/10000, Loss: 0.01390633825212717, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8243/10000, Loss: 1.0800239351738128e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8244/10000, Loss: 0.027732564136385918, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8245/10000, Loss: 9.775112630450167e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8246/10000, Loss: 5.030614147472079e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8247/10000, Loss: 5.41208692084183e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8248/10000, Loss: 4.3868925558854244e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8249/10000, Loss: 3.552430598574574e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8250/10000, Loss: 0.02773519605398178, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8251/10000, Loss: 0.013879385776817799, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8252/10000, Loss: 4.76837058727142e-08, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8253/10000, Loss: 0.027732860296964645, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8254/10000, Loss: 1.2230744914631941e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8255/10000, Loss: 1.1110167861261289e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8256/10000, Loss: 8.82143467606511e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8257/10000, Loss: 7.6139081102155615e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8258/10000, Loss: 2.4795500053187425e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8259/10000, Loss: 0.01386836264282465, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8260/10000, Loss: 0.027753541246056557, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8261/10000, Loss: 5.841237680215272e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8262/10000, Loss: 1.734023135213647e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8263/10000, Loss: 0.013875357806682587, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8264/10000, Loss: 0.01387287862598896, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8265/10000, Loss: 1.4662588228020468e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8266/10000, Loss: 1.2159338780293183e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8267/10000, Loss: 0.04160176217556, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8268/10000, Loss: 2.6464428515282634e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8269/10000, Loss: 1.3661218645211193e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8270/10000, Loss: 0.013902464881539345, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8271/10000, Loss: 7.581680279145075e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8272/10000, Loss: 0.013889581896364689, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8273/10000, Loss: 5.60282160222414e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8274/10000, Loss: 4.482255064885976e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8275/10000, Loss: 2.696392130019376e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8276/10000, Loss: 0.027732597663998604, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8277/10000, Loss: 1.7261344282815116e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8278/10000, Loss: 0.013885512948036194, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8279/10000, Loss: 0.013880692422389984, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8280/10000, Loss: 8.201559467124753e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8281/10000, Loss: 0.013883905485272408, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8282/10000, Loss: 6.508805086014036e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8283/10000, Loss: 5.412086352407641e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8284/10000, Loss: 0.013879590667784214, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8285/10000, Loss: 0.01387299969792366, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8286/10000, Loss: 2.1457650234424364e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8287/10000, Loss: 0.02773257903754711, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8288/10000, Loss: 0.013866903260350227, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8289/10000, Loss: 1.1515556934682536e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8290/10000, Loss: 0.013880855403840542, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8291/10000, Loss: 2.741807350048475e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8292/10000, Loss: 5.93660786307737e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8293/10000, Loss: 0.02773308753967285, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8294/10000, Loss: 1.2302253935558838e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8295/10000, Loss: 0.013864561915397644, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8296/10000, Loss: 4.7206776798702776e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8297/10000, Loss: 3.7001223063271027e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8298/10000, Loss: 9.059865533345146e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8299/10000, Loss: 0.013876447454094887, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8300/10000, Loss: 1.4662557532574283e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 8300: 0.3536970009565356\n",
            "Epoch 8301/10000, Loss: 2.4794369437586283e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8302/10000, Loss: 0.027783755213022232, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8303/10000, Loss: 0.013896599411964417, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8304/10000, Loss: 1.883505120758855e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8305/10000, Loss: 3.480899408714322e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8306/10000, Loss: 2.0980820636395947e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8307/10000, Loss: 3.480904240404925e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8308/10000, Loss: 0.0138838030397892, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8309/10000, Loss: 0.027732333168387413, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8310/10000, Loss: 7.50420440454036e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8311/10000, Loss: 0.013876110315322876, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8312/10000, Loss: 0.01386898010969162, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8313/10000, Loss: 0.02778060920536518, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8314/10000, Loss: 0.013881958089768887, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8315/10000, Loss: 0.02774936705827713, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8316/10000, Loss: 6.914106052136049e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8317/10000, Loss: 1.1587006838453817e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8318/10000, Loss: 1.3851964695277275e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8319/10000, Loss: 0.01385989785194397, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8320/10000, Loss: 0.013900283724069595, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8321/10000, Loss: 2.5485783226031344e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8322/10000, Loss: 0.013885538093745708, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8323/10000, Loss: 0.013885644264519215, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8324/10000, Loss: 1.1420115697546862e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8325/10000, Loss: 4.1484710777695e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8326/10000, Loss: 1.1062483054047334e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8327/10000, Loss: 7.792683391016908e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8328/10000, Loss: 2.369768253629445e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8329/10000, Loss: 1.2731397873722017e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8330/10000, Loss: 0.027807271108031273, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8331/10000, Loss: 8.181293196685147e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8332/10000, Loss: 7.315843504329678e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8333/10000, Loss: 0.027739664539694786, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8334/10000, Loss: 8.439976681984263e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8335/10000, Loss: 0.027732256799936295, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8336/10000, Loss: 1.549719286231266e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8337/10000, Loss: 1.3375138223636895e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8338/10000, Loss: 2.431867187624448e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8339/10000, Loss: 0.01387640368193388, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8340/10000, Loss: 8.749841526878299e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8341/10000, Loss: 0.013873212970793247, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8342/10000, Loss: 0.027767052873969078, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8343/10000, Loss: 0.013866591267287731, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8344/10000, Loss: 0.013879365287721157, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8345/10000, Loss: 7.85228348831879e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8346/10000, Loss: 0.01385761983692646, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8347/10000, Loss: 0.027796687558293343, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8348/10000, Loss: 0.013865969143807888, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8349/10000, Loss: 1.2922123460157309e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8350/10000, Loss: 0.013894520699977875, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8351/10000, Loss: 5.221351102591143e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8352/10000, Loss: 0.013890443369746208, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8353/10000, Loss: 0.027779879048466682, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8354/10000, Loss: 6.294208105828147e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8355/10000, Loss: 5.650498451359454e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8356/10000, Loss: 3.2663282922840153e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8357/10000, Loss: 1.6356123524019495e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8358/10000, Loss: 0.027780337259173393, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8359/10000, Loss: 1.3136717598172254e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8360/10000, Loss: 3.8862066276124096e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8361/10000, Loss: 0.01389500591903925, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8362/10000, Loss: 1.649684418225661e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8363/10000, Loss: 0.013881242834031582, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8364/10000, Loss: 7.957183697726578e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8365/10000, Loss: 0.013881804421544075, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8366/10000, Loss: 1.811979899457583e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8367/10000, Loss: 5.722028504351329e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8368/10000, Loss: 5.245196916803252e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8369/10000, Loss: 1.1014810752385529e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8370/10000, Loss: 4.816044452127244e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8371/10000, Loss: 0.01386311836540699, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8372/10000, Loss: 1.6420610336354002e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8373/10000, Loss: 0.013875965029001236, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8374/10000, Loss: 1.7166118482236925e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8375/10000, Loss: 0.027732418850064278, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8376/10000, Loss: 0.013878881931304932, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8377/10000, Loss: 6.36575123280636e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8378/10000, Loss: 0.027820773422718048, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8379/10000, Loss: 1.8835038417819305e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8380/10000, Loss: 1.096713162951346e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8381/10000, Loss: 0.027732135728001595, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8382/10000, Loss: 1.9550273577806365e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8383/10000, Loss: 0.013870222494006157, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8384/10000, Loss: 1.772722134774085e-05, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8385/10000, Loss: 1.258837301065796e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8386/10000, Loss: 7.346839083766099e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8387/10000, Loss: 0.013879346661269665, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8388/10000, Loss: 2.83717071170031e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8389/10000, Loss: 3.1471105899072427e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8390/10000, Loss: 6.914135752822403e-08, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8391/10000, Loss: 2.0027141545142513e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8392/10000, Loss: 0.013903743587434292, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8393/10000, Loss: 0.013884413987398148, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8394/10000, Loss: 1.6263389625237323e-05, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8395/10000, Loss: 2.179043576688855e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8396/10000, Loss: 0.027732189744710922, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8397/10000, Loss: 2.1696044427699235e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8398/10000, Loss: 0.027733242139220238, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8399/10000, Loss: 4.7683533921372145e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8400/10000, Loss: 0.013876128010451794, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 8400: 0.35465600090026883\n",
            "Epoch 8401/10000, Loss: 0.01386227086186409, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8402/10000, Loss: 0.013878725469112396, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8403/10000, Loss: 0.041648492217063904, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8404/10000, Loss: 0.0277725663036108, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8405/10000, Loss: 1.6108477211673744e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8406/10000, Loss: 0.027769923210144043, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8407/10000, Loss: 0.013882569968700409, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8408/10000, Loss: 5.578973514275276e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8409/10000, Loss: 1.6196758224396035e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8410/10000, Loss: 2.386468622717075e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8411/10000, Loss: 0.027732031419873238, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8412/10000, Loss: 0.02773194946348667, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8413/10000, Loss: 0.013897723518311977, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8414/10000, Loss: 0.013866545632481575, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8415/10000, Loss: 0.013886287808418274, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8416/10000, Loss: 5.483613563228573e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8417/10000, Loss: 4.005417508778919e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8418/10000, Loss: 0.013877400197088718, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8419/10000, Loss: 8.320767506120319e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8420/10000, Loss: 2.312657585434863e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8421/10000, Loss: 0.01388078648597002, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8422/10000, Loss: 1.883505262867402e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8423/10000, Loss: 5.483615268531139e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8424/10000, Loss: 4.6491513217006286e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8425/10000, Loss: 1.716612274549334e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8426/10000, Loss: 2.646440577791509e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8427/10000, Loss: 0.013865770772099495, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8428/10000, Loss: 0.013860566541552544, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8429/10000, Loss: 7.033308406789729e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8430/10000, Loss: 2.145765733985172e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8431/10000, Loss: 0.013902576640248299, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8432/10000, Loss: 1.6380448869313113e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8433/10000, Loss: 2.789491304611147e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8434/10000, Loss: 2.1696043006613763e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8435/10000, Loss: 0.027732782065868378, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8436/10000, Loss: 0.013872889801859856, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8437/10000, Loss: 0.013873135671019554, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8438/10000, Loss: 1.1443963785495725e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8439/10000, Loss: 0.013883101753890514, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8440/10000, Loss: 4.887563136435347e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8441/10000, Loss: 7.533986376984103e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8442/10000, Loss: 0.027766913175582886, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8443/10000, Loss: 1.6504474842804484e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8444/10000, Loss: 7.685406671953388e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8445/10000, Loss: 3.933894845431496e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8446/10000, Loss: 1.626609082450159e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8447/10000, Loss: 0.0138884037733078, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8448/10000, Loss: 0.013874744065105915, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8449/10000, Loss: 0.013884657062590122, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8450/10000, Loss: 0.013856587000191212, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8451/10000, Loss: 0.013878226280212402, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8452/10000, Loss: 8.27301903427724e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8453/10000, Loss: 0.01388285681605339, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8454/10000, Loss: 0.013870780356228352, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8455/10000, Loss: 9.083638587981113e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8456/10000, Loss: 0.0416143536567688, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8457/10000, Loss: 0.02774076908826828, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8458/10000, Loss: 3.5285862054479367e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8459/10000, Loss: 0.013867306523025036, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8460/10000, Loss: 7.653196689716424e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8461/10000, Loss: 7.009467708485317e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8462/10000, Loss: 0.01388750970363617, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8463/10000, Loss: 0.013887034729123116, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8464/10000, Loss: 5.078302365291165e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8465/10000, Loss: 0.02773267962038517, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8466/10000, Loss: 1.5739313312224112e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8467/10000, Loss: 2.19335856854741e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8468/10000, Loss: 3.6001125636175857e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8469/10000, Loss: 1.072871441465395e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8470/10000, Loss: 1.2922158703077002e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8471/10000, Loss: 1.584902565809898e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8472/10000, Loss: 2.2958799945627106e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8473/10000, Loss: 0.013868603855371475, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8474/10000, Loss: 3.4570533102851186e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8475/10000, Loss: 0.013875383883714676, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8476/10000, Loss: 6.222707042979891e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8477/10000, Loss: 0.013881455175578594, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8478/10000, Loss: 2.5272325387959427e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8479/10000, Loss: 9.775047828952665e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8480/10000, Loss: 0.013858761638402939, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8481/10000, Loss: 2.124219236065983e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8482/10000, Loss: 7.152528382903256e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8483/10000, Loss: 0.01387069933116436, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8484/10000, Loss: 7.82132974563865e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8485/10000, Loss: 7.367112289102806e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8486/10000, Loss: 1.1682499945209202e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8487/10000, Loss: 0.041618041694164276, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8488/10000, Loss: 1.3732775414609932e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8489/10000, Loss: 0.027732044458389282, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8490/10000, Loss: 0.013885426335036755, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8491/10000, Loss: 0.01387720461934805, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8492/10000, Loss: 0.013904225081205368, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8493/10000, Loss: 0.01388540118932724, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8494/10000, Loss: 0.04161642864346504, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8495/10000, Loss: 0.01387732569128275, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8496/10000, Loss: 0.013884017243981361, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8497/10000, Loss: 1.6474564290547278e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8498/10000, Loss: 3.075592189816234e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8499/10000, Loss: 4.482255064885976e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8500/10000, Loss: 0.013903019018471241, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 8500: 0.35561500084400205\n",
            "Epoch 8501/10000, Loss: 0.013884887099266052, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8502/10000, Loss: 0.013879012316465378, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8503/10000, Loss: 2.250581019325182e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8504/10000, Loss: 0.027738431468605995, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8505/10000, Loss: 8.225401302297541e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8506/10000, Loss: 0.013871265575289726, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8507/10000, Loss: 1.0323474270990118e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8508/10000, Loss: 0.013871483504772186, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8509/10000, Loss: 0.013878674246370792, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8510/10000, Loss: 0.013903971761465073, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8511/10000, Loss: 0.01386470440775156, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8512/10000, Loss: 0.013873128220438957, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8513/10000, Loss: 0.013868286274373531, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8514/10000, Loss: 0.013879326172173023, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8515/10000, Loss: 3.4809011140168877e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8516/10000, Loss: 0.013880540616810322, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8517/10000, Loss: 0.027733435854315758, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8518/10000, Loss: 3.838530915345473e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8519/10000, Loss: 3.8146865222188353e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8520/10000, Loss: 0.027784544974565506, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8521/10000, Loss: 0.013858983293175697, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8522/10000, Loss: 0.027731647714972496, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8523/10000, Loss: 1.1515492133185035e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8524/10000, Loss: 0.013861884362995625, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8525/10000, Loss: 0.027735115960240364, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8526/10000, Loss: 0.013886228203773499, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8527/10000, Loss: 0.013891221024096012, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8528/10000, Loss: 1.3351430538932618e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8529/10000, Loss: 0.027798902243375778, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8530/10000, Loss: 7.3397759479121305e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8531/10000, Loss: 5.698173026758013e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8532/10000, Loss: 0.01386586856096983, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8533/10000, Loss: 2.2500138584291562e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8534/10000, Loss: 0.013877504505217075, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8535/10000, Loss: 0.027746528387069702, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8536/10000, Loss: 0.013872317969799042, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8537/10000, Loss: 1.623610160095268e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8538/10000, Loss: 2.813334560869407e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8539/10000, Loss: 1.89772879366501e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8540/10000, Loss: 6.008116315570078e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8541/10000, Loss: 0.013871561735868454, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8542/10000, Loss: 4.17231035498844e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8543/10000, Loss: 2.701190169318579e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8544/10000, Loss: 0.027738532051444054, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8545/10000, Loss: 3.004058157785039e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8546/10000, Loss: 3.9577395227752277e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8547/10000, Loss: 2.2839667508378625e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8548/10000, Loss: 3.2901650115491066e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8549/10000, Loss: 0.013880661688745022, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8550/10000, Loss: 0.013872325420379639, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8551/10000, Loss: 1.4912493497831747e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8552/10000, Loss: 2.9086979225212417e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8553/10000, Loss: 0.013887428678572178, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8554/10000, Loss: 3.0994326039035514e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8555/10000, Loss: 1.1372449080226943e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8556/10000, Loss: 0.013882054015994072, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8557/10000, Loss: 0.013858538120985031, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8558/10000, Loss: 0.027746472507715225, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8559/10000, Loss: 0.02778458036482334, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8560/10000, Loss: 0.01387267280369997, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8561/10000, Loss: 3.314009404675744e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8562/10000, Loss: 0.013873368501663208, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8563/10000, Loss: 0.013883933424949646, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8564/10000, Loss: 3.8385289258258126e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8565/10000, Loss: 7.397035005851649e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8566/10000, Loss: 2.288737732669688e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8567/10000, Loss: 2.7656486167870753e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8568/10000, Loss: 0.01385914534330368, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8569/10000, Loss: 0.013869230635464191, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8570/10000, Loss: 2.026551300104984e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8571/10000, Loss: 0.027731990441679955, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8572/10000, Loss: 0.013888776302337646, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8573/10000, Loss: 0.01388943288475275, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8574/10000, Loss: 0.027732152491807938, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8575/10000, Loss: 4.02925024900469e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8576/10000, Loss: 2.1528398974623997e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8577/10000, Loss: 0.013893531635403633, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8578/10000, Loss: 0.01388385146856308, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8579/10000, Loss: 0.04162409156560898, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8580/10000, Loss: 4.887567115474667e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8581/10000, Loss: 0.013883366249501705, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8582/10000, Loss: 0.01385880634188652, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8583/10000, Loss: 1.964491048056516e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8584/10000, Loss: 0.013892291113734245, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8585/10000, Loss: 0.013881150633096695, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8586/10000, Loss: 0.013868448324501514, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8587/10000, Loss: 0.027795691043138504, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8588/10000, Loss: 1.2159229072494782e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8589/10000, Loss: 0.013866934925317764, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8590/10000, Loss: 8.940591555983701e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8591/10000, Loss: 0.0138605497777462, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8592/10000, Loss: 8.106133009277983e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8593/10000, Loss: 0.013887223787605762, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8594/10000, Loss: 3.3140091204586497e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8595/10000, Loss: 1.7857353213912575e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8596/10000, Loss: 1.454351803431564e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8597/10000, Loss: 8.82138976976421e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8598/10000, Loss: 0.013883071020245552, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8599/10000, Loss: 6.723371939187928e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8600/10000, Loss: 0.013880368322134018, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 8600: 0.35657400078773527\n",
            "Epoch 8601/10000, Loss: 1.5497195704483602e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8602/10000, Loss: 0.027731573209166527, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8603/10000, Loss: 5.102142495161388e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8604/10000, Loss: 0.01389710046350956, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8605/10000, Loss: 8.177665336006612e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8606/10000, Loss: 0.013891523703932762, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8607/10000, Loss: 0.01387035008519888, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8608/10000, Loss: 1.9311146388645284e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8609/10000, Loss: 4.959088641953713e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8610/10000, Loss: 0.013862560503184795, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8611/10000, Loss: 9.775152420843369e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8612/10000, Loss: 2.386487494732137e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8613/10000, Loss: 1.0204213367615012e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8614/10000, Loss: 3.671620447676105e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8615/10000, Loss: 0.02779451757669449, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8616/10000, Loss: 4.7683590764791006e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8617/10000, Loss: 4.029260765037179e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8618/10000, Loss: 0.013868100009858608, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8619/10000, Loss: 7.533981829510594e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8620/10000, Loss: 0.01387969683855772, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8621/10000, Loss: 0.013902000151574612, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8622/10000, Loss: 0.013879546895623207, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8623/10000, Loss: 4.816043315258867e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8624/10000, Loss: 4.196155316549266e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8625/10000, Loss: 4.5060957631903875e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8626/10000, Loss: 2.4080210891952447e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8627/10000, Loss: 0.0277386661618948, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8628/10000, Loss: 5.45976149624039e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8629/10000, Loss: 4.1246190107813163e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8630/10000, Loss: 2.741807350048475e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8631/10000, Loss: 0.013865535147488117, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8632/10000, Loss: 0.013885614462196827, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8633/10000, Loss: 1.52587830370976e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8634/10000, Loss: 6.438717718992848e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8635/10000, Loss: 2.384181954084852e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8636/10000, Loss: 1.0204215641351766e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8637/10000, Loss: 0.013900925405323505, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8638/10000, Loss: 6.405341991921887e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8639/10000, Loss: 0.013880896382033825, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8640/10000, Loss: 2.527232823013037e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8641/10000, Loss: 0.013861069455742836, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8642/10000, Loss: 7.462469397978566e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8643/10000, Loss: 0.013889778405427933, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8644/10000, Loss: 0.013880431652069092, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8645/10000, Loss: 0.013883915729820728, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8646/10000, Loss: 6.9918660301482305e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8647/10000, Loss: 7.152555525635762e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8648/10000, Loss: 3.1948022183314606e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8649/10000, Loss: 0.013868343085050583, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8650/10000, Loss: 0.01388087123632431, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8651/10000, Loss: 1.544935457786778e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8652/10000, Loss: 0.01387941837310791, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8653/10000, Loss: 0.01387016847729683, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8654/10000, Loss: 0.01388827059417963, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8655/10000, Loss: 2.5033875772351166e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8656/10000, Loss: 3.8146765746205347e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8657/10000, Loss: 0.013890701346099377, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8658/10000, Loss: 0.013888777233660221, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8659/10000, Loss: 0.013899771496653557, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8660/10000, Loss: 0.013898148201406002, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8661/10000, Loss: 0.013878009282052517, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8662/10000, Loss: 0.013881789520382881, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8663/10000, Loss: 7.653147235942015e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8664/10000, Loss: 1.4104869478615e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8665/10000, Loss: 0.013875080272555351, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8666/10000, Loss: 5.364400976759498e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8667/10000, Loss: 0.013873922638595104, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8668/10000, Loss: 2.479546026279422e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8669/10000, Loss: 0.013881411403417587, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8670/10000, Loss: 8.344644442104254e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8671/10000, Loss: 8.368459134544537e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8672/10000, Loss: 6.355338882713113e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8673/10000, Loss: 6.901317192387069e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8674/10000, Loss: 5.626657184620854e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8675/10000, Loss: 1.6450856321625906e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8676/10000, Loss: 1.3830748684995342e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8677/10000, Loss: 7.033317501736747e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8678/10000, Loss: 6.143160135252401e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8679/10000, Loss: 0.02773123048245907, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8680/10000, Loss: 6.580322065019573e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8681/10000, Loss: 2.6606712708598934e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8682/10000, Loss: 1.4090649528952781e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8683/10000, Loss: 4.1723123445081e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8684/10000, Loss: 7.939255510791554e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8685/10000, Loss: 0.013888780027627945, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8686/10000, Loss: 9.536737621829161e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8687/10000, Loss: 0.04159967228770256, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8688/10000, Loss: 0.02776687778532505, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8689/10000, Loss: 0.013866233639419079, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8690/10000, Loss: 0.04160046577453613, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8691/10000, Loss: 0.013892218470573425, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8692/10000, Loss: 0.02778150513768196, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8693/10000, Loss: 2.336497857413633e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8694/10000, Loss: 2.112318497893284e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8695/10000, Loss: 0.013854718767106533, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8696/10000, Loss: 0.013892821967601776, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8697/10000, Loss: 0.01387404277920723, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8698/10000, Loss: 0.013866574503481388, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8699/10000, Loss: 0.01386230532079935, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8700/10000, Loss: 0.013884223066270351, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 8700: 0.3575330007314685\n",
            "Epoch 8701/10000, Loss: 0.013875991106033325, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8702/10000, Loss: 6.5485050981806125e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8703/10000, Loss: 5.125975803821348e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8704/10000, Loss: 0.013864774256944656, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8705/10000, Loss: 0.013859493657946587, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8706/10000, Loss: 0.01388521771878004, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8707/10000, Loss: 6.250500518945046e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8708/10000, Loss: 0.013862316496670246, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8709/10000, Loss: 0.013890428468585014, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8710/10000, Loss: 0.027736905962228775, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8711/10000, Loss: 1.3516224498744123e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8712/10000, Loss: 5.078294975646713e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8713/10000, Loss: 0.027731098234653473, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8714/10000, Loss: 0.013877851888537407, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8715/10000, Loss: 2.2411276745515352e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8716/10000, Loss: 6.31806472028984e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8717/10000, Loss: 0.013890506699681282, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8718/10000, Loss: 6.105083684815327e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8719/10000, Loss: 1.3518651940103155e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8720/10000, Loss: 2.2411268219002523e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8721/10000, Loss: 1.7642963712205528e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8722/10000, Loss: 0.013881547376513481, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8723/10000, Loss: 0.027731582522392273, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8724/10000, Loss: 6.105094598751748e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8725/10000, Loss: 0.013876150362193584, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8726/10000, Loss: 0.013896054588258266, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8727/10000, Loss: 0.013875823467969894, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8728/10000, Loss: 2.52723367566432e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8729/10000, Loss: 0.013861036859452724, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8730/10000, Loss: 0.013868468813598156, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8731/10000, Loss: 2.455704759540822e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8732/10000, Loss: 3.838526652089058e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8733/10000, Loss: 2.0503975406427344e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8734/10000, Loss: 0.01390288770198822, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8735/10000, Loss: 0.013875888660550117, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8736/10000, Loss: 0.01388460397720337, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8737/10000, Loss: 0.013868107460439205, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8738/10000, Loss: 0.027731170877814293, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8739/10000, Loss: 1.3623678569274489e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8740/10000, Loss: 0.013880923390388489, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8741/10000, Loss: 4.711075234808959e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8742/10000, Loss: 5.0194830691907555e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8743/10000, Loss: 2.9475815608748235e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8744/10000, Loss: 7.653204647795064e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8745/10000, Loss: 0.013866747729480267, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8746/10000, Loss: 1.864419573394116e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8747/10000, Loss: 2.5820397695497377e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8748/10000, Loss: 0.027773775160312653, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8749/10000, Loss: 3.411704028621898e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8750/10000, Loss: 0.013883770443499088, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8751/10000, Loss: 1.2698674254352227e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8752/10000, Loss: 0.013867015950381756, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8753/10000, Loss: 0.027732452377676964, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8754/10000, Loss: 1.757324207574129e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8755/10000, Loss: 2.100443225572235e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8756/10000, Loss: 2.2364090909832157e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8757/10000, Loss: 0.013879794627428055, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8758/10000, Loss: 1.6045233905970235e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8759/10000, Loss: 0.013885913416743279, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8760/10000, Loss: 1.4424093706111307e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8761/10000, Loss: 1.942829112522304e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8762/10000, Loss: 0.027733691036701202, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8763/10000, Loss: 2.7608173240878386e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8764/10000, Loss: 0.013864781707525253, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8765/10000, Loss: 2.82282053376548e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8766/10000, Loss: 1.3279817494549206e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8767/10000, Loss: 2.551076079271297e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8768/10000, Loss: 0.013866035267710686, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8769/10000, Loss: 2.4365922399738338e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8770/10000, Loss: 1.2969882163815782e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8771/10000, Loss: 4.897010967397364e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8772/10000, Loss: 1.3899568784836447e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8773/10000, Loss: 1.4209546179699828e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8774/10000, Loss: 3.86236933991313e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8775/10000, Loss: 0.013877524062991142, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8776/10000, Loss: 0.01387404277920723, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8777/10000, Loss: 2.512889295758214e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8778/10000, Loss: 0.013885819353163242, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8779/10000, Loss: 2.0718252926599234e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8780/10000, Loss: 0.013874462805688381, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8781/10000, Loss: 0.027731360867619514, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8782/10000, Loss: 1.835819034567976e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8783/10000, Loss: 0.013872385956346989, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8784/10000, Loss: 0.013869167305529118, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8785/10000, Loss: 6.842570883236476e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8786/10000, Loss: 1.0371149983257055e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8787/10000, Loss: 2.036048726949957e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8788/10000, Loss: 1.6587009668000974e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8789/10000, Loss: 1.1658589755825233e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8790/10000, Loss: 0.013873305171728134, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8791/10000, Loss: 1.723750528981327e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8792/10000, Loss: 9.425579264643602e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8793/10000, Loss: 0.02773960307240486, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8794/10000, Loss: 0.027731124311685562, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8795/10000, Loss: 1.8620238506628084e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8796/10000, Loss: 0.013903168961405754, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8797/10000, Loss: 0.013861521147191525, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8798/10000, Loss: 0.02773207612335682, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8799/10000, Loss: 0.013879423961043358, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8800/10000, Loss: 0.013858933933079243, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 8800: 0.3584920006752017\n",
            "Epoch 8801/10000, Loss: 0.013872773386538029, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8802/10000, Loss: 1.8882498125094571e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8803/10000, Loss: 1.4376535091287224e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8804/10000, Loss: 0.013872155919671059, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8805/10000, Loss: 0.013869047164916992, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8806/10000, Loss: 0.013881242834031582, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8807/10000, Loss: 8.058503908614512e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8808/10000, Loss: 0.013877419754862785, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8809/10000, Loss: 0.013885900378227234, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8810/10000, Loss: 0.01385558769106865, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8811/10000, Loss: 9.38746779866051e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8812/10000, Loss: 0.013891633599996567, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8813/10000, Loss: 0.04166136682033539, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8814/10000, Loss: 5.006780270377931e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8815/10000, Loss: 7.940286195662338e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8816/10000, Loss: 2.2411290956370067e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8817/10000, Loss: 1.9717024315468734e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8818/10000, Loss: 0.02775813266634941, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8819/10000, Loss: 1.170627797364432e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8820/10000, Loss: 0.013849579729139805, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8821/10000, Loss: 3.242482193854812e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8822/10000, Loss: 1.3136746019881684e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8823/10000, Loss: 0.013899019919335842, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8824/10000, Loss: 1.1229432175241527e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8825/10000, Loss: 7.104837322913227e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8826/10000, Loss: 0.013897020369768143, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8827/10000, Loss: 0.013888131827116013, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8828/10000, Loss: 6.175017688292428e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8829/10000, Loss: 0.013844524510204792, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8830/10000, Loss: 0.027805902063846588, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8831/10000, Loss: 5.626665142699494e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8832/10000, Loss: 0.013854311779141426, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8833/10000, Loss: 0.0138732073828578, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8834/10000, Loss: 1.5056531992740929e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8835/10000, Loss: 3.957736964821379e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8836/10000, Loss: 0.013854682445526123, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8837/10000, Loss: 0.013865839689970016, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8838/10000, Loss: 8.940614861785434e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8839/10000, Loss: 7.963151347212261e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8840/10000, Loss: 0.013853282667696476, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8841/10000, Loss: 0.01386992447078228, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8842/10000, Loss: 0.013872072100639343, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8843/10000, Loss: 2.4079688500933116e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8844/10000, Loss: 0.013870112597942352, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8845/10000, Loss: 0.013855472207069397, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8846/10000, Loss: 0.013885465450584888, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8847/10000, Loss: 0.013909324072301388, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8848/10000, Loss: 1.1110217883469886e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8849/10000, Loss: 0.013883661478757858, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8850/10000, Loss: 5.483605605149933e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8851/10000, Loss: 0.01387773733586073, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8852/10000, Loss: 1.2016217851851252e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8853/10000, Loss: 0.013905029743909836, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8854/10000, Loss: 0.013846105895936489, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8855/10000, Loss: 1.3995075960338e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8856/10000, Loss: 1.3642719750350807e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8857/10000, Loss: 0.013874085620045662, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8858/10000, Loss: 0.0138963358476758, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8859/10000, Loss: 0.02773212641477585, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8860/10000, Loss: 0.013881637714803219, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8861/10000, Loss: 8.23362552182516e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8862/10000, Loss: 8.392270274271141e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8863/10000, Loss: 0.013860523700714111, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8864/10000, Loss: 1.4307890523923561e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8865/10000, Loss: 0.013863470405340195, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8866/10000, Loss: 1.449569822398189e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8867/10000, Loss: 0.013867815025150776, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8868/10000, Loss: 1.3552100426750258e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8869/10000, Loss: 1.3769048564427067e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8870/10000, Loss: 0.013890190050005913, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8871/10000, Loss: 2.7393577965995064e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8872/10000, Loss: 0.013880898244678974, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8873/10000, Loss: 3.3616930750213214e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8874/10000, Loss: 1.8119771993951872e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8875/10000, Loss: 0.013893287628889084, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8876/10000, Loss: 0.01388058066368103, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8877/10000, Loss: 1.311288201577554e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8878/10000, Loss: 0.02773907035589218, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8879/10000, Loss: 0.013867437839508057, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8880/10000, Loss: 6.532612815135508e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8881/10000, Loss: 9.399474947713315e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8882/10000, Loss: 1.029960799314722e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8883/10000, Loss: 0.013871385715901852, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8884/10000, Loss: 1.368513039778918e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8885/10000, Loss: 2.3412092104990734e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8886/10000, Loss: 0.027731847018003464, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8887/10000, Loss: 0.027749361470341682, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8888/10000, Loss: 7.499354524043156e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8889/10000, Loss: 0.013893727213144302, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8890/10000, Loss: 6.389591362676583e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8891/10000, Loss: 0.013864202424883842, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8892/10000, Loss: 1.94547919818433e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8893/10000, Loss: 0.02774476259946823, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8894/10000, Loss: 0.013882605358958244, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8895/10000, Loss: 0.027731729671359062, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8896/10000, Loss: 0.041694916784763336, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8897/10000, Loss: 0.013845761306583881, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8898/10000, Loss: 0.013867178000509739, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8899/10000, Loss: 5.173669137548131e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8900/10000, Loss: 3.123275291727623e-07, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 8900: 0.3594510006189349\n",
            "Epoch 8901/10000, Loss: 1.5120763237064239e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8902/10000, Loss: 8.678371159476228e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8903/10000, Loss: 0.013891804963350296, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8904/10000, Loss: 1.4438936887017917e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8905/10000, Loss: 2.2411309430481197e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8906/10000, Loss: 0.013884667307138443, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8907/10000, Loss: 2.2124620500107994e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8908/10000, Loss: 3.216195864297333e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8909/10000, Loss: 0.013868031091988087, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8910/10000, Loss: 2.4198855044232914e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8911/10000, Loss: 7.796252248226665e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8912/10000, Loss: 0.013889966532588005, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8913/10000, Loss: 1.0013509381678887e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8914/10000, Loss: 0.013875986449420452, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8915/10000, Loss: 2.4318677560586366e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8916/10000, Loss: 0.013883452862501144, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8917/10000, Loss: 7.581608656437311e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8918/10000, Loss: 8.845264574119938e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8919/10000, Loss: 0.027758099138736725, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8920/10000, Loss: 0.027778014540672302, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8921/10000, Loss: 0.013866858556866646, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8922/10000, Loss: 7.295585646716063e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8923/10000, Loss: 0.013881746679544449, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8924/10000, Loss: 8.082361091510393e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8925/10000, Loss: 8.535325264347193e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8926/10000, Loss: 2.198157517341315e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8927/10000, Loss: 0.013860153034329414, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8928/10000, Loss: 0.01387888565659523, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8929/10000, Loss: 4.005424045772088e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8930/10000, Loss: 9.60821807893808e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8931/10000, Loss: 0.013881612569093704, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8932/10000, Loss: 3.4332211384935363e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8933/10000, Loss: 0.013870577327907085, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8934/10000, Loss: 0.013867843896150589, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8935/10000, Loss: 2.126631898136111e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8936/10000, Loss: 0.013881952501833439, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8937/10000, Loss: 0.01386791467666626, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8938/10000, Loss: 0.01388502772897482, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8939/10000, Loss: 7.367081025222433e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8940/10000, Loss: 0.013893438503146172, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8941/10000, Loss: 0.04161204397678375, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8942/10000, Loss: 0.013887300156056881, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8943/10000, Loss: 0.013885000720620155, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8944/10000, Loss: 0.027731752023100853, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8945/10000, Loss: 5.364402113627875e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8946/10000, Loss: 0.01387951709330082, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8947/10000, Loss: 1.2278438816792914e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8948/10000, Loss: 0.013872863724827766, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8949/10000, Loss: 8.463799758828827e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8950/10000, Loss: 7.752185410936363e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8951/10000, Loss: 0.013877734541893005, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8952/10000, Loss: 0.01387146208435297, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8953/10000, Loss: 0.013877072371542454, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8954/10000, Loss: 0.013893596827983856, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8955/10000, Loss: 0.013866733759641647, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8956/10000, Loss: 0.013873748481273651, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8957/10000, Loss: 4.672990883136663e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8958/10000, Loss: 0.013873892836272717, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8959/10000, Loss: 0.02777649648487568, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8960/10000, Loss: 0.013896145857870579, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8961/10000, Loss: 2.582005663498421e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8962/10000, Loss: 0.013895326294004917, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8963/10000, Loss: 0.013876217417418957, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8964/10000, Loss: 0.013899204321205616, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8965/10000, Loss: 7.247872417792678e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8966/10000, Loss: 6.175010298647976e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8967/10000, Loss: 8.8214825666455e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8968/10000, Loss: 7.39094787149952e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8969/10000, Loss: 0.013875518925487995, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8970/10000, Loss: 0.013874133117496967, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8971/10000, Loss: 7.390942187157634e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8972/10000, Loss: 1.0442628308737767e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 8973/10000, Loss: 2.1623952761729015e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8974/10000, Loss: 4.3392074644543754e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8975/10000, Loss: 0.01386991236358881, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8976/10000, Loss: 0.013861993327736855, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8977/10000, Loss: 2.2267672648013104e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8978/10000, Loss: 3.743148795365414e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8979/10000, Loss: 9.393608593200042e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8980/10000, Loss: 2.0503377982095117e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8981/10000, Loss: 1.5497195704483602e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8982/10000, Loss: 3.5524215036275564e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8983/10000, Loss: 0.013853950425982475, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8984/10000, Loss: 0.013877734541893005, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8985/10000, Loss: 1.4195665244187694e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8986/10000, Loss: 7.629387965835122e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8987/10000, Loss: 2.145764597116795e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8988/10000, Loss: 0.013877631165087223, Train Accuracy: 0.9900000095367432\n",
            "Epoch 8989/10000, Loss: 7.72602652432397e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8990/10000, Loss: 1.4510384062305093e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8991/10000, Loss: 2.6606826395436656e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8992/10000, Loss: 2.4318629243680334e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8993/10000, Loss: 2.9802285439473053e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8994/10000, Loss: 0.027798328548669815, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8995/10000, Loss: 3.5524283248378197e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8996/10000, Loss: 7.425630428770091e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 8997/10000, Loss: 2.2172883973325952e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8998/10000, Loss: 2.86101794699789e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 8999/10000, Loss: 0.013882332481443882, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9000/10000, Loss: 0.027808865532279015, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 9000: 0.36041000056266814\n",
            "Epoch 9001/10000, Loss: 1.430509684041681e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9002/10000, Loss: 1.3764120922132861e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9003/10000, Loss: 1.749934313011181e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9004/10000, Loss: 0.013855398632586002, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9005/10000, Loss: 0.027732545509934425, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9006/10000, Loss: 0.013887320645153522, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9007/10000, Loss: 0.013856086879968643, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9008/10000, Loss: 0.027731584385037422, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9009/10000, Loss: 1.3756970474787522e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9010/10000, Loss: 0.01388345006853342, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9011/10000, Loss: 0.027731098234653473, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9012/10000, Loss: 2.303062501596287e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9013/10000, Loss: 0.013872241601347923, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9014/10000, Loss: 1.156321332018706e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9015/10000, Loss: 1.6950993995124009e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9016/10000, Loss: 0.013895159587264061, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9017/10000, Loss: 2.0980822057481419e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9018/10000, Loss: 0.02778938040137291, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9019/10000, Loss: 0.013860770501196384, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9020/10000, Loss: 9.67968048826151e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9021/10000, Loss: 0.01388584729284048, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9022/10000, Loss: 6.628014261877979e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9023/10000, Loss: 0.027785101905465126, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9024/10000, Loss: 8.058493676799117e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9025/10000, Loss: 3.4809016824510763e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9026/10000, Loss: 1.0061164630315034e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9027/10000, Loss: 0.013883630745112896, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9028/10000, Loss: 0.013885575346648693, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9029/10000, Loss: 0.027742508798837662, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9030/10000, Loss: 0.013887499459087849, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9031/10000, Loss: 0.013894781470298767, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9032/10000, Loss: 0.01387976948171854, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9033/10000, Loss: 0.0277309101074934, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9034/10000, Loss: 1.0728751931310399e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9035/10000, Loss: 0.02778395637869835, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9036/10000, Loss: 0.02780964970588684, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9037/10000, Loss: 6.7710658413489e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9038/10000, Loss: 1.1324754041197593e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9039/10000, Loss: 6.818742122050026e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9040/10000, Loss: 2.980219733217382e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9041/10000, Loss: 0.027749905362725258, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9042/10000, Loss: 4.4107318331043643e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9043/10000, Loss: 0.013864791020751, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9044/10000, Loss: 2.6702758759711287e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9045/10000, Loss: 0.02773164212703705, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9046/10000, Loss: 0.041612111032009125, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9047/10000, Loss: 0.013870015740394592, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9048/10000, Loss: 1.3947361594546237e-06, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9049/10000, Loss: 1.4386374459718354e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9050/10000, Loss: 0.013864855282008648, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9051/10000, Loss: 1.3017568107898114e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9052/10000, Loss: 0.013864681124687195, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9053/10000, Loss: 0.02778930589556694, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9054/10000, Loss: 0.013877974823117256, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9055/10000, Loss: 1.412174151482759e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9056/10000, Loss: 0.027731209993362427, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9057/10000, Loss: 3.0279082352535625e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9058/10000, Loss: 6.699532946186082e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9059/10000, Loss: 2.025046524067875e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9060/10000, Loss: 0.02773091569542885, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9061/10000, Loss: 0.01387073565274477, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9062/10000, Loss: 0.013861708343029022, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9063/10000, Loss: 0.013871265575289726, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9064/10000, Loss: 0.013867828994989395, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9065/10000, Loss: 1.7404541097221227e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9066/10000, Loss: 0.013864590786397457, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9067/10000, Loss: 5.340559710020898e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9068/10000, Loss: 0.01389392837882042, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9069/10000, Loss: 0.013867995701730251, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9070/10000, Loss: 7.867806317563009e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9071/10000, Loss: 1.0561848284851294e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9072/10000, Loss: 0.013894760049879551, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9073/10000, Loss: 2.1523597752093337e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9074/10000, Loss: 0.013862912543118, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9075/10000, Loss: 0.013868399895727634, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9076/10000, Loss: 0.013876985758543015, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9077/10000, Loss: 0.013886160217225552, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9078/10000, Loss: 7.128671768441563e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9079/10000, Loss: 1.0442671509736101e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9080/10000, Loss: 0.013874566182494164, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9081/10000, Loss: 7.883463695179671e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9082/10000, Loss: 0.013880196958780289, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9083/10000, Loss: 0.02773064374923706, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9084/10000, Loss: 6.784408924431773e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9085/10000, Loss: 2.7418067816142866e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9086/10000, Loss: 1.8095782934324234e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9087/10000, Loss: 8.416138825850794e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9088/10000, Loss: 5.507451419362042e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9089/10000, Loss: 5.006755259273632e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9090/10000, Loss: 1.5615872825947008e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9091/10000, Loss: 2.932544873601728e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9092/10000, Loss: 3.528584784362465e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9093/10000, Loss: 1.481314939155709e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9094/10000, Loss: 1.5237480511132162e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9095/10000, Loss: 3.027908803687751e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9096/10000, Loss: 3.027905961516808e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9097/10000, Loss: 0.027739714831113815, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9098/10000, Loss: 6.8664309083033e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9099/10000, Loss: 0.013862674124538898, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9100/10000, Loss: 0.013885396532714367, Train Accuracy: 0.9900000095367432\n",
            "Test Accuracy at epoch 9100: 0.36136900050640136\n",
            "Epoch 9101/10000, Loss: 1.6856021147759748e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9102/10000, Loss: 8.291183803521562e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9103/10000, Loss: 7.77620243752608e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9104/10000, Loss: 3.314009404675744e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9105/10000, Loss: 0.013879470527172089, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9106/10000, Loss: 0.027748405933380127, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9107/10000, Loss: 0.02773119881749153, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9108/10000, Loss: 1.103866793528141e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9109/10000, Loss: 1.8000060890699388e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9110/10000, Loss: 1.578826595505234e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9111/10000, Loss: 6.151183242764091e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9112/10000, Loss: 6.548410965478979e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9113/10000, Loss: 8.29691373382957e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9114/10000, Loss: 1.0728830091011332e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9115/10000, Loss: 1.1849290331156226e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9116/10000, Loss: 5.102136242385313e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9117/10000, Loss: 0.013849620707333088, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9118/10000, Loss: 0.01388836931437254, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9119/10000, Loss: 1.4245744750951417e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9120/10000, Loss: 4.053107147683477e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9121/10000, Loss: 6.441131063184002e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9122/10000, Loss: 0.013889910653233528, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9123/10000, Loss: 1.453900767955929e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9124/10000, Loss: 7.867735689615074e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9125/10000, Loss: 6.419679266400635e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9126/10000, Loss: 1.8476901004760293e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9127/10000, Loss: 2.861015673261136e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9128/10000, Loss: 4.339207180237281e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9129/10000, Loss: 9.798917517400696e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9130/10000, Loss: 7.53393862851226e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9131/10000, Loss: 0.01389154139906168, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9132/10000, Loss: 0.027759402990341187, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9133/10000, Loss: 0.0138640021905303, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9134/10000, Loss: 7.390939344986691e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9135/10000, Loss: 0.013865748420357704, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9136/10000, Loss: 0.013883622363209724, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9137/10000, Loss: 1.0585692962195026e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9138/10000, Loss: 2.4127380129357334e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9139/10000, Loss: 7.462462576768303e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9140/10000, Loss: 5.316708779901091e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9141/10000, Loss: 2.1528653633140493e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9142/10000, Loss: 0.013887237757444382, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9143/10000, Loss: 1.4074078535486478e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9144/10000, Loss: 0.027788598090410233, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9145/10000, Loss: 0.013863258063793182, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9146/10000, Loss: 1.7022559859469766e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9147/10000, Loss: 0.013881570659577847, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9148/10000, Loss: 1.0108902870342718e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9149/10000, Loss: 1.7642959448949114e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9150/10000, Loss: 0.013864208944141865, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9151/10000, Loss: 0.013866965658962727, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9152/10000, Loss: 0.013884301297366619, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9153/10000, Loss: 0.013900591991841793, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9154/10000, Loss: 2.3412096652464243e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9155/10000, Loss: 1.654571974540886e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9156/10000, Loss: 0.013894390314817429, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9157/10000, Loss: 1.388812052027788e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9158/10000, Loss: 0.013868083246052265, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9159/10000, Loss: 0.01388154923915863, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9160/10000, Loss: 0.027770230546593666, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9161/10000, Loss: 3.576262201931968e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9162/10000, Loss: 5.960446856079216e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9163/10000, Loss: 2.6797633836395107e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9164/10000, Loss: 0.013877243734896183, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9165/10000, Loss: 3.8623539921900374e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9166/10000, Loss: 0.027770308777689934, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9167/10000, Loss: 0.013888465240597725, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9168/10000, Loss: 4.1246249793402967e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9169/10000, Loss: 0.013884758576750755, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9170/10000, Loss: 3.0517543336827657e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9171/10000, Loss: 6.127330607341719e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9172/10000, Loss: 2.8371744065225357e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9173/10000, Loss: 6.403032784874085e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9174/10000, Loss: 2.198164793298929e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9175/10000, Loss: 6.365742706293531e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9176/10000, Loss: 0.013889930211007595, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9177/10000, Loss: 3.075592758250423e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9178/10000, Loss: 0.01385714951902628, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9179/10000, Loss: 0.02781224623322487, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9180/10000, Loss: 0.01388224121183157, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9181/10000, Loss: 4.315350849992683e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9182/10000, Loss: 7.367095236077148e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9183/10000, Loss: 6.389587383637263e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9184/10000, Loss: 1.575895225869317e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9185/10000, Loss: 0.041600316762924194, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9186/10000, Loss: 1.8119749256584328e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9187/10000, Loss: 0.041611168533563614, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9188/10000, Loss: 1.2874496633230592e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9189/10000, Loss: 0.013876812532544136, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9190/10000, Loss: 1.2588384379341733e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9191/10000, Loss: 6.127325491434021e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9192/10000, Loss: 6.508794854198641e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9193/10000, Loss: 0.04161335527896881, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9194/10000, Loss: 8.916771889744268e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9195/10000, Loss: 1.1587039807636756e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9196/10000, Loss: 0.013880951330065727, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9197/10000, Loss: 0.01388998981565237, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9198/10000, Loss: 9.632029787098872e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9199/10000, Loss: 1.3647389096149709e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9200/10000, Loss: 6.270374228733999e-07, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 9200: 0.3623280004501346\n",
            "Epoch 9201/10000, Loss: 1.6593419331911718e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9202/10000, Loss: 0.027744105085730553, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9203/10000, Loss: 0.01387975923717022, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9204/10000, Loss: 0.013878525234758854, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9205/10000, Loss: 0.013888441026210785, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9206/10000, Loss: 5.650498451359454e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9207/10000, Loss: 4.363048162758787e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9208/10000, Loss: 6.532653742397088e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9209/10000, Loss: 0.013854517601430416, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9210/10000, Loss: 0.013871409930288792, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9211/10000, Loss: 4.6491501848322514e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9212/10000, Loss: 0.013866242952644825, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9213/10000, Loss: 3.0040661158636794e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9214/10000, Loss: 3.480903956187831e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9215/10000, Loss: 4.88756995764561e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9216/10000, Loss: 0.013905229046940804, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9217/10000, Loss: 0.027732593938708305, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9218/10000, Loss: 1.3737994777329732e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9219/10000, Loss: 6.866417265882774e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9220/10000, Loss: 0.013883723877370358, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9221/10000, Loss: 0.01385306566953659, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9222/10000, Loss: 3.2186432008529664e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9223/10000, Loss: 0.027767790481448174, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9224/10000, Loss: 0.013885601423680782, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9225/10000, Loss: 1.9550260788037122e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9226/10000, Loss: 5.9604612800967516e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9227/10000, Loss: 6.031914949744532e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9228/10000, Loss: 0.013878419063985348, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9229/10000, Loss: 6.556433618243318e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9230/10000, Loss: 0.04161256551742554, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9231/10000, Loss: 2.2077026642364217e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9232/10000, Loss: 2.1981613826937973e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9233/10000, Loss: 2.694127658742218e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9234/10000, Loss: 0.027730770409107208, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9235/10000, Loss: 0.027772817760705948, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9236/10000, Loss: 0.013864702545106411, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9237/10000, Loss: 3.4332202858422534e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9238/10000, Loss: 3.6001048897560395e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9239/10000, Loss: 1.45911326399073e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9240/10000, Loss: 1.0538003607507562e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9241/10000, Loss: 0.01386278960853815, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9242/10000, Loss: 0.013884044252336025, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9243/10000, Loss: 2.098077658274633e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9244/10000, Loss: 0.013860218226909637, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9245/10000, Loss: 0.013890741392970085, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9246/10000, Loss: 0.02776142954826355, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9247/10000, Loss: 5.9214844441157766e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9248/10000, Loss: 2.0086299628019333e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9249/10000, Loss: 0.02773088589310646, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9250/10000, Loss: 8.964450444182148e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9251/10000, Loss: 0.013874907977879047, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9252/10000, Loss: 7.867811291362159e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9253/10000, Loss: 0.02776331827044487, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9254/10000, Loss: 5.935795343248174e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9255/10000, Loss: 5.809433332615299e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9256/10000, Loss: 0.013883463107049465, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9257/10000, Loss: 7.247841722346493e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9258/10000, Loss: 0.013887270353734493, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9259/10000, Loss: 2.0742353967762028e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9260/10000, Loss: 6.713033599226037e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9261/10000, Loss: 0.0138759296387434, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9262/10000, Loss: 0.01388868223875761, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9263/10000, Loss: 0.04159862548112869, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9264/10000, Loss: 0.027777574956417084, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9265/10000, Loss: 3.027908803687751e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9266/10000, Loss: 2.0503983932940173e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9267/10000, Loss: 2.8610162416953244e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9268/10000, Loss: 1.5974002565144474e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9269/10000, Loss: 1.9280512788100168e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9270/10000, Loss: 0.013869750313460827, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9271/10000, Loss: 1.6402718756580725e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9272/10000, Loss: 1.9073475243658322e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9273/10000, Loss: 1.0251988413756408e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9274/10000, Loss: 0.02773120626807213, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9275/10000, Loss: 0.013873239047825336, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9276/10000, Loss: 4.7445141149182746e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9277/10000, Loss: 0.013879980891942978, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9278/10000, Loss: 0.013886597938835621, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9279/10000, Loss: 5.792759566247696e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9280/10000, Loss: 3.123276144378906e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9281/10000, Loss: 0.027762480080127716, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9282/10000, Loss: 0.027767052873969078, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9283/10000, Loss: 9.298279337599524e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9284/10000, Loss: 0.013864700682461262, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9285/10000, Loss: 2.0503938458205084e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9286/10000, Loss: 0.013863444328308105, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9287/10000, Loss: 1.9788681981935952e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9288/10000, Loss: 0.013869543559849262, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9289/10000, Loss: 0.027730636298656464, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9290/10000, Loss: 0.01387764047831297, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9291/10000, Loss: 3.9338925716947415e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9292/10000, Loss: 0.013894247822463512, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9293/10000, Loss: 0.013886364176869392, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9294/10000, Loss: 1.3893129107600544e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9295/10000, Loss: 0.01388187613338232, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9296/10000, Loss: 0.01387794129550457, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9297/10000, Loss: 0.013883779756724834, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9298/10000, Loss: 0.013877435587346554, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9299/10000, Loss: 4.506086952460464e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9300/10000, Loss: 0.013871247880160809, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 9300: 0.3632870003938678\n",
            "Epoch 9301/10000, Loss: 1.3547417438530829e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9302/10000, Loss: 3.1947993761605176e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9303/10000, Loss: 0.013879750855267048, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9304/10000, Loss: 0.02773110568523407, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9305/10000, Loss: 0.013876628130674362, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9306/10000, Loss: 4.2676728639889916e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9307/10000, Loss: 0.013881812803447247, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9308/10000, Loss: 0.013866608962416649, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9309/10000, Loss: 0.013884495943784714, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9310/10000, Loss: 0.013871314004063606, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9311/10000, Loss: 0.013888870365917683, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9312/10000, Loss: 0.01390149723738432, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9313/10000, Loss: 4.1484642565592367e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9314/10000, Loss: 0.013873196206986904, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9315/10000, Loss: 0.027731576934456825, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9316/10000, Loss: 6.86642295022466e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9317/10000, Loss: 0.027730807662010193, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9318/10000, Loss: 0.013851695694029331, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9319/10000, Loss: 7.629390097463329e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9320/10000, Loss: 5.483602194544801e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9321/10000, Loss: 2.002714865056987e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9322/10000, Loss: 0.013878287747502327, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9323/10000, Loss: 9.012134682961914e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9324/10000, Loss: 1.4021914466866292e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9325/10000, Loss: 5.885774044145364e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9326/10000, Loss: 7.390972456278178e-08, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9327/10000, Loss: 1.8835031312391948e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9328/10000, Loss: 7.02060333424015e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9329/10000, Loss: 6.965802185732173e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9330/10000, Loss: 0.013858741149306297, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9331/10000, Loss: 6.914135752822403e-08, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9332/10000, Loss: 7.152554815093026e-08, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9333/10000, Loss: 4.410734106841119e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9334/10000, Loss: 2.217290955286444e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9335/10000, Loss: 1.0967250574367426e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9336/10000, Loss: 0.027741024270653725, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9337/10000, Loss: 7.605478344885341e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9338/10000, Loss: 0.01388728991150856, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9339/10000, Loss: 8.082352564997564e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9340/10000, Loss: 3.5524186614566133e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9341/10000, Loss: 7.438583793373255e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9342/10000, Loss: 0.013899006880819798, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9343/10000, Loss: 6.127284564172442e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9344/10000, Loss: 2.0598838545993203e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9345/10000, Loss: 0.013864407315850258, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9346/10000, Loss: 0.013875490054488182, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9347/10000, Loss: 9.393655204803508e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9348/10000, Loss: 2.3412169412040384e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9349/10000, Loss: 0.027736324816942215, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9350/10000, Loss: 2.3364947310255957e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9351/10000, Loss: 0.01388468500226736, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9352/10000, Loss: 1.3170863894629292e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9353/10000, Loss: 3.64779538131188e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9354/10000, Loss: 0.01385450828820467, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9355/10000, Loss: 0.02778146043419838, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9356/10000, Loss: 0.0138826509937644, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9357/10000, Loss: 0.013871540315449238, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9358/10000, Loss: 0.02776988409459591, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9359/10000, Loss: 0.013854124583303928, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9360/10000, Loss: 5.745870339524117e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9361/10000, Loss: 0.013886797241866589, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9362/10000, Loss: 6.140902769402601e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9363/10000, Loss: 0.01388527825474739, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9364/10000, Loss: 0.027784032747149467, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9365/10000, Loss: 2.2888120554398483e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9366/10000, Loss: 1.8620038417793694e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9367/10000, Loss: 0.013891884125769138, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9368/10000, Loss: 3.4093793033207476e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9369/10000, Loss: 3.910053010258707e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9370/10000, Loss: 0.013908687978982925, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9371/10000, Loss: 1.6641155298202648e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9372/10000, Loss: 0.013875643722712994, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9373/10000, Loss: 7.176371354944422e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9374/10000, Loss: 0.02779633179306984, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9375/10000, Loss: 8.583064925460349e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9376/10000, Loss: 1.1444087988365936e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9377/10000, Loss: 0.013883328065276146, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9378/10000, Loss: 8.583064925460349e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9379/10000, Loss: 9.512819474366552e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9380/10000, Loss: 4.43457281562587e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9381/10000, Loss: 0.01387226302176714, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9382/10000, Loss: 0.013884808868169785, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9383/10000, Loss: 0.013858758844435215, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9384/10000, Loss: 6.270335006774985e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9385/10000, Loss: 0.02780325897037983, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9386/10000, Loss: 4.053103452861251e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9387/10000, Loss: 1.3657328054250684e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9388/10000, Loss: 0.013868695124983788, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9389/10000, Loss: 0.013895745389163494, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9390/10000, Loss: 1.692769302508168e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9391/10000, Loss: 0.02773047238588333, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9392/10000, Loss: 0.013883327133953571, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9393/10000, Loss: 0.013849864713847637, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9394/10000, Loss: 8.034625693653652e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9395/10000, Loss: 7.700887749706453e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9396/10000, Loss: 3.766996314880089e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9397/10000, Loss: 0.013885622844099998, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9398/10000, Loss: 5.885820428375155e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9399/10000, Loss: 0.01389257051050663, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9400/10000, Loss: 0.013879338279366493, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 9400: 0.364246000337601\n",
            "Epoch 9401/10000, Loss: 0.027730440720915794, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9402/10000, Loss: 0.013892468065023422, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9403/10000, Loss: 0.027730640023946762, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9404/10000, Loss: 0.013888870365917683, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9405/10000, Loss: 0.013887569308280945, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9406/10000, Loss: 1.3445202057482675e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9407/10000, Loss: 6.318018108686374e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9408/10000, Loss: 5.435918524199224e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9409/10000, Loss: 0.013894550502300262, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9410/10000, Loss: 5.683172730641672e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9411/10000, Loss: 0.01388007216155529, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9412/10000, Loss: 0.013868365436792374, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9413/10000, Loss: 0.013882528059184551, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9414/10000, Loss: 5.960438898000575e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9415/10000, Loss: 3.5047449387093366e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9416/10000, Loss: 5.7220436389116e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9417/10000, Loss: 6.914137884450611e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9418/10000, Loss: 1.6450874795737036e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9419/10000, Loss: 3.0279073826022795e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9420/10000, Loss: 2.980225701776362e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9421/10000, Loss: 3.1471168426833174e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9422/10000, Loss: 0.013852285221219063, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9423/10000, Loss: 5.888915666218963e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9424/10000, Loss: 1.7261075981878093e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9425/10000, Loss: 7.224003297778836e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9426/10000, Loss: 8.201571404242713e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9427/10000, Loss: 0.013876272365450859, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9428/10000, Loss: 0.013858078047633171, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9429/10000, Loss: 0.02781381458044052, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9430/10000, Loss: 2.4080227944978105e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9431/10000, Loss: 6.174969939820585e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9432/10000, Loss: 0.01388876885175705, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9433/10000, Loss: 0.027736444026231766, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9434/10000, Loss: 4.553782275706908e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9435/10000, Loss: 0.013882838189601898, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9436/10000, Loss: 4.529939019448648e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9437/10000, Loss: 1.6450849216198549e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9438/10000, Loss: 0.013861436396837234, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9439/10000, Loss: 2.574917061792803e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9440/10000, Loss: 0.013898462988436222, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9441/10000, Loss: 6.532649194923579e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9442/10000, Loss: 0.013872872106730938, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9443/10000, Loss: 3.6716377849188575e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9444/10000, Loss: 1.6689266146840964e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9445/10000, Loss: 0.013875518925487995, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9446/10000, Loss: 0.01387181505560875, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9447/10000, Loss: 3.838528357391624e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9448/10000, Loss: 1.5019948023109464e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9449/10000, Loss: 0.013879228383302689, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9450/10000, Loss: 1.6689267567926436e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9451/10000, Loss: 1.310677453147946e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9452/10000, Loss: 6.248249974305509e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9453/10000, Loss: 0.027784794569015503, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9454/10000, Loss: 3.4570598472782876e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9455/10000, Loss: 2.4080216576294333e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9456/10000, Loss: 0.013855422846972942, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9457/10000, Loss: 8.535351980754058e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9458/10000, Loss: 0.01387681346386671, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9459/10000, Loss: 0.013881135731935501, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9460/10000, Loss: 0.01386199425905943, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9461/10000, Loss: 8.106226800919103e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9462/10000, Loss: 0.013878959231078625, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9463/10000, Loss: 0.013870462775230408, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9464/10000, Loss: 7.677001576666953e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9465/10000, Loss: 0.013903516344726086, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9466/10000, Loss: 5.531242095457856e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9467/10000, Loss: 1.2830288142140489e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9468/10000, Loss: 6.556438165716827e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9469/10000, Loss: 0.02773190476000309, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9470/10000, Loss: 0.013887081295251846, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9471/10000, Loss: 5.511555173143279e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9472/10000, Loss: 3.0755933266846114e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9473/10000, Loss: 0.02780589833855629, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9474/10000, Loss: 0.02773076482117176, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9475/10000, Loss: 0.013877229765057564, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9476/10000, Loss: 0.01386104803532362, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9477/10000, Loss: 0.013891336508095264, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9478/10000, Loss: 4.863725848736067e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9479/10000, Loss: 7.557838443972287e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9480/10000, Loss: 3.7193200341789634e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9481/10000, Loss: 0.013872028328478336, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9482/10000, Loss: 1.142016117228195e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9483/10000, Loss: 0.01387967448681593, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9484/10000, Loss: 2.0027144387313456e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9485/10000, Loss: 0.013873365707695484, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9486/10000, Loss: 2.312654885372467e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9487/10000, Loss: 1.482921902606904e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9488/10000, Loss: 1.3140292139723897e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9489/10000, Loss: 0.013886706903576851, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9490/10000, Loss: 0.04160948842763901, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9491/10000, Loss: 0.013882630504667759, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9492/10000, Loss: 1.7857123566500377e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9493/10000, Loss: 0.02772490866482258, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9494/10000, Loss: 9.536739042914633e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9495/10000, Loss: 2.598758328531403e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9496/10000, Loss: 0.013871598057448864, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9497/10000, Loss: 1.6974995560303796e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9498/10000, Loss: 0.013867542147636414, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9499/10000, Loss: 9.536739042914633e-08, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9500/10000, Loss: 0.013883637264370918, Train Accuracy: 0.9900000095367432\n",
            "Test Accuracy at epoch 9500: 0.36520500028133424\n",
            "Epoch 9501/10000, Loss: 0.027730269357562065, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9502/10000, Loss: 1.9550290630832023e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9503/10000, Loss: 0.027730636298656464, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9504/10000, Loss: 0.01386371348053217, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9505/10000, Loss: 7.629321885360696e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9506/10000, Loss: 7.82010374678066e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9507/10000, Loss: 1.9788723193414626e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9508/10000, Loss: 1.5639849380022497e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9509/10000, Loss: 5.924043307459215e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9510/10000, Loss: 0.027731051668524742, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9511/10000, Loss: 1.217240424011834e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9512/10000, Loss: 8.630680099486199e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9513/10000, Loss: 1.2284471267776098e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9514/10000, Loss: 0.0139071149751544, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9515/10000, Loss: 0.013876520097255707, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9516/10000, Loss: 0.013871997594833374, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9517/10000, Loss: 5.6546382438682485e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9518/10000, Loss: 0.013866161927580833, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9519/10000, Loss: 0.013874349184334278, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9520/10000, Loss: 6.151175284685451e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9521/10000, Loss: 4.529941293185402e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9522/10000, Loss: 0.013877496123313904, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9523/10000, Loss: 4.672990883136663e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9524/10000, Loss: 2.241131369373761e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9525/10000, Loss: 3.7193137814028887e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9526/10000, Loss: 0.013886409811675549, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9527/10000, Loss: 9.417487945029279e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9528/10000, Loss: 5.466302354761865e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9529/10000, Loss: 1.3828262979131978e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9530/10000, Loss: 5.125980351294857e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9531/10000, Loss: 0.013860957697033882, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9532/10000, Loss: 1.233937746292213e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9533/10000, Loss: 1.478192217518881e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9534/10000, Loss: 4.315357671202946e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9535/10000, Loss: 5.006771175430913e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9536/10000, Loss: 0.041612014174461365, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9537/10000, Loss: 2.741808202699758e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9538/10000, Loss: 1.6212352420552634e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9539/10000, Loss: 3.0040672527320567e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9540/10000, Loss: 0.013875933364033699, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9541/10000, Loss: 1.8119764888524514e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9542/10000, Loss: 0.027736352756619453, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9543/10000, Loss: 0.013881678692996502, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9544/10000, Loss: 2.0742372441873158e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9545/10000, Loss: 1.0490412449826181e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9546/10000, Loss: 5.06816286360845e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9547/10000, Loss: 5.373336534830742e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9548/10000, Loss: 0.013878917321562767, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9549/10000, Loss: 0.04163883253931999, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9550/10000, Loss: 0.013872457668185234, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9551/10000, Loss: 3.93389115060927e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9552/10000, Loss: 0.013887086883187294, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9553/10000, Loss: 0.0138772651553154, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9554/10000, Loss: 5.485395377036184e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9555/10000, Loss: 0.027730457484722137, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9556/10000, Loss: 0.013867301866412163, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9557/10000, Loss: 5.1587721827672794e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9558/10000, Loss: 5.960400812909938e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9559/10000, Loss: 0.01389208436012268, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9560/10000, Loss: 0.013872656971216202, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9561/10000, Loss: 4.816042178390489e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9562/10000, Loss: 0.013891899026930332, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9563/10000, Loss: 1.2380034604575485e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9564/10000, Loss: 3.1709589620732004e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9565/10000, Loss: 1.3113006502862845e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9566/10000, Loss: 0.01390431821346283, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9567/10000, Loss: 0.027731673792004585, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9568/10000, Loss: 0.013895661570131779, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9569/10000, Loss: 1.1917533811356407e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9570/10000, Loss: 6.222700221769628e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9571/10000, Loss: 9.274405670112174e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9572/10000, Loss: 0.013869398273527622, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9573/10000, Loss: 1.1910380635526963e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9574/10000, Loss: 0.013871399685740471, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9575/10000, Loss: 0.013887115754187107, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9576/10000, Loss: 1.660905581957195e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9577/10000, Loss: 5.866885658178944e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9578/10000, Loss: 0.027735071256756783, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9579/10000, Loss: 2.1219219092927233e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9580/10000, Loss: 0.013891748152673244, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9581/10000, Loss: 1.7881360747651343e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9582/10000, Loss: 3.027907951036468e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9583/10000, Loss: 8.344647284275197e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9584/10000, Loss: 0.0277301836758852, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9585/10000, Loss: 0.013858630321919918, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9586/10000, Loss: 1.1788851224991959e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9587/10000, Loss: 0.013868148438632488, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9588/10000, Loss: 0.04160415008664131, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9589/10000, Loss: 0.013890557922422886, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9590/10000, Loss: 5.0419771469023544e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9591/10000, Loss: 0.013871125876903534, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9592/10000, Loss: 5.722029072785517e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9593/10000, Loss: 0.013875650241971016, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9594/10000, Loss: 0.013889223337173462, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9595/10000, Loss: 0.013871735893189907, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9596/10000, Loss: 0.027779333293437958, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9597/10000, Loss: 1.181036168418359e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9598/10000, Loss: 3.218642632418778e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9599/10000, Loss: 8.034637062337424e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9600/10000, Loss: 4.815491593035404e-06, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 9600: 0.36616400022506745\n",
            "Epoch 9601/10000, Loss: 9.179037192552641e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9602/10000, Loss: 2.0027118807774968e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9603/10000, Loss: 1.2220450116728898e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9604/10000, Loss: 0.013873930089175701, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9605/10000, Loss: 1.1796067155955825e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9606/10000, Loss: 3.361694496106793e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9607/10000, Loss: 0.013878999277949333, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9608/10000, Loss: 5.102137379253691e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9609/10000, Loss: 0.013875972479581833, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9610/10000, Loss: 0.01387233380228281, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9611/10000, Loss: 0.013859717175364494, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9612/10000, Loss: 2.2411289535284595e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9613/10000, Loss: 4.743978479382349e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9614/10000, Loss: 1.1898639058927074e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9615/10000, Loss: 1.1571999493753538e-05, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9616/10000, Loss: 4.1961513375099457e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9617/10000, Loss: 1.5592190720781218e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9618/10000, Loss: 0.027810845524072647, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9619/10000, Loss: 1.3351434802189033e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9620/10000, Loss: 4.0292627545568394e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9621/10000, Loss: 1.8500888927519554e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9622/10000, Loss: 1.1521970009198412e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9623/10000, Loss: 4.774984518007841e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9624/10000, Loss: 0.013857829384505749, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9625/10000, Loss: 3.004069526468811e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9626/10000, Loss: 4.67298804096572e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9627/10000, Loss: 5.2732798394572455e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9628/10000, Loss: 5.793548893961997e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9629/10000, Loss: 2.741807065831381e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9630/10000, Loss: 2.2172878288984066e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9631/10000, Loss: 0.013874386437237263, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9632/10000, Loss: 0.027747349813580513, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9633/10000, Loss: 6.03192802373087e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9634/10000, Loss: 0.013877670280635357, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9635/10000, Loss: 0.02773020975291729, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9636/10000, Loss: 0.013883084990084171, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9637/10000, Loss: 0.027730397880077362, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9638/10000, Loss: 2.7894901677427697e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9639/10000, Loss: 0.013867863453924656, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9640/10000, Loss: 2.3364965784367087e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9641/10000, Loss: 0.013877453282475471, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9642/10000, Loss: 0.013885410502552986, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9643/10000, Loss: 8.320737379108323e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9644/10000, Loss: 0.013880887068808079, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9645/10000, Loss: 0.013869206421077251, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9646/10000, Loss: 4.1723097865542513e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9647/10000, Loss: 0.013880360871553421, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9648/10000, Loss: 3.9338979718195333e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9649/10000, Loss: 3.528585352796654e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9650/10000, Loss: 2.3126568748921272e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9651/10000, Loss: 1.6235923112617456e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9652/10000, Loss: 1.114300266635837e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9653/10000, Loss: 2.670282697181392e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9654/10000, Loss: 4.975287993147504e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9655/10000, Loss: 1.5377621593870572e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9656/10000, Loss: 0.013877954334020615, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9657/10000, Loss: 0.013870169408619404, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9658/10000, Loss: 0.013860895298421383, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9659/10000, Loss: 0.013882809318602085, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9660/10000, Loss: 3.910054715561273e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9661/10000, Loss: 1.4757742974325083e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9662/10000, Loss: 1.2611975535037345e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9663/10000, Loss: 2.8848509714407555e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9664/10000, Loss: 3.9815813579480164e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9665/10000, Loss: 4.291533528544278e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9666/10000, Loss: 5.173671979719074e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9667/10000, Loss: 0.013874487951397896, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9668/10000, Loss: 7.176336680458917e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9669/10000, Loss: 2.2649720676781726e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9670/10000, Loss: 7.343231231971004e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9671/10000, Loss: 0.013864085078239441, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9672/10000, Loss: 1.147684633906465e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9673/10000, Loss: 0.027759650722146034, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9674/10000, Loss: 2.5033844508470793e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9675/10000, Loss: 4.949079993821215e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9676/10000, Loss: 0.013867370784282684, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9677/10000, Loss: 0.013882622122764587, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9678/10000, Loss: 0.0138658182695508, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9679/10000, Loss: 0.013889787718653679, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9680/10000, Loss: 0.02773072011768818, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9681/10000, Loss: 0.013876380398869514, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9682/10000, Loss: 0.01387578621506691, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9683/10000, Loss: 2.169604869095565e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9684/10000, Loss: 0.027730237692594528, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9685/10000, Loss: 1.2159340201378654e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9686/10000, Loss: 4.148468519815651e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9687/10000, Loss: 0.01388639211654663, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9688/10000, Loss: 5.245190664027177e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9689/10000, Loss: 6.198882118724214e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9690/10000, Loss: 1.1071612789237406e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9691/10000, Loss: 1.088086992240278e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9692/10000, Loss: 1.9550293473002966e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9693/10000, Loss: 1.3661015145771671e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9694/10000, Loss: 1.8357840190219576e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9695/10000, Loss: 0.0138757498934865, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9696/10000, Loss: 0.013872313313186169, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9697/10000, Loss: 0.027776576578617096, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9698/10000, Loss: 0.013904173858463764, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9699/10000, Loss: 0.01387676689773798, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9700/10000, Loss: 0.013867199420928955, Train Accuracy: 0.9919999837875366\n",
            "Test Accuracy at epoch 9700: 0.3671230001688007\n",
            "Epoch 9701/10000, Loss: 1.0888075848924927e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9702/10000, Loss: 6.914135752822403e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9703/10000, Loss: 0.013867435045540333, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9704/10000, Loss: 0.01388956606388092, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9705/10000, Loss: 1.764293813266704e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9706/10000, Loss: 0.027730362489819527, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9707/10000, Loss: 0.02773093245923519, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9708/10000, Loss: 0.013878358528017998, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9709/10000, Loss: 0.027730055153369904, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9710/10000, Loss: 2.8848575084339245e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9711/10000, Loss: 4.334003733674763e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9712/10000, Loss: 3.671635226965009e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9713/10000, Loss: 7.724703436906566e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9714/10000, Loss: 4.3673849177139346e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9715/10000, Loss: 0.013877981342375278, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9716/10000, Loss: 0.027730168774724007, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9717/10000, Loss: 2.503388145669305e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9718/10000, Loss: 0.013875026255846024, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9719/10000, Loss: 0.013866567052900791, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9720/10000, Loss: 5.869388132850872e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9721/10000, Loss: 0.013875912874937057, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9722/10000, Loss: 4.60342471342301e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9723/10000, Loss: 9.536676657262433e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9724/10000, Loss: 2.408023362931999e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9725/10000, Loss: 0.013877027668058872, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9726/10000, Loss: 1.4543520876486582e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9727/10000, Loss: 6.246509656193666e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9728/10000, Loss: 0.013891234993934631, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9729/10000, Loss: 0.01387909147888422, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9730/10000, Loss: 4.56528914583032e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9731/10000, Loss: 0.027730315923690796, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9732/10000, Loss: 1.0490412449826181e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9733/10000, Loss: 0.013879036530852318, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9734/10000, Loss: 1.418578563061601e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9735/10000, Loss: 4.1957450775953475e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9736/10000, Loss: 0.041605107486248016, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9737/10000, Loss: 8.344588877662318e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9738/10000, Loss: 0.013892230577766895, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9739/10000, Loss: 3.1471171269004117e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9740/10000, Loss: 3.552422924713028e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9741/10000, Loss: 0.013851435855031013, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9742/10000, Loss: 6.747194447598304e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9743/10000, Loss: 2.2172878288984066e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9744/10000, Loss: 1.8358196030021645e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9745/10000, Loss: 5.383045390772168e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9746/10000, Loss: 0.013878935016691685, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9747/10000, Loss: 3.123276997030189e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9748/10000, Loss: 0.027729971334338188, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9749/10000, Loss: 1.7499559135103482e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9750/10000, Loss: 3.83853006269419e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9751/10000, Loss: 8.463797485092073e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9752/10000, Loss: 5.206626155995764e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9753/10000, Loss: 0.013896441087126732, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9754/10000, Loss: 1.0640314940246753e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9755/10000, Loss: 4.291133791411994e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9756/10000, Loss: 0.013882766477763653, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9757/10000, Loss: 7.033324891381199e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9758/10000, Loss: 1.358983467980579e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9759/10000, Loss: 1.537763864689623e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9760/10000, Loss: 0.013866421766579151, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9761/10000, Loss: 0.013858463615179062, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9762/10000, Loss: 4.1484668145130854e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9763/10000, Loss: 2.1219209145328932e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9764/10000, Loss: 3.9100581261664047e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9765/10000, Loss: 2.884858076868113e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9766/10000, Loss: 6.437299049366629e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9767/10000, Loss: 0.013868069276213646, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9768/10000, Loss: 0.027731062844395638, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9769/10000, Loss: 0.013869504444301128, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9770/10000, Loss: 0.027775460854172707, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9771/10000, Loss: 0.013893669471144676, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9772/10000, Loss: 0.013892117887735367, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9773/10000, Loss: 0.013889279216527939, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9774/10000, Loss: 0.04161654785275459, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9775/10000, Loss: 1.025199480864103e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9776/10000, Loss: 0.013880787417292595, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9777/10000, Loss: 6.627982429563417e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9778/10000, Loss: 7.867811291362159e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9779/10000, Loss: 0.013904369436204433, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9780/10000, Loss: 0.013906515203416348, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9781/10000, Loss: 2.264972494003814e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9782/10000, Loss: 0.02773039974272251, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9783/10000, Loss: 3.623949282882677e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9784/10000, Loss: 6.318039709185541e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9785/10000, Loss: 0.013883071951568127, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9786/10000, Loss: 6.103496730247571e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9787/10000, Loss: 4.482253075366316e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9788/10000, Loss: 1.0452075912326109e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9789/10000, Loss: 0.01386353187263012, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9790/10000, Loss: 1.0397247024229728e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9791/10000, Loss: 0.01387964840978384, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9792/10000, Loss: 3.6001125636175857e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9793/10000, Loss: 0.013862124644219875, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9794/10000, Loss: 1.3851787343810429e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9795/10000, Loss: 2.3603405452377046e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9796/10000, Loss: 1.9073469559316436e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9797/10000, Loss: 1.0013572904199464e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9798/10000, Loss: 0.027755744755268097, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9799/10000, Loss: 0.01387358270585537, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9800/10000, Loss: 1.5974013933828246e-07, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 9800: 0.3680820001125339\n",
            "Epoch 9801/10000, Loss: 0.013878894969820976, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9802/10000, Loss: 0.013896740041673183, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9803/10000, Loss: 1.0115968507307116e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9804/10000, Loss: 1.3828271505644807e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9805/10000, Loss: 0.027731047943234444, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9806/10000, Loss: 1.2826588999814703e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9807/10000, Loss: 0.013880416750907898, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9808/10000, Loss: 1.203981469188875e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9809/10000, Loss: 0.013866701163351536, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9810/10000, Loss: 1.0690581802919041e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9811/10000, Loss: 0.02772999182343483, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9812/10000, Loss: 0.013881697319447994, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9813/10000, Loss: 1.5020042383184773e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9814/10000, Loss: 0.013860681094229221, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9815/10000, Loss: 1.090994555852376e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9816/10000, Loss: 3.8501225390064064e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9817/10000, Loss: 1.3351430538932618e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9818/10000, Loss: 3.859659955196548e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9819/10000, Loss: 4.792195795744192e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9820/10000, Loss: 0.02772989682853222, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9821/10000, Loss: 3.7690640510845697e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9822/10000, Loss: 0.027729958295822144, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9823/10000, Loss: 1.1250876923440956e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9824/10000, Loss: 1.6021364217522205e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9825/10000, Loss: 0.013866400346159935, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9826/10000, Loss: 8.106170525934431e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9827/10000, Loss: 1.7404532570708398e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9828/10000, Loss: 0.013863625004887581, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9829/10000, Loss: 3.337859766361362e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9830/10000, Loss: 4.386887439977727e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9831/10000, Loss: 0.013881301507353783, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9832/10000, Loss: 0.027730287984013557, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9833/10000, Loss: 3.3378537978023815e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9834/10000, Loss: 1.9073452506290778e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9835/10000, Loss: 0.013891501352190971, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9836/10000, Loss: 3.7857664665352786e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9837/10000, Loss: 0.01386154256761074, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9838/10000, Loss: 2.9325389050427475e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9839/10000, Loss: 0.027755508199334145, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9840/10000, Loss: 4.2029987525893375e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9841/10000, Loss: 3.004062989475642e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9842/10000, Loss: 0.027729973196983337, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9843/10000, Loss: 0.013876516371965408, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9844/10000, Loss: 2.2411289535284595e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9845/10000, Loss: 0.013879443518817425, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9846/10000, Loss: 3.6954799043087405e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9847/10000, Loss: 0.013869461603462696, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9848/10000, Loss: 4.768361350215855e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9849/10000, Loss: 0.013850871473550797, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9850/10000, Loss: 1.478193922821447e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9851/10000, Loss: 0.013873573392629623, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9852/10000, Loss: 4.021813765575644e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9853/10000, Loss: 1.3112997976350016e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9854/10000, Loss: 4.7444888195968815e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9855/10000, Loss: 1.380412072649051e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9856/10000, Loss: 3.814696114545768e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9857/10000, Loss: 9.889661669149064e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9858/10000, Loss: 2.7656452061819436e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9859/10000, Loss: 0.013866137713193893, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9860/10000, Loss: 7.176345206971746e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9861/10000, Loss: 3.9338934243460244e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9862/10000, Loss: 0.013878311030566692, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9863/10000, Loss: 2.5749156407073315e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9864/10000, Loss: 1.7642931027239683e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9865/10000, Loss: 0.02776968851685524, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9866/10000, Loss: 4.76837058727142e-08, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9867/10000, Loss: 0.013884899206459522, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9868/10000, Loss: 0.013876590877771378, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9869/10000, Loss: 3.8930793380131945e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9870/10000, Loss: 0.01386631466448307, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9871/10000, Loss: 0.013861343264579773, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9872/10000, Loss: 2.6225998794870975e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9873/10000, Loss: 6.675666099908995e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9874/10000, Loss: 0.013880832120776176, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9875/10000, Loss: 0.02772965095937252, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9876/10000, Loss: 3.5974524053017376e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9877/10000, Loss: 1.4853161474093213e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9878/10000, Loss: 1.6379025282731163e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9879/10000, Loss: 0.041600823402404785, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9880/10000, Loss: 1.2206933206471149e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9881/10000, Loss: 5.412081804934132e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9882/10000, Loss: 1.1849106158479117e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9883/10000, Loss: 3.654677584563615e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9884/10000, Loss: 0.013906281441450119, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9885/10000, Loss: 0.013907769694924355, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9886/10000, Loss: 0.013860542327165604, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9887/10000, Loss: 0.02772984467446804, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9888/10000, Loss: 0.013854688964784145, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9889/10000, Loss: 0.027730034664273262, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9890/10000, Loss: 4.076940172126342e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9891/10000, Loss: 0.013863813132047653, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9892/10000, Loss: 3.0517514915118227e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9893/10000, Loss: 1.5258767405157414e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9894/10000, Loss: 3.862372182084073e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9895/10000, Loss: 1.009243987937225e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9896/10000, Loss: 1.1205666794467106e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9897/10000, Loss: 3.170961235809955e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9898/10000, Loss: 8.106228222004574e-08, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9899/10000, Loss: 0.02776332013309002, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9900/10000, Loss: 0.013885196298360825, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 9900: 0.3690410000562671\n",
            "Epoch 9901/10000, Loss: 8.30087301437743e-05, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9902/10000, Loss: 0.01386619545519352, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9903/10000, Loss: 1.0074537385662552e-05, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9904/10000, Loss: 0.013911775313317776, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9905/10000, Loss: 0.013855794444680214, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9906/10000, Loss: 3.242486741328321e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9907/10000, Loss: 0.013836942613124847, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9908/10000, Loss: 1.1634733709797729e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9909/10000, Loss: 0.013875235803425312, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9910/10000, Loss: 2.8347474199108547e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9911/10000, Loss: 0.027747925370931625, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9912/10000, Loss: 0.013876006007194519, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9913/10000, Loss: 1.1491654277051566e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9914/10000, Loss: 0.027730323374271393, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9915/10000, Loss: 5.399798283178825e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9916/10000, Loss: 0.013859715312719345, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9917/10000, Loss: 0.02773021161556244, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9918/10000, Loss: 8.726033229322638e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9919/10000, Loss: 0.013874794356524944, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9920/10000, Loss: 5.459772864924162e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9921/10000, Loss: 0.013913472183048725, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9922/10000, Loss: 1.5974033829024847e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9923/10000, Loss: 7.39091547075077e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9924/10000, Loss: 4.224416898068739e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9925/10000, Loss: 1.7166098587040324e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9926/10000, Loss: 6.723340675307554e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9927/10000, Loss: 1.1968481885560323e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9928/10000, Loss: 0.013906162232160568, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9929/10000, Loss: 0.027825606986880302, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9930/10000, Loss: 7.176345775405935e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9931/10000, Loss: 0.013895070180296898, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9932/10000, Loss: 0.013869795948266983, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9933/10000, Loss: 3.6001154057885287e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9934/10000, Loss: 2.4175267299142433e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9935/10000, Loss: 0.02773016132414341, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9936/10000, Loss: 0.02773001790046692, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9937/10000, Loss: 0.013903354294598103, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9938/10000, Loss: 4.0575177990831435e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9939/10000, Loss: 0.013853934593498707, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9940/10000, Loss: 3.314012246846687e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9941/10000, Loss: 0.013890615664422512, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9942/10000, Loss: 7.843906928428623e-07, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9943/10000, Loss: 0.013895606622099876, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9944/10000, Loss: 0.013862738385796547, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9945/10000, Loss: 0.013899131678044796, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9946/10000, Loss: 0.027815349400043488, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9947/10000, Loss: 0.013898634351789951, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9948/10000, Loss: 5.316700253388262e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9949/10000, Loss: 0.04158773645758629, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9950/10000, Loss: 3.0279122142928827e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9951/10000, Loss: 9.79940978140803e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9952/10000, Loss: 5.006775722904422e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9953/10000, Loss: 0.013856715522706509, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9954/10000, Loss: 2.980222575388325e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9955/10000, Loss: 5.769700237578945e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9956/10000, Loss: 0.027730587869882584, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9957/10000, Loss: 7.367084435827564e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9958/10000, Loss: 0.01386399194598198, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9959/10000, Loss: 8.130030551001255e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9960/10000, Loss: 0.013850872404873371, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9961/10000, Loss: 5.232905095908791e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9962/10000, Loss: 0.013896463438868523, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9963/10000, Loss: 9.265405424230266e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9964/10000, Loss: 4.002674359071534e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9965/10000, Loss: 0.013883709907531738, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9966/10000, Loss: 0.027730366215109825, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9967/10000, Loss: 3.385535762845393e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9968/10000, Loss: 2.0265545686015685e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9969/10000, Loss: 1.180157369162771e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9970/10000, Loss: 4.100425030628685e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9971/10000, Loss: 0.013884587213397026, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9972/10000, Loss: 5.245177590040839e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9973/10000, Loss: 0.013868318870663643, Train Accuracy: 0.9879999756813049\n",
            "Epoch 9974/10000, Loss: 0.02772977016866207, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9975/10000, Loss: 0.02771092765033245, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9976/10000, Loss: 7.700871833549172e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9977/10000, Loss: 0.013910849578678608, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9978/10000, Loss: 0.013901295140385628, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9979/10000, Loss: 0.01387879066169262, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9980/10000, Loss: 2.7202725050301524e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9981/10000, Loss: 2.1146927338122623e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9982/10000, Loss: 1.0636303159117233e-05, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9983/10000, Loss: 2.269666310894536e-06, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9984/10000, Loss: 4.18863646700629e-06, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9985/10000, Loss: 0.013856365345418453, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9986/10000, Loss: 1.0728830091011332e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9987/10000, Loss: 8.707591405254789e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9988/10000, Loss: 2.0312529613875085e-06, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9989/10000, Loss: 0.013864099979400635, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9990/10000, Loss: 0.013873977586627007, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9991/10000, Loss: 6.461103225774423e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9992/10000, Loss: 1.4781936386043526e-07, Train Accuracy: 0.9919999837875366\n",
            "Epoch 9993/10000, Loss: 0.01389111578464508, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9994/10000, Loss: 0.013889866881072521, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9995/10000, Loss: 3.242483899157378e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9996/10000, Loss: 6.031958150742867e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9997/10000, Loss: 7.510136583732674e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 9998/10000, Loss: 1.502035189560047e-07, Train Accuracy: 0.9900000095367432\n",
            "Epoch 9999/10000, Loss: 3.0517514915118227e-07, Train Accuracy: 0.9940000176429749\n",
            "Epoch 10000/10000, Loss: 0.027731359004974365, Train Accuracy: 0.9940000176429749\n",
            "Test Accuracy at epoch 10000: 0.37000000000000033\n"
          ]
        }
      ],
      "source": [
        "epochs = 10000\n",
        "test_acc_st=[]\n",
        "for epoch in range(epochs):\n",
        "    # Reset training accuracy for every epoch\n",
        "    train_accuracy_metric.reset_state()\n",
        "\n",
        "    # Shuffle the data at the beginning of each epoch\n",
        "    indices = tf.random.shuffle(tf.range(len(X_train_label)))\n",
        "    train_data = tf.gather(train_data, indices)\n",
        "    train_labels = tf.gather(train_labels, indices)\n",
        "\n",
        "    # Loop over the data in batches\n",
        "    for batch in range(num_batches):\n",
        "        batch_data = train_data[batch * batch_size:(batch + 1) * batch_size]\n",
        "        batch_labels = train_labels[batch * batch_size:(batch + 1) * batch_size]\n",
        "\n",
        "        # Perform one training step on the batch\n",
        "        loss = train_step(batch_data, batch_labels)\n",
        "\n",
        "    # Print training loss and accuracy for each epoch\n",
        "    train_accuracy = train_accuracy_metric.result().numpy()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.numpy()}, Train Accuracy: {train_accuracy}\")\n",
        "\n",
        "    # Every 100 epochs, evaluate and print test accuracy\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "\n",
        "        test_accuracy_metric.reset_state()\n",
        "        test_step(test_data, test_labels)\n",
        "        test_accuracy = test_accuracy_metric.result().numpy()\n",
        "        test_acc_st.append(test_accuracy)\n",
        "        print(f\"Test Accuracy at epoch {epoch+1}: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "5Fn_MT59PNmJ",
        "outputId": "fdfda654-1299-44ff-c61d-c2bc75e961f0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Replace these with your actual arrays\n",
        "array1=test_acc_st\n",
        "array2=baseline.test_acc\n",
        "\n",
        "# Plot both arrays\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(array1, label='Pre_Trained', marker='o')\n",
        "plt.plot(array2, label='Base line', marker='s')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epochs per 100')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of test Accuracy at every 100th Epoch')\n",
        "\n",
        "# Add grid and legend\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqsB85AAblXv"
      },
      "source": [
        "The above grpah shows that the pre-trained performes well compared to the baseline. which is similar while we implmeneted the direct training approach."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
